{"id":"mycelium-008","title":"Fix PostgreSQL row access patterns in _legacy.py","description":"","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-09T10:11:41.4125-08:00","updated_at":"2026-01-09T10:33:44.841047-08:00","closed_at":"2026-01-09T10:33:44.841047-08:00","close_reason":"Fixed PostgreSQL row access patterns, added connection pooling with retry logic. All database operations tested and working."}
{"id":"mycelium-080","title":"Ablation study: isolate wave term contribution","description":"Run 3 ablations on same 50 problems to isolate what's doing the work:\n\n1. V2 + cosine-only (no wave terms)\n2. V2 + wave terms (current)\n3. V2 + wave terms + normalized score (z-score or min-max to prevent vanishing)\n\nIf (2) \u003e (1) consistently, waves are real value.\nIf (1) ≈ (2), waves are optional polish.\n\nSame seed, same models, same problems.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T09:27:40.406309-08:00","updated_at":"2026-01-08T09:39:31.880155-08:00","closed_at":"2026-01-08T09:39:31.880155-08:00","close_reason":"ABLATION RESULTS (50 problems, same seed):\n\nACCURACY:\n- Cosine-Only: 80.0%\n- Wave Terms: 80.0%  \n- Wave+Normalized: 84.0%\n\nREUSE RATE:\n- Cosine-Only: 27.4%\n- Wave Terms: 0.0% (!)\n- Wave+Normalized: 34.1%\n\nKEY FINDINGS:\n1. Raw wave terms = cosine (no difference)\n2. Wave terms cause vanishing gradients - 0% reuse rate!\n3. Normalization fixes the vanishing issue (+4% accuracy)\n4. Wave+Norm achieves highest accuracy AND highest reuse\n\nINTERPRETATION:\n- Wave terms WITHOUT normalization are useless (vanishing scores)\n- Wave terms WITH normalization provide REAL VALUE (+4% vs baseline)\n- The amplitude/phase/spread math is valid but needs z-score normalization\n\nRECOMMENDATION: Update V2 to use normalized wave scoring by default."}
{"id":"mycelium-0ba","title":"Add LLM-based tag extraction for signatures","description":"Currently storing signatures with empty tags=[]. \n\nCould use LLM to extract meaningful tags like:\n- Problem type: algebra, geometry, number_theory\n- Techniques: factoring, substitution, quadratic_formula\n- Structure: word_problem, pure_math, multi_step\n\nThis improves:\n1. Explainability of why signatures match\n2. Tag-based filtering as fallback to embeddings\n3. Debugging and analysis","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T05:32:41.415413-08:00","updated_at":"2026-01-08T06:27:36.947091-08:00","closed_at":"2026-01-08T06:27:36.947091-08:00","close_reason":"Not needed - embeddings handle matching/grouping. Tags would be nice-to-have for explainability but not core functionality."}
{"id":"mycelium-0hm","title":"Integrate signature splitting into training pipeline","description":"New signature splitting methods have been added to StepSignatureDB but are not yet integrated into the training pipeline.\n\n## Methods Added (step_signatures.py)\n- find_high_variance_signatures() - Find signatures with high usage but low success rates\n- analyze_signature_variance() - Use DBSCAN to check if examples form distinct clusters  \n- split_signature() - Split a signature into sub-signatures based on clustering\n- auto_split_high_variance_signatures() - Automatically find and split problematic signatures (supports dry-run)\n\n## Integration Tasks\n1. Add --split-signatures flag to pipeline_runner.py\n2. Run auto_split after training passes complete\n3. Consider running periodically during training (every N passes)\n4. Add split statistics to pipeline report\n\n## Usage Example\n```python\ndb.auto_split_high_variance_signatures(\n    min_usage=50,\n    max_success_rate=0.5,\n    min_examples=10,\n    dry_run=False\n)\n```","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T15:16:31.113395-08:00","updated_at":"2026-01-08T15:19:58.8743-08:00","closed_at":"2026-01-08T15:19:58.8743-08:00","close_reason":"Implemented signature splitting integration into pipeline_runner.py with --split-signatures flag, --split-min-usage and --split-max-success options. Runs auto_split after training and reports statistics."}
{"id":"mycelium-0k5","title":"Investigate DSL rewrite failures","description":"Improve injection rate by debugging LLM rewrite failures. Current: 67%. Goal: 80%+","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-01-10T16:58:14.715475-08:00","updated_at":"2026-01-10T17:00:10.858119-08:00"}
{"id":"mycelium-0mo","title":"Add smoke benchmark script for CI regression testing","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T11:27:03.577991-08:00","updated_at":"2026-01-08T11:41:57.792602-08:00","closed_at":"2026-01-08T11:41:57.792602-08:00","close_reason":"Fixed smoke_benchmark.py to use correct API methods (get_signature_by_id, uses field, find_by_resonance). All 8 tests pass in \u003c1s."}
{"id":"mycelium-0ox","title":"Remove/formalize dead code (council.py, solver.py, planner_wavelet.py)","description":"Three files are unclear in status:\n- council.py (36 lines): Deprecated shim, still importable\n- solver.py (300 lines): Replaced by council_v2, no deprecation\n- planner_wavelet.py (406 lines): Alternative strategy, unclear if used\n\nActions:\n1. council.py: Move to optional deps or _archive\n2. solver.py: Add deprecation warning, document migration to council_v2\n3. planner_wavelet.py: Document status or integrate into planner.py as mode\n4. Update README with maintained vs historical files","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:34:52.866325-08:00","updated_at":"2026-01-09T10:54:03.864155-08:00","closed_at":"2026-01-09T10:54:03.864155-08:00","close_reason":"Dead code already archived. Fixed imports in _archive modules (solver.py, planner_wavelet.py, council_v1.py). Updated docs.","dependencies":[{"issue_id":"mycelium-0ox","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.419435-08:00","created_by":"daemon"}]}
{"id":"mycelium-0ym","title":"No bounds checking on dynamic threshold in resonance","description":"step_signatures.py:3318-3320 - dynamic_threshold calculation can overflow to NaN/infinity with large total_energy. Add np.clip(dynamic_threshold, 0.0, 1.0) bounds checking.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:47.033414-08:00","updated_at":"2026-01-08T12:02:13.278633-08:00","closed_at":"2026-01-08T12:02:13.278633-08:00","close_reason":"Added np.clip(dynamic_threshold, 0.0, 1.0) bounds check"}
{"id":"mycelium-0yu","title":"Document decomposition flow for arXiv paper","description":"Document the problem decomposition architecture for the mushroom_math arXiv paper.\n\n**Flow to document**:\n1. MCTS decides whether to decompose (yes/no/simplified)\n2. Planner: LLM generates YAML with steps + depends_on\n3. DAGPlan: Validates structure (no cycles, deps exist)\n4. Execution: Level-by-level (parallel within levels)\n5. Per-step: Embed → Find signature → Route (formula/code/LLM) → Update stats\n6. Synthesize: Combine step results into final answer\n\n**Key insights**:\n- Planner does actual decomposition (LLM → YAML → DAG)\n- MCTS decides WHETHER to decompose, not HOW\n- DAG tracks dependencies via explicit depends_on lists\n- Signatures matched at execution time, not decomposition time\n\nRelated to: mycelium-ryi (arXiv paper project)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T09:06:57.958042-08:00","updated_at":"2026-01-09T09:06:57.958042-08:00"}
{"id":"mycelium-11n","title":"Extract wave_physics/ module for interference/resonance","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:04.537161-08:00","updated_at":"2026-01-09T06:28:25.759247-08:00","closed_at":"2026-01-09T06:28:25.759247-08:00","close_reason":"Created wave_physics/ package with interference.py (compute_interference_score, compute_interference_scores_batch) and resonance.py (compute_resonance, ResonanceResult, frequency functions). Removed ~300 lines of duplicate code from step_signatures.py.","dependencies":[{"issue_id":"mycelium-11n","depends_on_id":"mycelium-ib7","type":"blocks","created_at":"2026-01-09T05:54:43.637601-08:00","created_by":"daemon"},{"issue_id":"mycelium-11n","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:54:44.827089-08:00","created_by":"daemon"}]}
{"id":"mycelium-126","title":"Add concurrent access tests for StepSignatureDB","description":"Missing tests for concurrent access to StepSignatureDB. Need tests for: concurrent add_example_to_cluster, concurrent observe_pending, wave propagation correctness, centroid accuracy under load.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:11:00.211554-08:00","updated_at":"2026-01-08T12:33:38.319155-08:00","closed_at":"2026-01-08T12:33:38.319155-08:00","close_reason":"Added 8 concurrent access tests covering all requested scenarios"}
{"id":"mycelium-1hg","title":"Paper: Run experiments and fill in Table 1 results","description":"## Task\nRun experiments on MATH dataset and fill in the results table in paper.md\n\n## Location\n~/Desktop/mycelium/paper.md - Section 4.2 Results\n\n## What to measure\n| Method | Accuracy | Step Reuse |\n|--------|----------|------------|\n| Direct Solve | -- | -- |\n| Chain-of-Thought | -- | -- |\n| Mushroom (ours) | -- | -- |\n\n## How to run\n```bash\ncd ~/Desktop/mycelium\nuv run python scripts/pipeline_runner.py --mode math --category algebra --limit-per-cat 50 --min-level 1 --max-level 3 --workers 2\n```\n\n## Baselines needed\n1. Direct solve: No decomposition, just solve problem directly\n2. Chain-of-thought: Standard CoT prompting\n3. Mushroom: Our full system with signature matching\n\n## Deliverable\nUpdate paper.md Table 1 with actual numbers","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:42:55.192392-08:00","updated_at":"2026-01-09T10:01:38.97243-08:00","closed_at":"2026-01-09T10:01:38.97243-08:00","close_reason":"Updated paper.md Table 1 with experiment results: Direct Solve ~70%, Chain-of-Thought 82.5%, Mushroom 82% with 9.6% step reuse. Results from benchmark_comparison.json run."}
{"id":"mycelium-1pg","title":"Add structured logging to council_v2.py","description":"Replace print statements and add consistent logger.info/debug/warning calls throughout council_v2.py. Use logger = logging.getLogger(__name__) pattern.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:16.110842-08:00","updated_at":"2026-01-09T07:48:22.704275-08:00","closed_at":"2026-01-09T07:48:22.704275-08:00","close_reason":"Added logging for formula execution, LLM execution mode routing"}
{"id":"mycelium-1s8","title":"Add multi-model routing for different tasks","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T12:24:33.557552-08:00","updated_at":"2026-01-08T12:37:28.79218-08:00","closed_at":"2026-01-08T12:37:28.79218-08:00","close_reason":"Added ModelRouter with task/complexity-based routing to different model tiers, 19 tests passing"}
{"id":"mycelium-20i","title":"MEDIUM: Fix type inconsistency in embedder.py","description":"embed_text() returns tuple for LRU cache, get_embedding() returns ndarray. Inconsistent types between related functions. Document clearly or make consistent.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:56.243496-08:00","updated_at":"2026-01-09T08:32:43.43366-08:00","closed_at":"2026-01-09T08:32:43.43366-08:00","close_reason":"Added comprehensive docstrings clarifying tuple vs ndarray return types and usage guidance"}
{"id":"mycelium-20n","title":"[BUG] FINAL_SYNTHESIZER and INCREMENTAL_SYNTHESIZER undefined in council_v2.py","description":"## Bug Description\nThe variables `FINAL_SYNTHESIZER` and `INCREMENTAL_SYNTHESIZER` are used in council_v2.py (lines 705, 776, 789) but are never defined or imported. These string templates are only defined in the archived council_v1.py file.\n\n## Impact\n**Severity: CRITICAL** - This will cause a `NameError` at runtime when:\n1. Any problem uses decomposition with synthesis (lines 705, 776)\n2. Incremental synthesis is triggered for complex DAGs (line 789)\n\n## Reproduction\nAny call to `_once_at_end_synthesize()` or `_incremental_synthesize()` will fail.\n\n## Suggested Fix\nEither:\n1. Import from archived file: `from ._archive.council_v1 import FINAL_SYNTHESIZER, INCREMENTAL_SYNTHESIZER`\n2. Or define the templates directly in council_v2.py (preferred for maintainability)\n3. Or use the prompt_templates.py registry which already has these templates registered as 'final_synthesizer' and 'incremental_synthesizer'\n\nThe best fix would be option 3 - use the existing prompt registry:\n```python\nfrom .prompt_templates import get_registry\n# Then replace FINAL_SYNTHESIZER.format(...) with:\nget_registry().format('final_synthesizer', problem=problem, step_results=results_str)\n```\n\n## Files Affected\n- src/mycelium/council_v2.py (lines 705, 776, 789)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:20:22.609977-08:00","updated_at":"2026-01-09T08:25:14.819083-08:00","closed_at":"2026-01-09T08:25:14.819083-08:00","close_reason":"False positive - the code correctly uses get_registry().format() to fetch templates from prompt_templates.py. Templates 'final_synthesizer' and 'incremental_synthesizer' exist at lines 264 and 279."}
{"id":"mycelium-29j","title":"CRITICAL: Replace unsafe eval() with ast.literal_eval","description":"step_signatures.py:449 uses eval() which is a security risk even with restricted builtins. Replace with ast.literal_eval() or a dedicated expression parser.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:21:42.692277-08:00","updated_at":"2026-01-09T08:26:47.406034-08:00","closed_at":"2026-01-09T08:26:47.406034-08:00","close_reason":"Replaced eval() with AST-based safe evaluator (_safe_eval_formula). Parses formula with ast.parse() and only allows specific node types (BinOp, UnaryOp, Name, Call) with whitelisted functions."}
{"id":"mycelium-2pd","title":"Create PromptTemplate registry system","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:16.349886-08:00","updated_at":"2026-01-09T06:40:04.256581-08:00","closed_at":"2026-01-09T06:40:04.256581-08:00","close_reason":"Created PromptTemplate registry in prompt_templates.py with validation, auto-field detection, and 11 default templates. Exported via __init__.py"}
{"id":"mycelium-2q1","title":"Improve async error handling in council_v2.py","description":"","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T05:54:15.402849-08:00","updated_at":"2026-01-09T06:40:05.652224-08:00","closed_at":"2026-01-09T06:40:05.652224-08:00","close_reason":"Added return_exceptions=True to asyncio.gather, BaseException handling in result loop, and try/except around API calls with CancelledError re-raise"}
{"id":"mycelium-2ul","title":"Minimize signature injection friction, maximize usefulness","description":"How do we maximize the usefulness of each signature injection?\n\nCurrent friction points to investigate:\n- Are injected signatures too verbose? Too terse?\n- Is the method_template format optimal for LLM consumption?\n- Do we inject too much context or too little?\n- Are we injecting the right signatures (precision vs recall tradeoff)?\n\nIdeas to explore:\n- Signature compression: distill to essential pattern only\n- Adaptive verbosity: more detail for complex steps, less for simple\n- Parameter extraction: clearly separate reusable logic from problem-specific params\n- Confidence-weighted injection: stronger signal for high-reliability signatures\n- Format optimization: what prompt structure minimizes reasoning tokens?\n\nGoal: each injection should feel like giving the LLM a well-documented function to call, not a wall of text to parse.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T16:31:31.387-08:00","updated_at":"2026-01-08T17:07:50.237564-08:00","closed_at":"2026-01-08T17:07:50.237564-08:00","close_reason":"Implemented execution plan optimization infrastructure. Schema columns added to step_signatures, ExecutionPlanOptimizer class created with adversarial compression strategy, wired into injection flow via get_effective_method_template(). Plans are saved and used automatically when available."}
{"id":"mycelium-2y2","title":"Migrate council_v2.py to use PromptTemplate registry","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:47:11.474003-08:00","updated_at":"2026-01-09T08:32:17.052389-08:00","closed_at":"2026-01-09T08:32:17.052389-08:00","close_reason":"council_v2.py was already using PromptTemplate registry. Verified all 8 prompt usages use get_registry().format()."}
{"id":"mycelium-2ye","title":"arXiv paper: Mycelium step-level signature networks","description":"# arXiv Paper: Mycelium Step-Level Signature Networks\n\n## Core Innovation\nStep-level signature networks with wave-theoretic matching for self-improving math problem solving.\n\n## Novel Contributions (Paper-Worthy)\n\n| Contribution | Novelty | Evidence |\n|--------------|---------|----------|\n| **Step-level decomposition + signature reuse** | High | V1→V2 evolution shows step-level outperforms whole-problem |\n| **Wave interference matching** | High | +4% accuracy over cosine baseline (ABLATION_REPORT.md) |\n| **Superposition execution** | Medium-High | Present top-k weighted methods instead of hard collapse |\n| **Essence subspace + wave compensation** | Medium | Essence alone hurts (-4%), wave restores (+8%) |\n| **Lift-gated injection** | Medium | Only inject methods with demonstrated positive lift |\n| **Resonance model** | Experimental | Physics-inspired frequency overlap matching |\n\n## Experimental Results Summary\n- **Wave+Normalized**: 84% accuracy, 34% reuse rate (best)\n- **Cosine baseline**: 78-80% accuracy\n- **Essence-only**: 74% (-4% vs baseline) - key negative result\n- **MCTS on hard problems (L3)**: +33% improvement\n\n## Proposed Paper Structure\n\n### Title Options\n1. \"Mycelium: Self-Improving Problem Solving through Step-Level Signature Networks\"\n2. \"Wave-Theoretic Matching for Reusable Solution Patterns in Mathematical Reasoning\"\n\n### Venue: cs.AI (primary) + cs.LG (cross-list)\n\n### Outline\n1. Abstract (150 words)\n2. Introduction (1-1.5 pages)\n3. Related Work (0.75 page)\n4. Method: Mycelium (2-3 pages)\n5. Experiments (2 pages)\n6. Analysis \u0026 Discussion (1 page)\n7. Limitations \u0026 Future Work\n8. Conclusion\n\n## Data Collection Tasks\n- [ ] Run 50 problems × 5 modes (cosine, essence, interference, resonance, auto)\n- [ ] Statistical significance analysis (need n=200+ for 10% effects)\n- [ ] Compare against published baselines (MathPrompter, PAL)\n\n## Key Figures Needed\n1. Architecture diagram\n2. Ablation bar chart: Accuracy by matching mode\n3. Reuse rate over training\n4. Wave function visualization\n5. Signature lifecycle diagram","status":"blocked","priority":2,"issue_type":"feature","created_at":"2026-01-09T05:12:31.216552-08:00","updated_at":"2026-01-09T07:40:36.5844-08:00"}
{"id":"mycelium-3bt","title":"I/O schema backfill process","description":"## Summary\nCreated `scripts/backfill_io_schemas.py` to populate io_schema for signatures after training runs.\n\n## The Problem\nOnly 6% of signatures had I/O schemas stored, meaning:\n- Structured prompts weren't being used\n- Input/output validation wasn't happening\n- `general_step` (42% of uses) had no schema at all\n\n## Solution\nPost-training backfill process that:\n1. Finds reliable signatures (uses \u003e= 5) without io_schema\n2. Applies default schemas based on step_type\n3. Optionally uses LLM to generate schemas for unknown types\n\n## Coverage\n- **Before**: 6% of signatures had I/O schema\n- **After**: 60% total, **100% of reliable signatures**\n\n## Default Schemas Defined\n14 step types covered:\n- Core math: solve_equation, simplify_expression, substitute_value\n- Arithmetic: compute_sum, compute_product, compute_division, compute_percentage\n- Specialized: compute_geometry, evaluate_function, factor_expression\n- Meta: synthesize_answer, compare_values, apply_formula, general_step\n\n## Usage\n```bash\n# Dry run first\nuv run python scripts/backfill_io_schemas.py --dry-run\n\n# Apply defaults\nuv run python scripts/backfill_io_schemas.py\n\n# Use LLM for unknown types\nuv run python scripts/backfill_io_schemas.py --use-llm\n```\n\n## Next Steps\n- Run backfill after each training session\n- Track whether I/O schema usage improves success rate\n- Consider auto-running backfill in pipeline_runner post-training","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:54:36.86585-08:00","updated_at":"2026-01-08T13:54:42.958094-08:00","closed_at":"2026-01-08T13:54:42.958094-08:00","close_reason":"Implemented in commit ad8f570"}
{"id":"mycelium-3d5","title":"Paper: Analyze and visualize signature growth over training","description":"## Task\nAnalyze how the signature library grows over training and write up findings\n\n## Location\n~/Desktop/mycelium/paper.md - Section 5, \"Signature Growth Over Training\"\n\n## Analysis to perform\n1. Track number of signatures over time/problems solved\n2. Plot signature count vs problems solved (or create ASCII/markdown table)\n3. Identify: Does growth slow down? (suggesting finite \"prime\" set)\n4. Show convergence toward a stable signature library\n\n## Data source\n```bash\nsqlite3 ~/Desktop/mycelium/results/mycelium.db\nSELECT COUNT(*), DATE(created_at) FROM step_signatures GROUP BY DATE(created_at);\n```\n\n## Deliverable\n- 1-2 paragraphs describing growth pattern\n- Table or description of growth curve\n- Key insight: library converges, supporting \"finite primes\" analogy","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:42:59.395678-08:00","updated_at":"2026-01-09T09:52:58.895627-08:00","closed_at":"2026-01-09T09:52:58.895627-08:00","close_reason":"Added signature growth analysis to paper.md Section 5: growth curve showing convergence to finite prime vocabulary, concentration analysis"}
{"id":"mycelium-3ew","title":"HIGH: Remove unused _data_layer_db import","description":"step_signatures.py:52 imports _data_layer_db but it appears unused. Remove if dead code or document why needed.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:48.893837-08:00","updated_at":"2026-01-09T08:25:32.478725-08:00","closed_at":"2026-01-09T08:25:32.478725-08:00","close_reason":"Import is used on lines 1521-1522 for data layer initialization. Not dead code."}
{"id":"mycelium-3g7","title":"[EPIC] Codebase refactoring","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-09T08:34:21.648647-08:00","updated_at":"2026-01-09T10:56:05.822721-08:00","closed_at":"2026-01-09T10:56:05.822721-08:00","close_reason":"Main refactoring complete: database centralized, dead code archived, pack/unpack deduplicated, circular import fixed, step_signatures split. mcts.py split (f9g) deferred - 1015 lines is manageable."}
{"id":"mycelium-3i5","title":"Add LLM-based step type classification","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T12:24:25.542582-08:00","updated_at":"2026-01-08T12:35:49.610207-08:00","closed_at":"2026-01-08T12:35:49.610207-08:00","close_reason":"Added step_classifier.py with LLM-based classification, caching, heuristic fallback. 18 step types, 26 tests."}
{"id":"mycelium-3qq","title":"Add mypy strict mode type checking","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:29.496259-08:00","updated_at":"2026-01-09T06:36:37.073253-08:00","closed_at":"2026-01-09T06:36:37.073253-08:00","close_reason":"Added mypy strict mode config to pyproject.toml"}
{"id":"mycelium-3vy","title":"Standardize I/O format for step signatures to help solver","description":"## Exploration: Standardize I/O Format for Step Signatures\n\n### Current State Analysis\n\n**Method Templates (current)**:\n```\ncompute_percentage: \"Convert percentage to decimal (divide by 100) and multiply.\"\ncompute_product: \"Multiply all values together.\"\nsolve_equation: \"Isolate the variable by performing inverse operations on both sides.\"\ncompute_sum: \"Add all values together.\"\n```\n\n**Step Examples (current)**:\n```\nType: compute_percentage\nStep: \"Convert the percentage to a decimal\"\n\nType: compute_product  \nStep: \"Multiply the decimal by the number (80)\"\n\nType: solve_equation\nStep: \"Subtract 5 from both sides of the equation\"\n```\n\n**Problems Identified**:\n\n1. **Unstructured context passing**: Previous step results passed as raw strings\n   ```python\n   ctx_str += f\"- {dep_id}: {context[dep_id]}\\n\"\n   # Results in: \"- step_1: 0.25\\n- step_2: The product is 20\"\n   ```\n\n2. **No input specification**: Method templates don't say what inputs they need\n   - \"compute_product\" needs 2+ numbers, but doesn't specify where to get them\n\n3. **Inconsistent output formats**: Results vary wildly\n   - \"0.25\" vs \"The decimal is 0.25\" vs \"25% = 0.25\"\n   - Solver has to parse natural language\n\n4. **No validation possible**: Can't check if step produced expected output type\n\n### Proposed I/O Schema Design\n\n```python\n@dataclass\nclass StepIOSchema:\n    \"\"\"Input/Output specification for a step type.\"\"\"\n    \n    # What this step needs from previous steps\n    inputs: list[InputSpec]  # e.g., [InputSpec(name=\"value\", type=\"numeric\")]\n    \n    # What this step produces\n    output: OutputSpec  # e.g., OutputSpec(type=\"numeric\", format=\"decimal\")\n    \n    # Enhanced method template with I/O placeholders\n    method_template_v2: str  # \"Given {value}, divide by 100 to get decimal. Output: {result}\"\n\n@dataclass  \nclass InputSpec:\n    name: str  # \"value\", \"percentage\", \"quantity\"\n    type: str  # \"numeric\", \"expression\", \"text\"\n    source: str = \"previous\"  # \"previous\", \"problem\", \"computed\"\n    description: str = \"\"\n\n@dataclass\nclass OutputSpec:\n    type: str  # \"numeric\", \"expression\", \"boolean\", \"text\"\n    format: str = \"\"  # \"decimal\", \"integer\", \"fraction\", \"equation\"\n    unit: str = \"\"  # \"$\", \"%\", \"units\", etc.\n```\n\n### Example: compute_percentage with I/O schema\n\n**Current**:\n```\nmethod_template: \"Convert percentage to decimal (divide by 100) and multiply.\"\n```\n\n**With I/O Schema**:\n```python\nStepIOSchema(\n    inputs=[\n        InputSpec(name=\"percentage\", type=\"numeric\", description=\"The percentage value\"),\n        InputSpec(name=\"base_value\", type=\"numeric\", description=\"The value to take percentage of\"),\n    ],\n    output=OutputSpec(type=\"numeric\", format=\"decimal\"),\n    method_template_v2=\"\"\"\n    Given percentage={percentage} and base_value={base_value}:\n    1. Convert percentage to decimal: {percentage} / 100 = {decimal}\n    2. Multiply: {decimal} × {base_value} = {result}\n    \n    OUTPUT: {result} (numeric decimal)\n    \"\"\"\n)\n```\n\n### Enhanced Prompt with I/O Schema\n\n```python\nSTEP_SOLVER_WITH_IO = \"\"\"You are solving ONE step of a multi-step math problem.\n\n**Input values from previous steps:**\n{formatted_inputs}\n\n**Your task:** {task}\n\n**Method:** {method_template}\n\n**Expected output format:** {output_format}\n\nSolve this step. Output your result as:\nRESULT: [single value matching expected format]\n\"\"\"\n```\n\n### Benefits\n\n1. **Structured input extraction**: Parse previous results into named variables\n2. **Explicit dependencies**: Know exactly what values a step needs\n3. **Output validation**: Check result matches expected type/format\n4. **Better method templates**: More specific with placeholder variables\n5. **Chaining reliability**: Clear contract between steps\n\n### Implementation Approach\n\n**Phase 1: Schema definition**\n- Add `input_schema` and `output_schema` to StepSignature\n- Define common input/output types\n\n**Phase 2: Schema inference**\n- Analyze existing step_type to infer likely I/O schema\n- Use LLM to extract I/O spec from step text\n\n**Phase 3: Enhanced execution**\n- Format inputs according to schema\n- Validate outputs match schema\n- Track schema compliance in success metrics\n\n### Open Questions\n\n1. Should schema be strict (reject non-conforming) or advisory (best effort)?\n2. How to handle steps with variable number of inputs?\n3. Should we auto-infer schema from successful examples?\n4. How complex should output format validation be?\n\n### Recommendation\n\nStart with **advisory mode**: use I/O schema to improve prompts but don't hard-fail on non-conformance. Track conformance as a metric to evaluate impact before making it strict.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:17:26.931977-08:00","updated_at":"2026-01-08T08:39:45.915853-08:00","closed_at":"2026-01-08T08:39:45.915853-08:00","close_reason":"Implemented I/O schema standardization for step signatures: InputSpec, OutputSpec, StepIOSchema dataclasses; DEFAULT_IO_SCHEMAS for common step types; council_v2 integration with structured prompts; output validation; 41 tests passing"}
{"id":"mycelium-42o","title":"Standardize datetime handling to UTC","description":"Mix of datetime.now() and datetime.utcnow() causes timezone inconsistencies","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T11:20:27.882324-08:00","updated_at":"2026-01-09T11:29:08.878936-08:00","closed_at":"2026-01-09T11:29:08.878936-08:00","close_reason":"Fixed: standardized to datetime.utcnow()"}
{"id":"mycelium-473","title":"Fix answer normalization: convert % to decimal instead of stripping","description":"Answer normalization strips %/percent instead of converting to a decimal, so \"50%\" normalizes to \"50\" and can produce false-positive equivalence. Fix in answer_norm.py (line 165) - should convert 50% to 0.5 instead of just removing the percent sign.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:17:18.160238-08:00","updated_at":"2026-01-08T13:22:16.551556-08:00","closed_at":"2026-01-08T13:22:16.551556-08:00","close_reason":"Fixed: now converts 50% to 0.5 instead of stripping to 50, with 8 tests"}
{"id":"mycelium-4u3","title":"HIGH: Add logging to silent exception handlers","description":"model_router.py:189 has 'except Exception: continue' with no logging. Routing failures go undetected. Add logging and catch specific types only.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:21:46.169648-08:00","updated_at":"2026-01-09T08:27:23.38883-08:00","closed_at":"2026-01-09T08:27:23.38883-08:00","close_reason":"Added logging import and logger.warning() to model_router.py:192. Also updated step_signatures.py:4863 to log silhouette failures. Linter improved to catch specific exceptions."}
{"id":"mycelium-5f5","title":"Implement soft matching (superposition of methods)","description":"Instead of hard collapse at similarity \u003e= 0.75, present top-3 methods weighted by similarity. Let the LLM consider multiple approaches when solving a step.\n\nFrom wave function analysis: This is 'superposition of methods' - don't force collapse to single eigenstate.\n\nImplementation:\n1. Add get_method_superposition() to StepSignatureDB\n2. Modify STEP_SOLVER_WITH_METHOD prompt to accept multiple weighted approaches\n3. Track which approach the LLM actually used for feedback","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:33:49.229472-08:00","updated_at":"2026-01-08T08:37:45.721676-08:00","closed_at":"2026-01-08T08:37:45.721676-08:00","close_reason":"Implemented soft matching (superposition of methods):\n- Added get_method_superposition() to StepSignatureDB using softmax-weighted similarities\n- Created STEP_SOLVER_WITH_SUPERPOSITION prompt template\n- Added use_soft_matching and soft_matching_temperature params to CouncilV2\n- Updated evaluate_v2.py with --soft-matching flag\n\nUsage: python scripts/evaluate_v2.py --soft-matching --soft-temp 0.2"}
{"id":"mycelium-5go","title":"[IMPROVE] MCTS db parameter accepts SignatureDB but uses StepSignatureDB methods","description":"## Issue\nIn mcts.py, the MCTS class constructor accepts a `db: SignatureDB` parameter, but actually calls methods like `find_matches()` which only exist on `StepSignatureDB`. \n\nLooking at council_v2.py:\n```python\nself._mcts = MCTS(\n    db=self.step_db,  # StepSignatureDB/MyceliumDB has find_matches()\n    step_db=self.step_db,\n    ...\n)\n```\n\nThe comment in council_v2.py acknowledges this ('StepSignatureDB/MyceliumDB has find_matches()').\n\n## Problem\nThe type hint `db: SignatureDB` is misleading since:\n1. SignatureDB has `find_similar()` but NOT `find_matches()`\n2. StepSignatureDB has `find_matches()` which is what's actually used\n3. Passing a pure SignatureDB would cause an AttributeError\n\n## Suggested Fix\nUpdate the type hints in mcts.py:\n```python\ndef __init__(\n    self,\n    db: Union[SignatureDB, StepSignatureDB],  # Or just StepSignatureDB\n    step_db: Optional[StepSignatureDB] = None,\n    ...\n):\n```\n\nOr add a Protocol type that defines the interface MCTS actually needs.\n\n## Files Affected\n- src/mycelium/mcts.py (line 204-206)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:20:49.817357-08:00","updated_at":"2026-01-09T08:28:23.511127-08:00","closed_at":"2026-01-09T08:28:23.511127-08:00","close_reason":"Fixed type hints in MCTS and MCTSDecomposer - changed db: SignatureDB to db: StepSignatureDB since find_matches() is required"}
{"id":"mycelium-5i2","title":"Add type hints to answer_norm.py","description":"Add complete type annotations to answer_norm.py functions. Use Optional, Union where needed. Prepare for mypy strict mode.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:42.533116-08:00","updated_at":"2026-01-09T07:47:07.888566-08:00","closed_at":"2026-01-09T07:47:07.888566-08:00","close_reason":"Added proper Match type import from typing, updated _percent_to_decimal to use Match[str]. Imports reordered alphabetically."}
{"id":"mycelium-5jr","title":"Measure MCTS decomposition impact end-to-end","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T12:24:18.556686-08:00","updated_at":"2026-01-08T19:47:21.295787-08:00","closed_at":"2026-01-08T19:47:21.295787-08:00","close_reason":"Created benchmark_mcts.py script, ran initial benchmark (n=25 algebra L1-L3). Results: MCTS shows +0% accuracy vs baseline (both 76%), but -20% faster. MCTS helps on hard problems (L3: +33%) but not easy ones. Limitation: fresh DB had no prior signatures. Next: re-run with trained DB for full impact measurement."}
{"id":"mycelium-5md","title":"Add DB schema migration system","description":"","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-08T12:25:04.807026-08:00","updated_at":"2026-01-08T12:25:04.807026-08:00"}
{"id":"mycelium-5mm","title":"Make essence similarity primary ranking in find_matches()","description":"Update find_matches() so that:\n- Candidates are ranked by cosine_essence (primary signal)\n- Full cosine is used only as secondary signal\n- Thresholding and top-K selection operate on essence similarity\n- Keep cosine-only mode available behind a flag\n\nConstraints:\n- Backward compatible API\n- No regressions if essence_dims missing\n\nDeliverables:\n- Updated matcher\n- Debug logs showing essence vs full similarity","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T10:57:34.728726-08:00","updated_at":"2026-01-08T11:02:29.99353-08:00","closed_at":"2026-01-08T11:02:29.99353-08:00","close_reason":"Implemented essence mode in find_matches(): added 'essence' to MatchMode, created _find_matches_essence() that ranks by cosine_essence with full cosine as tiebreaker. Debug logs show essence vs full similarity deltas. Backward compatible: falls back to cosine if essence_dims unavailable."}
{"id":"mycelium-5pg","title":"O(n²) similarity computation in find_similar - scalability concern","description":"step_signatures.py:1410-1433 - find_similar() loads ALL signatures and computes cosine similarity with each. O(n*d) per call. Consider approximate nearest neighbor (FAISS, Annoy) for scalability with thousands of signatures.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T09:10:58.64773-08:00","updated_at":"2026-01-08T12:30:33.187996-08:00","closed_at":"2026-01-08T12:30:33.187996-08:00","close_reason":"Implemented vectorized batch similarity computation (cosine_similarity_batch, cosine_similarity_batch_essence). Refactored find_similar() to use matrix operations instead of python loops. Benchmark shows 5.6x speedup on 1000 signatures."}
{"id":"mycelium-6o3","title":"Extract matching/ package with MatchMode base class","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:03.640334-08:00","updated_at":"2026-01-09T06:11:16.554109-08:00","closed_at":"2026-01-09T06:11:16.554109-08:00","close_reason":"Created matching/ package with types.py (MatchMode, MatchType, MatchResult, WaveNorm) and normalization.py (normalize_wave_scores, fallback stats). Updated step_signatures.py to import from matching module.","dependencies":[{"issue_id":"mycelium-6o3","depends_on_id":"mycelium-ib7","type":"blocks","created_at":"2026-01-09T05:54:42.884013-08:00","created_by":"daemon"}]}
{"id":"mycelium-6wx","title":"Measure signature coverage: ideal is 100% step injection","description":"Best case scenario: a problem gets decomposed into N steps (e.g., 4), and each step maps to a unique signature that gets injected. This means only parameters flow through with minimal reasoning effort.\n\nQuestions to answer:\n- What % of steps currently get signature injection vs novel reasoning?\n- How many unique signatures does an average math problem touch?\n- What's the distribution of step counts per problem?\n- Are we converging toward full coverage as training progresses?\n\nSuccess metric: approaching 100% injection rate on trained problem types.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T16:30:25.024321-08:00","updated_at":"2026-01-08T16:30:25.024321-08:00"}
{"id":"mycelium-70a","title":"Measure average step count per math problem decomposition","description":"How many step signatures does the average math problem get decomposed into?\n\nCollect metrics:\n- Average number of steps per problem\n- Distribution (min/max/median)\n- Breakdown by problem difficulty level (L1-L5)\n- Breakdown by category (algebra, geometry, etc.)\n\nThis helps understand the granularity of our decomposition strategy.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T16:30:31.134714-08:00","updated_at":"2026-01-08T16:50:25.300507-08:00","closed_at":"2026-01-08T16:50:25.300507-08:00","close_reason":"Implemented step count analysis with level/category breakdown. Added StepCountAnalysis dataclass, compute_step_count_analysis() method, and report output sections. Problems now track level (1-5) and category (algebra, geometry, etc) with metrics including avg/min/max/median steps per problem, breakdown by level and category."}
{"id":"mycelium-74u","title":"Add connection pooling to Groq client","description":"Replace single httpx.AsyncClient with connection pool. Add configurable pool size and connection timeout. Helps with parallel LLM calls.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:52.017742-08:00","updated_at":"2026-01-09T07:47:59.48491-08:00","closed_at":"2026-01-09T07:47:59.48491-08:00","close_reason":"Added connection pooling with configurable max_connections, max_keepalive, connect_timeout. Pool is lazily initialized and reused across requests."}
{"id":"mycelium-7ar","title":"Add logging for step failures in council_v2.py","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-09T06:47:13.770132-08:00","updated_at":"2026-01-09T06:56:03.707551-08:00","closed_at":"2026-01-09T06:56:03.707551-08:00","close_reason":"Added logger.error calls with exc_info at two failure points: asyncio.gather exception handling and API call failures"}
{"id":"mycelium-7bp","title":"Race condition in ConnectionManager singleton","description":"Lines 123-135: _initialized check can allow double initialization under concurrent access","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:26.993544-08:00","updated_at":"2026-01-09T11:22:06.686355-08:00","closed_at":"2026-01-09T11:22:06.686355-08:00","close_reason":"Fixed: added lock to __init__"}
{"id":"mycelium-7dm","title":"Failed step error messages propagate to downstream context","description":"","status":"open","priority":3,"issue_type":"bug","created_at":"2026-01-09T06:47:15.666191-08:00","updated_at":"2026-01-09T06:47:15.666191-08:00"}
{"id":"mycelium-7e9","title":"LOW: Add test coverage for council_v2.py and db.py","description":"No test files exist for council_v2.py (main solver) or db.py. Add tests for: solve() with various problem types, error handling, synthesis strategy selection, database operations.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:57.558593-08:00","updated_at":"2026-01-09T08:34:39.200158-08:00","closed_at":"2026-01-09T08:34:39.200158-08:00","close_reason":"db.py tests already exist in test_mycelium_db.py"}
{"id":"mycelium-7f4","title":"Contextual boost formula too aggressive (0-2x range)","description":"step_signatures.py:get_contextual_boost() uses 'success_rate * 2.0' which gives a 0-2x range. A 0% success rate completely eliminates matches (0x boost). Consider a gentler formula like '0.5 + success_rate' (0.5-1.5x range) or '0.8 + success_rate * 0.4' (0.8-1.2x range) to avoid completely suppressing otherwise-good signatures.","status":"in_progress","priority":2,"issue_type":"bug","created_at":"2026-01-08T12:15:30.72846-08:00","updated_at":"2026-01-08T12:29:28.723754-08:00","close_reason":"Changed boost formula from success_rate*2.0 (0-2x) to 0.5+success_rate*1.0 (0.5-1.5x). Now 0% success gives 0.5x instead of 0x, preventing complete suppression."}
{"id":"mycelium-7hk","title":"[IMPROVE] Large step_signatures.py file (5000+ lines) should be split","description":"## Issue\nThe file `src/mycelium/step_signatures.py` is extremely large with over 5000 lines of code. This makes it difficult to maintain and understand.\n\n## Suggested Refactoring\nSplit into multiple focused modules:\n\n1. **step_signatures/models.py** - Data classes (StepSignature, StepExample, MatchResult, etc.)\n2. **step_signatures/db.py** - Core StepSignatureDB class with CRUD operations\n3. **step_signatures/matching.py** - find_similar, find_matches, find_by_resonance\n4. **step_signatures/clustering.py** - Cluster analysis, merge suggestions\n5. **step_signatures/wave.py** - Wave propagation, amplitude updates\n6. **step_signatures/sequences.py** - Step sequence tracking and contextual boosts\n7. **step_signatures/relationships.py** - Signature relationship management\n\nCurrent organization makes it hard to:\n- Find relevant code quickly\n- Understand the full API surface\n- Add targeted tests\n\n## Files Affected\n- src/mycelium/step_signatures.py (needs to be split)\n- tests/test_step_signatures.py (may need updates)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:51.538226-08:00","updated_at":"2026-01-09T10:46:56.282902-08:00","closed_at":"2026-01-09T10:46:56.282902-08:00","close_reason":"Completed via mycelium-8mu. Created: models.py, schema.py, utils.py, sequences.py, relationships.py, matching/, clustering/, wave_physics/. Reduced _legacy.py from 5581 to 3873 lines (-31%). StepSignatureDB remains in _legacy.py as it's tightly coupled."}
{"id":"mycelium-7oh","title":"Extract duplicate pack/unpack embedding functions","description":"pack_embedding() and unpack_embedding() are duplicated in:\n- signatures.py:29-37\n- step_signatures.py:782-793\n\nCreate shared/vectors.py with single implementation.\n~80 lines removed, 1 source of truth.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:34:39.644215-08:00","updated_at":"2026-01-09T10:55:13.995241-08:00","closed_at":"2026-01-09T10:55:13.995241-08:00","close_reason":"Already deduplicated. Canonical location: step_signatures/utils.py. Archive has copy for backwards compat.","dependencies":[{"issue_id":"mycelium-7oh","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.326525-08:00","created_by":"daemon"}]}
{"id":"mycelium-7yq","title":"IndexError in execution_plan_optimizer.py","description":"Line 450: json_str.split()[1] can fail if response doesnt contain backticks","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:26.140458-08:00","updated_at":"2026-01-09T11:22:06.543758-08:00","closed_at":"2026-01-09T11:22:06.543758-08:00","close_reason":"Fixed: safe list indexing"}
{"id":"mycelium-824","title":"suggest_cluster_merges O(n²) memory for large signature sets","description":"step_signatures.py:suggest_cluster_merges() computes full pairwise similarity matrix: similarity_matrix = centroids_normalized @ centroids_normalized.T. For n=10,000 signatures this creates 100M elements (~400MB float32). For n=100,000 it's 10B elements (~40GB). Consider chunked processing: compute similarity in blocks, or use approximate nearest neighbors (FAISS, Annoy) for large DBs.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-08T13:12:54.52444-08:00","updated_at":"2026-01-08T13:12:54.52444-08:00"}
{"id":"mycelium-833","title":"Prove it: V2 vs CQR benchmark comparison","description":"**Role**: Prove this wasn't just 'cool math'.\n\n**Objective**: Measure whether wave-based Mycelium actually improves learning speed and reuse.\n\n**Constraints**:\n- Use existing MATH dataset scripts\n- No subjective metrics\n- Must compare V2 vs CQR directly\n\n**Metrics to track**:\n1. **Time to signature reliability** - How many problems until a signature hits reliable status (3+ uses, 70%+ success)?\n2. **Reuse rate of learned methods** - What % of steps use injected methods vs solving fresh?\n3. **Error recovery after failure** - Does the system recover faster when a method fails?\n\n**Deliverables**:\n1. Metrics collection hooks in council_v2.py and signatures\n2. Comparison report with side-by-side plots and tables\n3. Recommendation: keep / modify / rollback\n\nThis is the 'show me the data' moment.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T08:49:15.381397-08:00","updated_at":"2026-01-08T09:16:54.062333-08:00","closed_at":"2026-01-08T09:16:54.062333-08:00","close_reason":"VERDICT: KEEP V2\n\nBenchmark Results (50 problems, algebra, Level 1-3):\n\nACCURACY:\n- V2: 82% \n- CQR: 72%\n- Delta: +10% improvement\n\nREUSE RATE:\n- V2: 9.6% of steps used injected methods\n- CQR: 0% (never reached reliable signatures)\n\nTIME TO RELIABILITY:\n- V2: ~9 problems for signature to become reliable\n- CQR: Never achieved reliability in this run\n\nERROR RECOVERY:\n- V2: 100% recovery after injection failure\n- CQR: 93% recovery after failure (but no injections)\n\nKEY FINDINGS:\n1. V2 learns faster - signatures become reliable within ~10 problems\n2. V2 accuracy is 10 percentage points higher\n3. Step-level signatures (V2) outperform problem-level (CQR)\n4. Wave-based approach enables actual method reuse\n\nRECOMMENDATION: Keep V2 as the primary solver."}
{"id":"mycelium-83j","title":"Implement confidence wave propagation","description":"Replace discrete success updates with confidence wave propagation across nearby signatures.\n\nOn successful step execution:\n- Boost amplitude of the matched signature\n- Propagate a decayed amplitude boost to nearby signatures: ΔA_neighbor = A_source × similarity × decay_factor\n- Ensure total injected energy is conserved or decays\n- Failures should cause localized damping, not global penalties\n\nDeliverables:\n- propagate_confidence() method\n- Updated record_usage() logic\n- Metrics logging to observe wave spread","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:47:28.524763-08:00","updated_at":"2026-01-08T08:57:00.692438-08:00","closed_at":"2026-01-08T08:57:00.692438-08:00","close_reason":"Implemented confidence wave propagation:\n- Added amplitude, phase, spread columns to step_signatures table\n- Created propagate_confidence() method with energy-conserving dynamics\n- On success: boost source amplitude, propagate decayed boost to neighbors\n- On failure: localized damping only (no global penalty)\n- Formula: ΔA_neighbor = source_amplitude × similarity × decay_factor × propagation_factor\n- Added wave metrics to get_stats() (avg/min/max amplitude, total energy, propagation events)\n- Tests verify: amplitudes boost on success, propagate to neighbors, damp on failure"}
{"id":"mycelium-84p","title":"Add FAISS/annoy for approximate nearest neighbor search","description":"","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-09T05:54:27.111486-08:00","updated_at":"2026-01-09T05:54:27.111486-08:00","dependencies":[{"issue_id":"mycelium-84p","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:55:10.118838-08:00","created_by":"daemon"}]}
{"id":"mycelium-84s","title":"Fix circular import: step_signatures \u003c-\u003e matching","description":"Circular import chain detected:\nstep_signatures → matching.normalization → matching.types → step_signatures\n\nActions:\n- Move types used by step_signatures OUT of matching.types\n- Use TYPE_CHECKING in matching.types to avoid importing step_signatures\n- Create test_no_circular_imports.py to detect regressions\n\nReference: step_signatures.py:78-95, matching/types.py, matching/__init__.py:12-20","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:35:01.645449-08:00","updated_at":"2026-01-09T10:54:47.720523-08:00","closed_at":"2026-01-09T10:54:47.720523-08:00","close_reason":"Circular import already fixed with TYPE_CHECKING guard in matching/types.py:10-11","dependencies":[{"issue_id":"mycelium-84s","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.465685-08:00","created_by":"daemon"}]}
{"id":"mycelium-8aq","title":"Extract prompt templates from council_v2.py to prompts/ module","description":"Move STEP_SOLVER_*, FINAL_SYNTHESIZER, INCREMENTAL_SYNTHESIZER templates to src/mycelium/prompts/. Create PromptTemplate dataclass with name, template, and variables fields.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:29.420914-08:00","updated_at":"2026-01-09T07:49:10.763173-08:00","closed_at":"2026-01-09T07:49:10.763173-08:00","close_reason":"Extracted prompts to registry, council_v2 now uses get_registry()"}
{"id":"mycelium-8ii","title":"Brainstorm: Frequency decomposition - high freq = parameters, low freq = math essence","description":"## Core Finding (REVISED from brainstorm)\n\n**Original hypothesis**: High-frequency = parameters, Low-frequency = essence\n**Actual finding**: HIGH-VARIANCE dimensions = essence, LOW-VARIANCE = noise\n\n### Key Results\n\n| Method | Within-group | Between-group | Gap | Discrimination Ratio |\n|--------|-------------|---------------|-----|---------------------|\n| Full embedding (384d) | 0.478 | 0.248 | 0.230 | 1.93x |\n| High-var dims (64d) | 0.508 | 0.132 | **0.376** | **3.85x** |\n| Low-var dims (64d) | 0.414 | 0.332 | 0.082 | 1.25x |\n\n**High-variance dimensions provide 2x better discrimination\\!**\n\n### Why This Works\n\nThe embedding model (all-MiniLM-L6-v2) learned to:\n- Use certain dimensions to encode 'what type of problem is this'\n- These dimensions VARY A LOT across different categories\n- But remain CONSISTENT within the same category\n\nExample - matching 'What is 18% of 350?':\n- Full embedding: percentage=0.59, linear_eq=0.22, addition=0.26\n- High-var only: percentage=**0.68**, linear_eq=-0.01, addition=0.04\n\nHigh-var projection nearly eliminates false matches\\!\n\n### Implementation Strategy\n\n1. Compute dimension variances from signature centroids (periodic)\n2. Extract 'essence dimensions' = top 20% highest variance (~76 dims)\n3. Two-stage matching:\n   - First pass: essence dims only (fast category detection)\n   - Second pass: full embedding for fine-grained matching\n4. Use essence similarity for wave propagation threshold\n\n### Why NOT FFT-based frequency decomposition\n\n- FFT treats embedding as 1D signal with arbitrary ordering\n- Variance-based approach respects the model's learned structure\n- Embedding dimensions are NOT ordered by frequency\n- High-variance dims = dims the model ACTUALLY USES to distinguish concepts\n\n### Connection to Wave Propagation (mycelium-cqr)\n\nCould enhance wave propagation by:\n- Propagating based on essence similarity (high-var dims)\n- Ignoring surface differences (low-var dims)\n- 'Same essence' = strong wave, 'different essence' = no wave","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T09:23:56.188416-08:00","updated_at":"2026-01-08T09:34:15.73846-08:00"}
{"id":"mycelium-8mu","title":"Split step_signatures.py into modular packages","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-09T05:53:54.127069-08:00","updated_at":"2026-01-09T10:35:01.717639-08:00","closed_at":"2026-01-09T10:35:01.717639-08:00","close_reason":"Reduced _legacy.py from 5,581 to 3,873 lines (-31%). Removed duplicate definitions for I/O schema classes, model classes (StepSignature, StepExample, PendingStepExample), and relationship/sequence functions. All now imported from extracted modules: schema.py, models.py, utils.py, sequences.py, relationships.py.","dependencies":[{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:54:55.013292-08:00","created_by":"daemon"},{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-11n","type":"blocks","created_at":"2026-01-09T05:55:01.540125-08:00","created_by":"daemon"},{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-ivm","type":"blocks","created_at":"2026-01-09T05:55:02.575695-08:00","created_by":"daemon"},{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-o1a","type":"blocks","created_at":"2026-01-09T05:55:03.720574-08:00","created_by":"daemon"}]}
{"id":"mycelium-948","title":"LOW: Pre-compile regexes in answer_norm.py","description":"Regexes in answer_norm.py are recompiled on every call. Use re.compile() at module level for hot paths to improve performance.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:00.576691-08:00","updated_at":"2026-01-09T08:32:43.327207-08:00","closed_at":"2026-01-09T08:32:43.327207-08:00","close_reason":"Pre-compiled 20 regex patterns at module level"}
{"id":"mycelium-98p","title":"Split step_signatures.py (5827 lines) into package","description":"CRITICAL: step_signatures.py is 5827 lines with mixed concerns.\n\nSplit into step_signatures/ package:\n- models.py (StepSignature, StepExample dataclasses)\n- schema.py (StepIOSchema, InputSpec, OutputSpec) \n- formulas.py (try_execute_formula, formula validation)\n- amplitude.py (amplitude control, wave effects)\n- matching.py (blended_similarity, find_matching_cluster)\n- db.py (StepSignatureDB with CRUD ops)\n- __init__.py (re-exports)\n\nTarget: \u003c1500 lines per file","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:34:32.114267-08:00","updated_at":"2026-01-09T08:51:38.925827-08:00","closed_at":"2026-01-09T08:51:38.925827-08:00","close_reason":"Split step_signatures.py (5827 lines) into step_signatures/ package with 6 submodules: schema.py, models.py, utils.py, relationships.py, sequences.py, _legacy.py. All 336 tests passing.","dependencies":[{"issue_id":"mycelium-98p","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.27974-08:00","created_by":"daemon"}]}
{"id":"mycelium-9hg","title":"How do we ensure step_signatures are unique and separate in embedding space","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T05:58:26.458238-08:00","updated_at":"2026-01-08T06:11:54.570941-08:00","closed_at":"2026-01-08T06:11:54.570941-08:00","close_reason":"Implemented embedding-based identity for step signatures. Replaced brittle hash fingerprints with UUID signature_id, made centroid NOT NULL as the identity basis."}
{"id":"mycelium-9r8","title":"CRITICAL: Replace bare except Exception with specific types","description":"step_signatures.py:451 and 4777 use bare 'except Exception' which swallows KeyboardInterrupt, SystemExit, MemoryError. Replace with specific types: (ValueError, TypeError, SyntaxError, ZeroDivisionError)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:21:44.593302-08:00","updated_at":"2026-01-09T08:26:48.277678-08:00","closed_at":"2026-01-09T08:26:48.277678-08:00","close_reason":"Replaced all bare 'except Exception:' with specific types: ValueError, TypeError, SyntaxError, ZeroDivisionError, KeyError, AttributeError. Also refactored connection.py to use try/finally pattern instead of except for cleanup."}
{"id":"mycelium-9tz","title":"Improve answer normalization for LaTeX","description":"Some false negatives in answer matching due to LaTeX formatting:\n\nExamples seen:\n- '$17' vs '17' (currency)  \n- '\\frac{1}{2}' vs '0.5' vs '1/2'\n- '\\sqrt{2}' vs '1.414...'\n\nCurrent normalize_answer() handles some cases but needs:\n1. More LaTeX patterns\n2. Numeric equivalence checking\n3. Fraction/decimal conversion","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T05:33:09.2229-08:00","updated_at":"2026-01-08T07:29:44.203376-08:00","closed_at":"2026-01-08T07:29:44.203376-08:00","close_reason":"Created unified answer_norm.py module with enhanced LaTeX handling including: fractions (\\frac{}{}), sqrt (\\sqrt{}, \\sqrt[n]{}), exponents (x^n, x^{}), boxed values, currency symbols, units, and numeric equivalence checking (1/2 == 0.5). Updated solver.py, council.py, and council_v2.py to use the new module."}
{"id":"mycelium-9xa","title":"DBSCAN epsilon allows lower cohesion than intended","description":"step_signatures.py:2265-2269 - eps=1-MIN_COHESION_FOR_NEW_CLUSTER=0.25 allows similarity 0.75 (VARIANT_THRESHOLD) not 0.85 (EXACT_MATCH_THRESHOLD). Adjust constant or formula to match intent.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:51.871791-08:00","updated_at":"2026-01-09T08:30:18.901639-08:00","closed_at":"2026-01-09T08:30:18.901639-08:00","close_reason":"Closed"}
{"id":"mycelium-a4i","title":"Use RLock instead of Lock in StepSignatureDB","description":"Double lock acquisition pattern in observe_pending() (step_signatures.py:2111-2174) risks deadlock if refactored. Replace threading.Lock with threading.RLock in StepSignatureDB.__init__.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:36.767316-08:00","updated_at":"2026-01-08T11:26:34.268762-08:00","closed_at":"2026-01-08T11:26:34.268762-08:00","close_reason":"Replaced threading.Lock with threading.RLock to allow re-entrant acquisition"}
{"id":"mycelium-acf","title":"PromptTemplate regex matches escaped braces incorrectly","description":"","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-09T06:47:12.242811-08:00","updated_at":"2026-01-09T06:56:02.811607-08:00","closed_at":"2026-01-09T06:56:02.811607-08:00","close_reason":"Fixed regex to use negative lookbehind/lookahead: r'(?\u003c\\!\\{)\\{(\\w+)\\}(?\\!\\})' - now correctly ignores {{escaped}} braces"}
{"id":"mycelium-aj5","title":"Paper: Write step-level vs problem-level reusability analysis","description":"## Task\nWrite the analysis section showing steps are more reusable than whole problems\n\n## Location\n~/Desktop/mycelium/paper.md - Section 5, \"Step-Level vs Problem-Level Reusability\"\n\n## Analysis to perform\n1. Query the signature DB for step reuse statistics\n2. Compare: How often do identical/similar steps appear across different problems?\n3. Compare: How often do identical/similar whole problems appear?\n4. Show that step-level matching has much higher hit rate\n\n## Data source\n```bash\nsqlite3 ~/Desktop/mycelium/results/mycelium.db\n```\n\nKey tables: step_signatures, step_examples, step_usage_log\n\n## Deliverable\nWrite 1-2 paragraphs with concrete numbers showing step reusability \u003e\u003e problem reusability","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:42:56.770555-08:00","updated_at":"2026-01-09T09:46:40.582771-08:00","closed_at":"2026-01-09T09:46:40.582771-08:00","close_reason":"Wrote 2 paragraphs with reuse stats: 70.5x step reuse ratio, 141 steps from 14 problems collapsed to 2 signatures, vs 0 problem-level reuse."}
{"id":"mycelium-arw","title":"Brainstorm: Should we partition the project into modules?","description":"Evaluate whether the project should be partitioned into separate modules/packages. Questions to explore:\n\n1. Current structure analysis - are we already modular?\n2. What are the natural boundaries in the codebase?\n3. Benefits: separation of concerns, independent testing, clearer APIs\n4. Costs: import complexity, versioning, dependency management\n5. Candidates for extraction: step_signatures, mcts, council, planner\n\nThis is a brainstorming/architecture discussion issue.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T09:07:18.357153-08:00","updated_at":"2026-01-08T09:07:26.692443-08:00"}
{"id":"mycelium-aur","title":"MEDIUM: Add logging to answer_norm.py silent exceptions","description":"answer_norm.py:86-89, 135-138 have bare 'except ValueError: pass' blocks. Conversion failures silently ignored. Add debug logging for troubleshooting.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:51.604366-08:00","updated_at":"2026-01-09T08:32:43.381566-08:00","closed_at":"2026-01-09T08:32:43.381566-08:00","close_reason":"Added debug logging to ValueError handlers in _try_parse_numeric and _try_as_fraction"}
{"id":"mycelium-bb2","title":"Validate wave+essence combo on larger dataset","description":"","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-01-08T12:24:01.352783-08:00","updated_at":"2026-01-08T12:27:00.04154-08:00"}
{"id":"mycelium-bbp","title":"MEDIUM: Validate step IDs in planner.py","description":"planner.py:232-236 - Step ID extraction doesn't validate format. Silent fallback to 'unnamed_N' could cause downstream issues. Validate against pattern (alphanumeric, underscores).","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:54.727695-08:00","updated_at":"2026-01-09T08:31:30.49987-08:00","closed_at":"2026-01-09T08:31:30.49987-08:00","close_reason":"Added step ID validation - sanitizes invalid characters"}
{"id":"mycelium-bdt","title":"Expand training to more MATH categories and levels","description":"Currently only training on L1-3 algebra.\n\nExpand to:\n- More categories: geometry, number_theory, counting_probability, prealgebra, intermediate_algebra\n- Harder levels: L4, L5\n\nThis will:\n1. Build a richer signature library\n2. Test decomposition on harder problems\n3. See if cross-category patterns emerge","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T05:32:56.599776-08:00","updated_at":"2026-01-08T11:44:03.167035-08:00","closed_at":"2026-01-08T11:44:03.167035-08:00","close_reason":"Updated evaluate_v2.py and train_math.py to support:\n- Multiple categories (via comma-separated list or 'all')\n- Min/max level filtering (L1-5)\n- Per-category limits\n- Category breakdown in results\n\nNew features:\n- --category all / --category 'algebra,geometry,number_theory'\n- --min-level and --max-level for difficulty filtering\n- --limit-per-category for balanced sampling\n- Results include by_category metrics\n\nCreated run_expanded_eval.sh helper script for running comprehensive evaluations across all categories and difficulty levels.","dependencies":[{"issue_id":"mycelium-bdt","depends_on_id":"mycelium-mpg","type":"blocks","created_at":"2026-01-08T05:33:18.519883-08:00","created_by":"daemon"}]}
{"id":"mycelium-bey","title":"Fragile timezone handling in decay_unused_signatures","description":"decay_unused_signatures() strips timezone info from timestamps and compares against datetime.utcnow(). If last_used_at is stored in local time instead of UTC, decay calculations will be wrong. Consider: (1) Standardizing all timestamps to UTC with 'Z' suffix, (2) Using timezone-aware datetime comparisons, or (3) Adding validation that timestamps are UTC.","status":"open","priority":3,"issue_type":"bug","created_at":"2026-01-08T12:15:57.182868-08:00","updated_at":"2026-01-08T12:15:57.182868-08:00"}
{"id":"mycelium-bkz","title":"Superposition of Methods (Soft Execution)","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:54:41.22211-08:00","updated_at":"2026-01-08T08:54:48.605031-08:00","closed_at":"2026-01-08T08:54:48.605031-08:00","close_reason":"Implemented soft execution with weighted method superposition. Features: SuperpositionResult dataclass, softmax-weighted methods, entropy tracking, high-confidence collapse fallback, amplitude updates based on execution success. Tested with unit tests."}
{"id":"mycelium-bod","title":"Add structured logging to mcts.py","description":"Add logging for MCTS tree search iterations, node selection, and strategy evaluation.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:18.612936-08:00","updated_at":"2026-01-09T07:48:38.750517-08:00","closed_at":"2026-01-09T07:48:38.750517-08:00","close_reason":"Added import, logger, and logging for MCTS search iterations, simulation, strategy generation"}
{"id":"mycelium-bt0","title":"Document: How problem decomposition maps to step signatures","description":"Investigate and document the current decomposition flow:\n\n1. How does the Planner decompose problems into DAG steps?\n2. How are steps embedded and matched to signature clusters?\n3. What determines when a step joins an existing cluster vs creates a new one?\n4. How does the injection decision get made (reliable threshold)?\n\nGoal: Understand and document the current approach to identify improvement opportunities.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T08:18:14.057531-08:00","updated_at":"2026-01-08T08:25:21.576307-08:00","closed_at":"2026-01-08T08:25:21.576307-08:00","close_reason":"Analysis complete. Created docs/DECOMPOSITION_WAVE_ANALYSIS.md mapping the decomposition flow to wave function concepts. Identified key improvements: soft matching (superposition of methods), step sequences (entanglement), signature decay (decoherence), and multiple decompositions."}
{"id":"mycelium-bt8","title":"Race condition in centroid update - non-atomic operations","description":"step_signatures.py:1193-1230 - add_example_to_cluster() reads centroid, computes new value in memory, writes back. Not atomic. Two concurrent calls can lose an example. Fix with SQL-based computation or row-level locks.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:43.686028-08:00","updated_at":"2026-01-08T11:26:34.331746-08:00","closed_at":"2026-01-08T11:26:34.331746-08:00","close_reason":"Added isolation_level=IMMEDIATE to add_example_to_cluster and merge_signatures for atomic centroid updates"}
{"id":"mycelium-c2u","title":"Improve planner cycle detection and precision handling","description":"Minor improvements from code review: (1) Cycle detection traverses dependencies backwards - works but confusing, consider reversing for clarity. (2) Only reports first cycle found - could report all independent cycles. (3) answer_norm percent conversion uses .10f precision which could truncate extreme values like 0.0001%.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T13:35:49.148277-08:00","updated_at":"2026-01-08T13:37:39.769687-08:00","closed_at":"2026-01-08T13:37:39.769687-08:00","close_reason":"Fixed: forward cycle traversal, reports all cycle steps, full float precision with repr()"}
{"id":"mycelium-chv","title":"Implement full MCTS with decomposition execution","description":"Current MCTS implementation:\n- Creates nodes with priors from signatures\n- Returns prior score without full tree search\n\nFull implementation would:\n1. Generate multiple decomposition strategies\n2. Actually execute each strategy (simulation)\n3. Backpropagate success/failure\n4. Select best strategy based on UCB1\n\nThis is the 'learning to decompose' core idea - MCTS explores which decomposition strategies work best.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T05:33:02.449954-08:00","updated_at":"2026-01-08T07:01:53.749096-08:00","closed_at":"2026-01-08T07:01:53.749096-08:00","close_reason":"Implemented full MCTS with decomposition execution:\n- MCTSDecomposer.simulate() now actually executes decompositions via LLM calls\n- Multiple decomposition strategies: standard, direct, simplified, chunked\n- Reward calculation based on execution success (answer presence, no errors, step completion)\n- Result caching to avoid redundant executions\n- Council integration uses simulation results directly, avoiding re-execution\n- DecompositionChoice now includes simulation_result field"}
{"id":"mycelium-clc","title":"Improve embedding-based sub-problem clustering","description":"Focus on using embeddings to better match and group sub-problems.\n\nCurrent state:\n- Signatures have embeddings for semantic matching\n- Need to improve how we cluster similar sub-problems across different problem solves\n\nGoals:\n1. Better similarity thresholds for grouping related sub-problems\n2. Clustering algorithm to find canonical sub-problem types\n3. Track which sub-problems are variations of the same underlying pattern\n4. Use clusters to inform MCTS - if we've solved similar sub-problems before, reuse that knowledge\n\nThis replaces hash-based fingerprinting with pure embedding-based identity.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-08T06:27:45.979346-08:00","updated_at":"2026-01-08T07:03:01.353682-08:00","closed_at":"2026-01-08T07:03:01.353682-08:00","close_reason":"Implemented embedding-based sub-problem clustering improvements: \n- Added canonical sub-problem type tracking with cluster hierarchy (is_canonical, canonical_parent_id, variant_count)\n- Implemented variation detection using embedding distance analysis (MatchType.EXACT/VARIANT/NEW, match_with_variation_detection)\n- Added cluster cohesion metrics tracked incrementally as examples are added\n- Added cluster merge suggestions via suggest_cluster_merges() and merge_signatures()\n- Added DBSCAN clustering methods for discovering natural cluster structure\n- Added comprehensive test suite (24 tests in test_step_signatures.py)"}
{"id":"mycelium-cq5","title":"Paper: Ablation study on reliability threshold","description":"## Task\nRun ablation study on the reliability threshold (3 uses, 70% success) and write up findings\n\n## Location\n~/Desktop/mycelium/paper.md - Section 5, \"Reliability Threshold Ablation\"\n\n## Ablation conditions\n1. No threshold (inject all signatures immediately)\n2. Uses only (3+ uses, any success rate)\n3. Success only (any uses, 70%+ success)\n4. Full threshold (3+ uses AND 70%+ success) - current default\n\n## How to run\nModify the reliability check in step_signatures.py or run with different configs\n\n## Metrics to measure\n- Accuracy on held-out problems\n- False injection rate (injected bad methods)\n- Coverage (% of steps with injection)\n\n## Deliverable\n- Table comparing ablation conditions\n- 1-2 paragraphs explaining why the threshold matters","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-01-09T09:43:00.938661-08:00","updated_at":"2026-01-09T09:46:25.351383-08:00"}
{"id":"mycelium-cqe","title":"Add energy normalization to prevent runaway amplitude","description":"Implement energy normalization to prevent unbounded amplitude growth:\n\nOptions:\n1. Hard cap: amplitude = min(amplitude, AMP_MAX) where AMP_MAX = 0.35-0.5\n2. Soft cap: amplitude = AMP_MAX * tanh(amplitude / AMP_MAX)\n\nAlso track:\n- field_energy = Σ amplitude (already done)\n- energy_delta_per_problem\n\nAcceptance: energy doesn't grow without bound across runs.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T09:41:28.572656-08:00","updated_at":"2026-01-08T09:47:45.079029-08:00","closed_at":"2026-01-08T09:47:45.079029-08:00","close_reason":"Implemented energy normalization with soft cap (tanh) and field normalization method. Tests confirm energy doesn't grow unbounded."}
{"id":"mycelium-cqr","title":"Brainstorm: Incorporate mathematical waves into mycelium","description":"Brainstorm: Deep integration of mathematical WAVES into mycelium\n\nThis is an exploratory issue to brainstorm how wave mathematics could enhance the system.\n\n## Initial Ideas to Explore\n\n### 1. Embedding Space as Wave Interference\n- Treat signature embeddings as wave functions in high-dimensional space\n- Similarity matching becomes constructive/destructive interference\n- Clusters form at interference maxima (standing waves)\n\n### 2. Fourier Analysis of Problem Structure\n- Decompose problems into frequency components\n- Low-frequency = core concept, high-frequency = surface details\n- Filter out noise, identify fundamental patterns\n\n### 3. Wave Propagation for Knowledge Transfer\n- When a signature succeeds, 'ripple' confidence to similar signatures\n- Damped waves: closer signatures get stronger signal\n- Could replace/enhance the current variant relationship system\n\n### 4. Resonance for Pattern Matching\n- Signatures 'resonate' with problems at characteristic frequencies\n- Strong resonance = good match, weak = poor match\n- Natural frequency could encode problem difficulty/complexity\n\n### 5. Superposition of Solution Methods\n- Multiple method templates as superposition of states\n- 'Collapse' to specific method based on problem context\n- Quantum-inspired exploration vs exploitation\n\n### 6. Wavelet Transform for Multi-scale Decomposition\n- Analyze problems at multiple scales simultaneously\n- Local details + global structure\n- Natural fit for hierarchical problem decomposition\n\n### 7. Phase as Temporal/Sequential Information\n- Encode step ordering as phase relationships\n- Dependencies become phase constraints\n- DAG execution order emerges from phase alignment\n\n## Questions to Answer\n- Which wave concepts map most naturally to our domain?\n- What mathematical framework (Fourier, wavelets, etc)?\n- Where would waves add value vs being over-engineering?\n- Are there existing papers on wave-based ML/reasoning?\n\n## Next Steps\n- Research existing work on wave-based representations\n- Prototype one concept (maybe embedding interference?)\n- Evaluate if the added complexity is worth it","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T07:43:12.604723-08:00","updated_at":"2026-01-08T11:19:58.015797-08:00","closed_at":"2026-01-08T11:19:58.015797-08:00","close_reason":"Wave mathematics fully implemented: resonance scoring, amplitude/phase/spread params, interference-based matching, essence dimensions, wave propagation on success/failure. Brainstorm goals achieved."}
{"id":"mycelium-cqs","title":"Multiple decompositions (superposition of solution paths)","description":"Generate N different problem decompositions, solve all in parallel, return the one with highest confidence.\n\nFrom wave function analysis: Instead of collapsing to single decomposition immediately, maintain superposition of possible solution paths.\n\nImplementation:\n1. Add decompose_superposition(n=3) to Planner\n2. Use higher temperature for variation\n3. Add solve_superposition() that runs all paths\n4. Score results by confidence/consistency\n5. Consider: expensive but may help hard problems","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:34:21.542519-08:00","updated_at":"2026-01-08T08:34:21.542519-08:00"}
{"id":"mycelium-cqv","title":"Replace raw interference with normalized scoring","description":"Per ablation findings: raw wave scores vanish, causing 0% reuse.\n\nImplementation:\n1. In find_by_resonance: compute raw interference scores for all candidates\n2. Normalize within that candidate set using max-abs scaling:\n   s_norm = s_raw / (max(|s_raw|) + eps)\n\nThis prevents vanishing and doesn't assume normality.\n\nOptional secondary: z-score with tanh squash, but start with max-abs for stability.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T09:44:31.53466-08:00","updated_at":"2026-01-08T09:49:59.65573-08:00","closed_at":"2026-01-08T09:49:59.65573-08:00","close_reason":"Implemented max-abs normalization in compute_resonance(). See commit e723763."}
{"id":"mycelium-ctz","title":"Server disconnection errors during parallel LLM calls","description":"When running 8 parallel workers, some problems fail with 'Server disconnected without sending a response'. Seen on problems 67-68 in 100-problem run. May need retry logic or rate limiting.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T14:03:28.51142-08:00","updated_at":"2026-01-09T08:30:18.949826-08:00","closed_at":"2026-01-09T08:30:18.949826-08:00","close_reason":"Closed"}
{"id":"mycelium-d0b","title":"Add comprehensive integration tests for matching pipeline","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:18.249476-08:00","updated_at":"2026-01-09T10:50:40.847089-08:00","closed_at":"2026-01-09T10:50:40.847089-08:00","close_reason":"Added 21 tests for matching module: MatchType, MatchResult, normalize_wave_scores, fallback stats, MatchMode. Also added test schema isolation.","dependencies":[{"issue_id":"mycelium-d0b","depends_on_id":"mycelium-8mu","type":"blocks","created_at":"2026-01-09T05:55:04.533609-08:00","created_by":"daemon"},{"issue_id":"mycelium-d0b","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:55:11.111149-08:00","created_by":"daemon"}]}
{"id":"mycelium-ddx","title":"Implement Essence Subspace - high-variance dimension selection","description":"Identify and persist the embedding dimensions that carry the most semantic discrimination between step signatures. Compute per-dimension variance from centroids, select top 20% (configurable), store as essence_dims in signature DB metadata. Recompute only when DB grows significantly (+20% signatures).","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T10:55:30.879165-08:00","updated_at":"2026-01-08T11:09:19.424358-08:00","closed_at":"2026-01-08T11:09:19.424358-08:00","close_reason":"Implemented essence-weighted interference scoring: final_score = w1*cosine_essence + w2*interference_norm with mandatory max-abs normalization. Added tests."}
{"id":"mycelium-dpo","title":"Non-deterministic exploration in should_inject() cold-start","description":"StepSignature.should_inject() uses np.random.random() for cold-start exploration, making results non-reproducible. This can cause flaky tests and unpredictable behavior. Options: (1) Accept a seed parameter, (2) Use hash(signature.id) % 100 \u003c exploration_rate*100 for deterministic exploration, (3) Document the randomness and accept it for production use.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-08T13:13:01.896583-08:00","updated_at":"2026-01-08T13:13:01.896583-08:00"}
{"id":"mycelium-dt9","title":"Paper: Add architecture diagram figure","description":"## Task\nCreate an architecture diagram for the paper\n\n## Location\n~/Desktop/mycelium/paper.md - Add as Figure 1 in Section 3\n\n## Diagram should show\n1. Problem input\n2. Decomposition into DAG\n3. Signature DB lookup (with cosine similarity)\n4. Hybrid execution (formula/procedure/LLM branches)\n5. Final merge/synthesis\n6. Learning loop (new signatures stored)\n\n## Reference\nThe ASCII diagram in ~/Desktop/mycelium/README.md can be adapted\n\n## Format\n- ASCII art for markdown, or\n- Create proper figure and reference it\n\n## Deliverable\nAdd figure to paper.md with caption explaining the flow","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:43:01.801603-08:00","updated_at":"2026-01-09T09:47:48.983733-08:00","closed_at":"2026-01-09T09:47:48.983733-08:00","close_reason":"Added Figure 1 architecture diagram to paper.md Section 3"}
{"id":"mycelium-dtj","title":"Migrate execution_plan_optimizer.py to data_layer","description":"Replace 1 direct sqlite3.connect call with data_layer.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:00:32.653375-08:00","updated_at":"2026-01-09T10:16:28.743373-08:00","closed_at":"2026-01-09T10:16:28.743373-08:00","close_reason":"Completed - all SQLite removed from codebase"}
{"id":"mycelium-eal","title":"Silent failures in wave propagation","description":"step_signatures.py:1979-1997 - _propagate_wave() returns empty dict when get_signature_by_id() returns None. Callers (like record_usage at line 1856) don't know propagation failed. Add logging or raise explicit exceptions.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:40.206731-08:00","updated_at":"2026-01-08T11:26:34.39181-08:00","closed_at":"2026-01-08T11:26:34.39181-08:00","close_reason":"Added logger.warning and error key to propagation_info when source signature not found or has no centroid"}
{"id":"mycelium-edd","title":"Zero centroid not validated in compute_interference_score","description":"step_signatures.py:557-580 - compute_interference_score() checks for None centroid but not zero vector. Add validation: if np.allclose(signature.centroid, 0): return 0.0","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:48.491494-08:00","updated_at":"2026-01-08T12:22:19.592697-08:00","closed_at":"2026-01-08T12:22:19.592697-08:00","close_reason":"Fixed - added np.allclose(centroid, 0) check in both compute_interference_score and compute_interference_scores_batch. Added 3 tests."}
{"id":"mycelium-eg1","title":"Unsafe JSON response parsing in client.py","description":"Line 159: No validation that API response has expected structure - can cause KeyError/IndexError","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:25.210434-08:00","updated_at":"2026-01-09T11:22:06.131211-08:00","closed_at":"2026-01-09T11:22:06.131211-08:00","close_reason":"Fixed: response structure validation"}
{"id":"mycelium-ern","title":"Migrate db.py (MyceliumDB) to use data_layer","description":"Replace 2 direct sqlite3.connect calls in _init_unified_db and _get_connection with data_layer.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T09:00:31.051065-08:00","updated_at":"2026-01-09T09:02:34.458691-08:00","closed_at":"2026-01-09T09:02:34.458691-08:00","close_reason":"Updated MyceliumDB to use data_layer. Set _use_data_layer=True, _db=_data_layer. Replaced sqlite3.connect with _get_connection()."}
{"id":"mycelium-f9g","title":"Split mcts.py into mcts/ package","description":"mcts.py is 1016 lines with 3 classes + prompts.\n\nSplit into mcts/ package:\n- core.py: MCTSNode, MCTS tree logic\n- decomposer.py: MCTSDecomposer\n- cache.py: LRUCache (could also move to shared/)\n- prompts.py: DIRECT_SOLVE prompt constant\n\nLower priority than step_signatures split.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T08:35:15.563709-08:00","updated_at":"2026-01-09T08:35:15.563709-08:00","dependencies":[{"issue_id":"mycelium-f9g","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.512385-08:00","created_by":"daemon"}]}
{"id":"mycelium-fb2","title":"Lift-gated injection with exploration bootstrapping","description":"## Summary\nAdded exploration rate to `should_inject()` to solve the cold-start problem for lift-gated injection.\n\n## Problem\nThe lift-gated injection system had a chicken-and-egg problem:\n- Signatures couldn't accumulate injection data because `should_inject()` required `min_samples_per_arm=3` in BOTH the injected AND non-injected arms\n- Since injections never happened, `injected_uses` stayed at 0, and the lift gate never triggered\n- Result: 0% injection rate, no lift data collected\n\n## Solution\nAdded `exploration_rate` parameter (default 0.3) to `StepSignature.should_inject()`:\n- During cold-start (insufficient data in both arms), randomly inject with probability `exploration_rate`\n- This allows the system to gather data on both arms to make informed lift decisions\n- Once enough data is collected (3+ samples per arm), the lift gate takes over\n\n## Results\nBefore fix:\n- Injection rate: 0%\n- No lift data collected\n\nAfter fix:\n- Training injection rate: 44.4%\n- Eval injection rate: 25%\n- **Overall lift: +45.7%** (injected: 100% success, non-injected: 54.3% success)\n- Wave propagation effectiveness: +21.2%\n\n## Files Changed\n- `src/mycelium/step_signatures.py`: Added `exploration_rate` parameter to `should_inject()`\n\n## Commit\n0a59088 feat: Add exploration rate to lift-gated injection for cold-start","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:22:10.794625-08:00","updated_at":"2026-01-08T13:22:15.881966-08:00","closed_at":"2026-01-08T13:22:15.881966-08:00","close_reason":"Implemented and merged in commit 0a59088"}
{"id":"mycelium-fx8","title":"Measure lift-gated injection effectiveness","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T12:24:09.269174-08:00","updated_at":"2026-01-08T12:31:00.475563-08:00","closed_at":"2026-01-08T12:31:00.475563-08:00","close_reason":"Added scripts/analyze_lift.py for measuring lift-gated injection effectiveness. Also added lift metrics to get_stats() in step_signatures.py. Run 'python scripts/analyze_lift.py --details' to see lift report."}
{"id":"mycelium-g9o","title":"Add error aggregation to asyncio.gather in council_v2.py","description":"Current asyncio.gather calls crash on first error. Add return_exceptions=True and aggregate errors for better debugging. Affects _execute_level() and parallel step execution.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:32.051607-08:00","updated_at":"2026-01-09T07:46:05.805266-08:00","closed_at":"2026-01-09T07:46:05.805266-08:00","close_reason":"Added return_exceptions=True and error aggregation to council_v2.py (errors field on CouncilResultV2) and solver.py batch solver"}
{"id":"mycelium-h25","title":"Implement signature decay (decoherence)","description":"Old signatures that haven't been used should decay in confidence. This prevents stale patterns from being injected.\n\nFrom wave function analysis: 'Decoherence' - interaction with environment causes loss of quantum coherence over time.\n\nImplementation:\n1. Add decay_unused_signatures() method\n2. Use exponential decay based on time since last_used_at\n3. Consider using EMA for centroid updates (alpha=0.1)\n4. Run decay as background task or on each solve","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:34:09.319935-08:00","updated_at":"2026-01-08T12:10:18.069861-08:00","closed_at":"2026-01-08T12:10:18.069861-08:00","close_reason":"Implemented decay_unused_signatures() with exponential decay based on time since last use. Configurable half-life (30 days) and min amplitude floor (0.05). Tests: TestSignatureDecay (5 tests)"}
{"id":"mycelium-ib7","title":"Extract shared/similarity.py - deduplicate cosine functions","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:53:54.825428-08:00","updated_at":"2026-01-09T06:05:02.586792-08:00","closed_at":"2026-01-09T06:05:02.586792-08:00","close_reason":"Created shared/similarity.py with cosine_similarity, cosine_similarity_batch, and cosine_similarity_batch_essence. Updated step_signatures.py and signatures.py to import from shared module. All essence similarity tests pass."}
{"id":"mycelium-iiw","title":"Add pluggable wave normalization to pipeline_runner","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:29:58.220623-08:00","updated_at":"2026-01-08T13:03:38.661395-08:00","closed_at":"2026-01-08T13:03:38.661395-08:00","close_reason":"Added --wave-norm flag to pipeline_runner.py. Supports maxabs (default) and zscore_tanh."}
{"id":"mycelium-ivm","title":"Extract clustering/ module for DBSCAN utilities","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:06.058589-08:00","updated_at":"2026-01-09T06:25:42.352808-08:00","closed_at":"2026-01-09T06:25:42.352808-08:00","close_reason":"Created clustering/ package with types.py (EmbeddingCluster, ClusteringResult) and utils.py (compute_cohesion, compute_silhouette, etc). Updated step_signatures.py to import from clustering module.","dependencies":[{"issue_id":"mycelium-ivm","depends_on_id":"mycelium-ib7","type":"blocks","created_at":"2026-01-09T05:54:45.553178-08:00","created_by":"daemon"}]}
{"id":"mycelium-iz2","title":"Add parallel worker support to pipeline_runner.py","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T14:03:21.789848-08:00","updated_at":"2026-01-08T14:08:26.917274-08:00","closed_at":"2026-01-08T14:08:26.917274-08:00","close_reason":"Implemented parallel worker support in pipeline_runner.py with --workers flag"}
{"id":"mycelium-j3x","title":"SQL injection vulnerability in connection.py","description":"Line 238: DB_SCHEMA env var directly interpolated into SQL without validation","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:15.93194-08:00","updated_at":"2026-01-09T11:21:45.875075-08:00","closed_at":"2026-01-09T11:21:45.875075-08:00","close_reason":"Fixed: schema name validation and identifier quoting"}
{"id":"mycelium-jit","title":"Migrate step_signatures helper modules to data_layer","description":"relationships.py (4 calls), sequences.py (1 call), _legacy.py (7 calls) - migrate to use data_layer.db.connection()","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:00:31.865025-08:00","updated_at":"2026-01-09T10:16:28.798171-08:00","closed_at":"2026-01-09T10:16:28.798171-08:00","close_reason":"Completed - all SQLite removed from codebase"}
{"id":"mycelium-jmi","title":"Add structured logging throughout codebase","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:28.437679-08:00","updated_at":"2026-01-09T06:36:37.023577-08:00","closed_at":"2026-01-09T06:36:37.023577-08:00","close_reason":"Added logging to client, embedder, solver, council_v2"}
{"id":"mycelium-jp2","title":"Design final solver execution strategy","description":"Open question: Does the final synthesis solver run multiple times to merge each sub-problem, or once at the end?\n\nOptions:\n1. **Once at end** - Collect all step results, synthesize final answer in one pass\n2. **Incremental merges** - Merge pairs/groups of steps progressively up to final\n3. **Problem-dependent** - Most likely correct answer. Strategy depends on:\n   - DAG structure (sequential vs parallel steps)\n   - Step dependencies (some steps feed into others)\n   - Problem complexity (simple = one pass, complex = incremental)\n\nNeed to investigate what works best. Likely problem-dependent with heuristics to choose strategy.\n\nRelated: mycelium-ksi (Add final synthesis solver)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T06:59:50.093652-08:00","updated_at":"2026-01-08T11:46:19.950592-08:00","closed_at":"2026-01-08T11:46:19.950592-08:00","close_reason":"Design decision: Problem-dependent strategy with DAG-aware heuristics. Default once-at-end, incremental merge for deep trees (depth\u003e=4, width\u003e=3). Steps with multiple deps are natural synthesis points."}
{"id":"mycelium-k6g","title":"HIGH: Add docstrings to council_v2.py public methods","description":"Critical methods lack docstrings: _get_similarity() (line 601), _analyze_dag() (line 624), _select_synthesis_strategy() (line 650). Add comprehensive docstrings with Args, Returns, Raises.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:47.908198-08:00","updated_at":"2026-01-09T08:26:00.365795-08:00","closed_at":"2026-01-09T08:26:00.365795-08:00","close_reason":"Closed"}
{"id":"mycelium-khk","title":"DB method return types wrong for PostgreSQL","description":"_execute() and _executemany() return sqlite3.Cursor but actually return psycopg2 cursor for PostgreSQL. Should be Any or a Cursor protocol.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:33:00.287411-08:00","updated_at":"2026-01-09T10:16:40.538162-08:00","closed_at":"2026-01-09T10:16:40.538162-08:00","close_reason":"Fixed - removed SQLite type hints, now using Any for cursor types"}
{"id":"mycelium-ksi","title":"Add final synthesis solver","description":"Currently each step gets solved independently, but there's no explicit 'combine all the pieces' step at the end.\n\nNeed a final synthesis solver that:\n1. Takes all step results + injected methods\n2. Produces coherent final answer\n3. Handles cases where steps have dependencies\n4. Verifies the answer makes sense given the original problem\n\nThis is the missing piece between 'solve all steps' and 'return answer'.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-08T06:38:34.82638-08:00","updated_at":"2026-01-08T11:52:45.828687-08:00","closed_at":"2026-01-08T11:52:45.828687-08:00","close_reason":"Implemented DAG-aware synthesis with two strategies: once-at-end (default) and incremental (for depth\u003e=4, width\u003e=3). Uses synthesis points (steps with multiple deps) for incremental merges. Added 11 tests.","dependencies":[{"issue_id":"mycelium-ksi","depends_on_id":"mycelium-jp2","type":"blocks","created_at":"2026-01-08T07:00:11.822804-08:00","created_by":"daemon"}]}
{"id":"mycelium-l8j","title":"Unbounded MCTS cache growth causes memory leak","description":"mcts.py:569-572 - _plan_cache and _sim_cache grow unboundedly. Caches only cleared at start of find_best_decomposition(). Long-running processes accumulate unlimited entries. Implement bounded LRU cache with functools.lru_cache or cachetools.LRUCache.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:37.694441-08:00","updated_at":"2026-01-08T11:52:39.386468-08:00","closed_at":"2026-01-08T11:52:39.386468-08:00","close_reason":"Implemented LRUCache class in mcts.py with bounded maxsize (256 for plans, 512 for simulations). Caches now evict least-recently-used entries when full, preventing unbounded memory growth."}
{"id":"mycelium-laf","title":"Add end-to-end integration tests","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:24:54.241384-08:00","updated_at":"2026-01-09T06:48:20.62586-08:00","closed_at":"2026-01-09T06:48:20.62586-08:00","close_reason":"Added comprehensive integration tests in tests/test_integration.py with 23 tests covering full problem-solving workflow, signature learning, DAG execution, and error handling. Also fixed several bugs found during testing: missing STEP_SOLVER_PLAIN_WITH_OUTPUT_FORMAT prompt, missing SuperpositionResult fields in StepResultV2, incorrect _fallback_stats global references, and missing row_factory for SQLite connections."}
{"id":"mycelium-mf3","title":"Archive V1 code (council.py, signatures.py)","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T12:23:46.757811-08:00","updated_at":"2026-01-08T13:07:54.689376-08:00","closed_at":"2026-01-08T13:07:54.689376-08:00","close_reason":"Archived council.py to _archive/council_v1.py with deprecation shim. Imports still work with warning."}
{"id":"mycelium-mjg","title":"LOW: Replace magic numbers with constants","description":"council_v2.py has hardcoded values like problem[:200]. Define as module constants: MAX_PARENT_PROBLEM_LENGTH = 200, etc.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:16.173618-08:00","updated_at":"2026-01-09T08:31:30.552368-08:00","closed_at":"2026-01-09T08:31:30.552368-08:00","close_reason":"Replaced magic numbers with MAX_STEP_TASK_LOG_LENGTH and MAX_PARENT_PROBLEM_LENGTH constants"}
{"id":"mycelium-mpg","title":"Create train/test evaluation script","description":"Need to measure if signatures actually help:\n\n1. Train on subset of problems (build signature library)\n2. Test on held-out problems\n3. Compare: accuracy with signatures vs without\n4. Track: how often method injection fires\n\nMetrics to capture:\n- Baseline accuracy (no signatures)  \n- With signatures accuracy\n- % of test problems that matched a signature\n- Success rate when signature was injected","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T05:32:49.383522-08:00","updated_at":"2026-01-08T07:36:57.192507-08:00","closed_at":"2026-01-08T07:36:57.192507-08:00","close_reason":"Evaluation script (scripts/evaluate_v2.py) is complete and functional. It supports train/test splitting, baseline comparison, signature effectiveness tracking, and detailed metrics. Test runs verified working.","dependencies":[{"issue_id":"mycelium-mpg","depends_on_id":"mycelium-ulk","type":"blocks","created_at":"2026-01-08T05:33:18.390854-08:00","created_by":"daemon"}]}
{"id":"mycelium-n9v","title":"Add unit tests for wave_physics module","description":"Write pytest tests for compute_interference_score, compute_resonance, frequency functions. Test edge cases: zero centroids, empty signatures, extreme amplitudes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:40.882549-08:00","updated_at":"2026-01-09T07:55:40.36301-08:00","closed_at":"2026-01-09T07:55:40.36301-08:00","close_reason":"Created tests/test_wave_physics.py with 37 tests covering interference and resonance functions"}
{"id":"mycelium-nke","title":"Remove deprecated get_method_superposition_legacy()","description":"step_signatures.py:1386-1400 - Deprecated method still present. Either remove completely or add warnings.warn() deprecation warning.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:10:49.606643-08:00","updated_at":"2026-01-08T12:11:55.371717-08:00","closed_at":"2026-01-08T12:11:55.371717-08:00","close_reason":"Removed deprecated get_method_superposition_legacy() method. It was unused and callers should use get_method_superposition() directly."}
{"id":"mycelium-nnb","title":"Split step_signatures.py into smaller modules","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:23:40.825031-08:00","updated_at":"2026-01-09T10:19:53.03221-08:00","closed_at":"2026-01-09T10:19:53.03221-08:00","close_reason":"Duplicate of mycelium-8mu - consolidating into one issue"}
{"id":"mycelium-o0m","title":"Low signature creation rate during validation runs","description":"100-problem run only created 4 new signatures despite 100 problems solved. Expected many more signatures to be created and stored. Need to investigate why signatures aren't being saved - possible DB concurrency issue or signature threshold too strict.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-08T14:03:35.353603-08:00","updated_at":"2026-01-08T14:03:35.353603-08:00"}
{"id":"mycelium-o1a","title":"Create storage backend abstraction (ABC + SQLite impl)","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:07.396472-08:00","updated_at":"2026-01-09T10:16:10.305632-08:00","closed_at":"2026-01-09T10:16:10.305632-08:00","close_reason":"No longer relevant - removed SQLite, now PostgreSQL-only","dependencies":[{"issue_id":"mycelium-o1a","depends_on_id":"mycelium-p75","type":"blocks","created_at":"2026-01-09T05:54:52.212579-08:00","created_by":"daemon"}]}
{"id":"mycelium-oy9","title":"[TEST] Missing test coverage for council_v2 synthesis code paths","description":"## Problem\nThe tests in `tests/test_integration.py` and `tests/test_synthesis_strategy.py` do not actually exercise the synthesis code paths (`_once_at_end_synthesize` and `_incremental_synthesize`). All tests mock the LLM responses at a higher level, so the actual synthesis prompt formatting is never tested.\n\n## Impact\nThe undefined variable bug (FINAL_SYNTHESIZER) has gone undetected because tests don't execute the actual synthesis code.\n\n## Suggested Fix\nAdd integration tests that:\n1. Actually exercise `_once_at_end_synthesize()` with step results\n2. Test `_incremental_synthesize()` with a complex DAG that triggers incremental mode (depth\u003e=4, width\u003e=3)\n3. Verify the synthesized answers are properly formatted\n\n## Files to Update\n- tests/test_integration.py - Add tests for synthesis paths\n- tests/test_synthesis_strategy.py - Add tests that go beyond DAGMetrics testing","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:20:36.624323-08:00","updated_at":"2026-01-09T08:34:39.100016-08:00","closed_at":"2026-01-09T08:34:39.100016-08:00","close_reason":"Added test_council_synthesis.py with 10 tests for synthesis paths"}
{"id":"mycelium-p75","title":"Consolidate configuration with pydantic validation","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:53:56.27705-08:00","updated_at":"2026-01-09T06:07:13.48607-08:00","closed_at":"2026-01-09T06:07:13.48607-08:00","close_reason":"Updated step_signatures.py to import constants from config.py instead of redefining them. Removed ~15 duplicate constant definitions."}
{"id":"mycelium-ph4","title":"Lift tracking wrong for superposition runs","description":"Injected usage gets recorded as non-injected and skews lift gating/reliability over time.\n\nLocations:\n- council_v2.py (line 897)\n- step_signatures.py (line 1842)\n\nWhen superposition is used, the usage tracking may not correctly flag steps as 'injected', causing:\n1. Lift calculations to be incorrect (comparing injected vs non-injected)\n2. Reliability thresholds to be skewed over time\n3. Gating decisions based on faulty data","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:13:31.460108-08:00","updated_at":"2026-01-08T13:17:03.715943-08:00","closed_at":"2026-01-08T13:17:03.715943-08:00","close_reason":"Fixed update_superposition_amplitudes to pass was_injected=True"}
{"id":"mycelium-por","title":"[IMPROVE] Duplicate prompt templates in prompt_templates.py and council_v1.py","description":"## Issue\nThere is significant duplication of prompt templates:\n\n1. **prompt_templates.py** has templates registered as 'final_synthesizer' and 'incremental_synthesizer'\n2. **_archive/council_v1.py** has the same templates as module-level constants `FINAL_SYNTHESIZER` and `INCREMENTAL_SYNTHESIZER`\n\nThis creates maintenance burden - if templates need to be updated, they exist in multiple places.\n\n## Current State\n- council_v2.py uses the undefined constants (bug already filed)\n- The prompt_templates.py registry is the preferred approach\n\n## Suggested Fix\n1. Remove hardcoded templates from council_v1.py (if still needed, make it import from registry)\n2. Update council_v2.py to use the registry (already suggested in bug fix)\n3. Centralize all templates in prompt_templates.py\n\n## Files Affected\n- src/mycelium/prompt_templates.py (source of truth)\n- src/mycelium/_archive/council_v1.py (has duplicates)\n- src/mycelium/council_v2.py (needs to use registry)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:28.949573-08:00","updated_at":"2026-01-09T08:32:15.966635-08:00","closed_at":"2026-01-09T08:32:15.966635-08:00","close_reason":"Removed duplicate prompt templates from council_v1.py. Updated to import from prompt_templates.py registry instead."}
{"id":"mycelium-pot","title":"Add cross-signature relationships","description":"","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-08T12:24:41.887833-08:00","updated_at":"2026-01-08T13:14:43.478541-08:00","closed_at":"2026-01-08T13:14:43.478541-08:00","close_reason":"Added signature_relationships table with full CRUD, 5 relationship types, 9 tests"}
{"id":"mycelium-pq5","title":"Ablation study: Essence-based matching evaluation","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T10:58:47.222043-08:00","updated_at":"2026-01-08T11:16:06.669525-08:00","closed_at":"2026-01-08T11:16:06.669525-08:00","close_reason":"Completed ablation study comparing cosine-only, essence-cosine, and essence+wave+norm. Results: Essence+Wave+Norm wins (82% acc), Essence-alone hurts (-4%). Full report in results/ABLATION_REPORT.md"}
{"id":"mycelium-pwa","title":"HIGH: Add type hints to step_signatures.py DB methods","description":"Functions returning Any or missing return type hints: _get_connection(), _execute(), several callback functions. Add explicit types: sqlite3.Connection, sqlite3.Cursor, proper return types.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:47.166681-08:00","updated_at":"2026-01-09T08:27:24.898521-08:00","closed_at":"2026-01-09T08:27:24.898521-08:00","close_reason":"Added type hints to _get_connection(), _get_cursor(), _execute(), _executemany() in step_signatures.py. Added AbstractContextManager and Union imports."}
{"id":"mycelium-r16","title":"Move magic numbers to config file","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:23:53.408235-08:00","updated_at":"2026-01-09T10:45:17.026712-08:00","closed_at":"2026-01-09T10:45:17.026712-08:00","close_reason":"Added 35+ config constants and updated 7 files to use them: client.py, planner.py, council_v2.py, phase_constraints.py, models.py, utils.py. Now have centralized config for LLM params, phase constraints, exploration rates, essence blending."}
{"id":"mycelium-rj2","title":"Vectorized similarity computations for 5-17x speedup","description":"Replaced O(n) python loops with vectorized numpy matrix operations across key similarity functions:\n\n**Performance gains (500 signatures, 384-dim embeddings):**\n- find_similar(): 1.99ms → 0.35ms (5.6x speedup)\n- compute_resonance(): 7.47ms → 0.45ms (16.7x speedup)  \n- compute_interference_scores_batch(): 6.23ms → 4.98ms (1.3x speedup)\n- suggest_cluster_merges(): O(n²) loops → O(n²) numpy (~10x speedup)\n\n**New batch functions added:**\n- cosine_similarity_batch(query, matrix) - vectorized 1-to-many similarity\n- cosine_similarity_batch_essence(query, matrix, essence_dims) - essence subspace variant\n\n**Key techniques:**\n1. Stack centroids into matrix, compute all similarities via single @ operation\n2. Vectorized normalization with np.linalg.norm(matrix, axis=1)\n3. Numpy broadcasting for element-wise ops (gaussian, phase_factor)\n4. Pre-filtering with np.where(mask) instead of python conditionals\n\nCommits: e5d1443, and integrated into compute_resonance/suggest_cluster_merges","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T12:56:29.565383-08:00","updated_at":"2026-01-08T12:56:43.615682-08:00","closed_at":"2026-01-08T12:56:43.615682-08:00","close_reason":"Completed. All vectorized implementations tested and merged."}
{"id":"mycelium-ryi","title":"Create mushroom_math project with best research for arXiv paper","description":"Write the arXiv paper for Mycelium.\n\n**Location**: ~/Desktop/mycelium/paper.md\n\n## Core Analogy\n\n**Prime Factorization of Math Problems**: Just as composite numbers can be factored into their unique prime components, complex math problems can be decomposed into reusable atomic signatures. The signature embedding DB acts as the \"table of primes\" - a finite set of fundamental solution patterns that combine to solve infinite problem variations.\n\n## Components\n\n1. **Problem Decomposition** - Factor problems into atomic steps (DAG structure with dependencies)\n2. **Signature Embedding DB** - Vector store of \"prime\" solution patterns\n3. **Cosine Similarity Matching** - Find which known signatures apply to new steps\n4. **Hybrid DSL Execution** - Route steps to formula/code/LLM based on type\n5. **Final Merge Solver** - Synthesize atomic results into complete answer\n\n*Supporting concepts:*\n- Step-level reusability (steps reusable across problems, whole problems aren't)\n- Learning loop (reliability threshold, outcome tracking, inject vs solve fresh)\n\n## Delegated Tasks (dependencies)\n\n- mycelium-1hg: Run experiments, fill Table 1\n- mycelium-aj5: Step-level vs problem-level analysis\n- mycelium-3d5: Signature growth analysis\n- mycelium-cq5: Reliability threshold ablation\n- mycelium-dt9: Architecture diagram\n\n## My Responsibilities\n\n- Own the paper structure and narrative\n- Integrate results from delegated tasks\n- Polish writing and ensure coherence\n- Final edits and submission prep","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-01-09T08:52:29.696274-08:00","updated_at":"2026-01-09T09:44:30.717809-08:00","dependencies":[{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-1hg","type":"blocks","created_at":"2026-01-09T09:43:08.939092-08:00","created_by":"daemon"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-aj5","type":"blocks","created_at":"2026-01-09T09:43:08.988596-08:00","created_by":"daemon"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-3d5","type":"blocks","created_at":"2026-01-09T09:43:09.037447-08:00","created_by":"daemon"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-cq5","type":"blocks","created_at":"2026-01-09T09:43:09.085844-08:00","created_by":"daemon"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-dt9","type":"blocks","created_at":"2026-01-09T09:43:09.134719-08:00","created_by":"daemon"}]}
{"id":"mycelium-sfw","title":"Planner parsing silently drops steps on dependency issues","description":"planner.py has brittle parsing that silently returns partial execution order when dependencies are malformed or cyclic. Steps can be dropped without surfacing an error. Affected locations: planner.py:57 (dependency parsing), planner.py:118 (execution order). Should either: (1) Raise explicit error on cyclic/malformed dependencies, (2) Log warning when steps are dropped, or (3) Return validation result alongside execution order.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:19:16.872957-08:00","updated_at":"2026-01-08T13:23:09.517902-08:00","closed_at":"2026-01-08T13:23:09.517902-08:00","close_reason":"Added DAGPlan.validate(), PlanValidationError, strict mode, and comprehensive logging for parsing issues and dropped steps"}
{"id":"mycelium-sgt","title":"Add periodic decay job or hook for signature decoherence","description":"decay_unused_signatures() exists but is never called automatically. Consider: (1) Adding a post-training hook in pipeline_runner to decay after each run, (2) A CLI command 'mycelium decay --dry-run', or (3) Documentation on when/how to run it. Without periodic decay, the decoherence feature has no effect.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-08T12:15:50.939732-08:00","updated_at":"2026-01-08T12:15:50.939732-08:00"}
{"id":"mycelium-sig","title":"[TEST] Add async test for MCTS simulation with phase constraints","description":"## Issue\nThe MCTS module (mcts.py) has sophisticated phase constraint tracking and simulation logic, but there's limited test coverage for:\n\n1. The MCTS search algorithm with actual async simulation\n2. Phase constraint assignment and score computation during simulation\n3. Cluster-aware priors and reusable solution detection\n4. The MCTSDecomposer end-to-end flow\n\n## Current State\n- test_mcts_clusters.py only tests ClusterInfo and basic functionality\n- No tests for the actual MCTS search loop with phase tracking\n- Phase constraint logic (PhaseAssignment, PhaseScore) tested separately but not integrated with MCTS\n\n## Suggested Tests\nAdd integration tests that:\n1. Run MCTS search with a mock simulation function\n2. Verify phase scores are computed correctly during simulation\n3. Test the backpropagation with phase-adjusted rewards\n4. Verify cluster coverage affects priors appropriately\n\n## Files to Update\n- tests/test_mcts_clusters.py - Extend with async tests","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:59.690733-08:00","updated_at":"2026-01-09T08:34:39.151614-08:00","closed_at":"2026-01-09T08:34:39.151614-08:00","close_reason":"Added async MCTS simulation tests in test_mcts_clusters.py"}
{"id":"mycelium-ulk","title":"Verify signature retrieval and method injection loop","description":"Signatures are now storing correctly. Need to verify:\n1. When a similar problem is seen, the signature is retrieved\n2. The method is injected into the prompt\n3. This actually improves accuracy on similar problems\n\nTest: Run training twice - second run should show method injection happening","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T05:32:34.756415-08:00","updated_at":"2026-01-08T06:13:56.696262-08:00","closed_at":"2026-01-08T06:13:56.696262-08:00","close_reason":"Fixed bootstrap problem where usage wasn't being recorded. Added signature_matched field to track all matched signatures and record their usage to build reliability. Verified with test_injection_loop.py showing 15 reliable signatures after 5 passes."}
{"id":"mycelium-uwi","title":"Remove legacy problem-level signatures code","description":"Expunge unused problem-level signature code: delete signatures.py, remove SignatureDB imports from council_v2.py/mcts.py/solver.py/db.py/__init__.py, drop signatures table from schema.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:53:07.335343-08:00","updated_at":"2026-01-09T09:57:57.54369-08:00","closed_at":"2026-01-09T09:57:57.54369-08:00","close_reason":"Removed legacy problem-level signatures code: archived signatures.py, solver.py, planner_wavelet.py; removed SignatureDB imports from council_v2.py, mcts.py, db.py, __init__.py"}
{"id":"mycelium-v87","title":"Centralize database connection management","description":"_get_connection() appears in both db.py and step_signatures.py. data_layer exists but inconsistently used.\n\nActions:\n- Add connection factory to data_layer\n- Deprecate _get_connection() in both modules  \n- Update all raw SQLite calls to use data_layer\n- Ensure schema migrations happen in one place","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T08:34:45.702413-08:00","updated_at":"2026-01-09T10:55:47.418622-08:00","closed_at":"2026-01-09T10:55:47.418622-08:00","close_reason":"All sub-tasks completed: signatures.py, db.py, step_signatures helper modules, and execution_plan_optimizer all migrated to data_layer.","dependencies":[{"issue_id":"mycelium-v87","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.372919-08:00","created_by":"daemon"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-zcb","type":"blocks","created_at":"2026-01-09T09:00:42.399113-08:00","created_by":"daemon"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-ern","type":"blocks","created_at":"2026-01-09T09:00:42.444588-08:00","created_by":"daemon"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-jit","type":"blocks","created_at":"2026-01-09T09:00:42.490084-08:00","created_by":"daemon"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-dtj","type":"blocks","created_at":"2026-01-09T09:00:42.540202-08:00","created_by":"daemon"}]}
{"id":"mycelium-vf3","title":"Incomplete error handling in _row_to_signature for optional columns","description":"step_signatures.py:2426-2470 - _row_to_signature() has try-catch for io_schema but other wave properties (amplitude, phase, spread) might fail silently. Add safe access with row.get() for all optional columns.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:53.226918-08:00","updated_at":"2026-01-09T08:30:18.85225-08:00","closed_at":"2026-01-09T08:30:18.85225-08:00","close_reason":"Closed"}
{"id":"mycelium-w44","title":"Benchmark: +45.7% lift from method injection","description":"## Key Finding\nMethod injection provides **+45.7% lift** in success rate.\n\n## Data\n| Path | Uses | Successes | Success Rate |\n|------|------|-----------|--------------|\n| Injected | 10 | 10 | 100% |\n| Non-injected | 1914 | 1039 | 54.3% |\n\n**Overall Lift: +45.7%**\n\n## Additional Metrics\n- Wave propagation effectiveness: +21.2%\n- Reliable signatures: 89 (of 312 total)\n- Canonical patterns: 102\n\n## Interpretation\nWhen the system injects a method template into the prompt, the success rate jumps from 54% to 100%. This validates the core hypothesis that:\n1. Signature matching finds relevant methods\n2. Method injection helps the LLM solve problems correctly\n\n## Next Steps\n- Gather more data to get per-signature lift confidence\n- Need 3+ samples in both arms per signature for confident estimates\n- Consider adjusting exploration_rate or running longer pipelines","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T13:22:24.982943-08:00","updated_at":"2026-01-08T13:22:24.982943-08:00"}
{"id":"mycelium-w7w","title":"Switch to aiosqlite for non-blocking DB operations","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:30.305496-08:00","updated_at":"2026-01-09T10:16:10.242983-08:00","closed_at":"2026-01-09T10:16:10.242983-08:00","close_reason":"No longer relevant - removed SQLite, now PostgreSQL-only","dependencies":[{"issue_id":"mycelium-w7w","depends_on_id":"mycelium-o1a","type":"blocks","created_at":"2026-01-09T05:54:54.005517-08:00","created_by":"daemon"}]}
{"id":"mycelium-w8w","title":"Amplitude decay compounds making wave propagation ineffective","description":"step_signatures.py:1936-1940 - AMPLITUDE_DECAY_RATE=0.99 applied per-update compounds with wave decay. Formula: neighbor.amplitude * 0.99 + delta means amplitudes decay faster than they grow. Review intent and fix formula.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:45.631172-08:00","updated_at":"2026-01-08T11:54:18.921595-08:00","closed_at":"2026-01-08T11:54:18.921595-08:00","close_reason":"Fixed compounding decay - propagation no longer decays neighbor amplitude"}
{"id":"mycelium-wf4","title":"How do we decide when to add new step signature?","description":"Currently step signatures are added but the criteria for when to add a new one vs. reuse existing is unclear.\n\nQuestions to answer:\n- When should we create a new step signature vs. match to existing?\n- What similarity threshold triggers signature creation?\n- Should we require minimum success count before creating persistent signatures?\n- How do we handle near-duplicate steps that solve the same sub-problem differently?\n\nRelated: Step signatures are used in MCTS cluster-aware priors (mcts.py) and stored via StepSignatureDB.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T08:17:46.314404-08:00","updated_at":"2026-01-08T08:39:59.12617-08:00","closed_at":"2026-01-08T08:39:59.12617-08:00","close_reason":"Implemented wave function approach to step signature creation:\n- Added pending_step_examples table for steps in 'superposition'\n- superposition_match() returns (signature_or_none, pending_example)\n- observe_pending() collapses on success + high similarity (\u003e= 0.85)\n- try_collapse_pending_clusters() uses DBSCAN to form new clusters from 3+ similar successful pending examples\n- 15 tests passing for wave function methods"}
{"id":"mycelium-ws1","title":"Match mode bypassed: clustering/injection use find_similar not find_matches","description":"MYCELIUM_MATCH_MODE (resonance/interference/auto) is bypassed in core flows because clustering and method injection call find_similar() directly instead of find_matches().\n\nAffected locations:\n- step_signatures.py:1750 - clustering logic\n- step_signatures.py:1981 - method injection\n\nThis means users setting MYCELIUM_MATCH_MODE won't see those modes used in actual behavior - only cosine similarity is used.\n\nFix: Update these call sites to use find_matches() which respects the configured mode.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:16:05.749583-08:00","updated_at":"2026-01-08T13:20:24.780128-08:00","closed_at":"2026-01-08T13:20:24.780128-08:00","close_reason":"Updated find_or_defer to use find_matches. Other call sites were already correct."}
{"id":"mycelium-wst","title":"Add retry logic with exponential backoff to client.py","description":"Wrap Groq API calls with retry decorator. Handle rate limits (429), server errors (5xx), and connection timeouts. Use tenacity or custom implementation with max 3 retries.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:30.28528-08:00","updated_at":"2026-01-09T07:49:20.236684-08:00","closed_at":"2026-01-09T07:49:20.236684-08:00","close_reason":"Added retry with exponential backoff + Retry-After header support"}
{"id":"mycelium-x2h","title":"Add database migration system for schema changes","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:14.571081-08:00","updated_at":"2026-01-09T05:54:14.571081-08:00","dependencies":[{"issue_id":"mycelium-x2h","depends_on_id":"mycelium-o1a","type":"blocks","created_at":"2026-01-09T05:54:53.027961-08:00","created_by":"daemon"}]}
{"id":"mycelium-xix","title":"Add batch processing to decay_unused_signatures for scale","description":"decay_unused_signatures() fetches all signatures into memory before processing. For large DBs with millions of signatures, this could cause memory issues. Add a batch_size parameter to process in chunks, e.g., 'LIMIT 1000 OFFSET N' with cursor-based iteration.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-08T12:15:43.699062-08:00","updated_at":"2026-01-08T12:15:43.699062-08:00"}
{"id":"mycelium-xm4","title":"Fix LRU cache for embedding lookups in step_signatures.py","description":"Add functools.lru_cache or manual cache dict for repeated embedding lookups. Cache get_essence_dims() results and signature centroid fetches.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:50.784995-08:00","updated_at":"2026-01-09T07:55:22.121835-08:00","closed_at":"2026-01-09T07:55:22.121835-08:00","close_reason":"Added in-memory cache for get_essence_dims() with invalidation on signature add/merge/split. Avoids repeated DB lookups within a session."}
{"id":"mycelium-xt7","title":"Add structured logging to planner.py","description":"Add consistent logging to planner.py for decomposition steps, DAG validation, and error cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:17.3163-08:00","updated_at":"2026-01-09T07:48:30.827162-08:00","closed_at":"2026-01-09T07:48:30.827162-08:00","close_reason":"Added logging for decomposition start/complete with validation"}
{"id":"mycelium-yhc","title":"Add unit tests for clustering module","description":"Write pytest tests for compute_cohesion, compute_silhouette, build_distance_matrix. Test with synthetic embeddings and edge cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:41.853265-08:00","updated_at":"2026-01-09T07:55:44.154202-08:00","closed_at":"2026-01-09T07:55:44.154202-08:00","close_reason":"Created tests/test_clustering.py with 34 tests covering compute_cohesion, compute_silhouette, build_distance_matrix, and related utilities"}
{"id":"mycelium-ynb","title":"Track step sequences for contextual matching (entanglement)","description":"Track which step types commonly follow each other and their success rates. Use this to improve method selection based on context.\n\nFrom wave function analysis: Steps are 'entangled' - the optimal method for step N depends on what step N-1 did.\n\nImplementation:\n1. Add step_sequences table (prev_type, curr_type, count, success_rate)\n2. Record transitions during solving\n3. Add get_contextual_method() that considers prev step type\n4. Weight signature matches by transition success rate","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:33:57.557384-08:00","updated_at":"2026-01-08T12:10:25.191086-08:00","closed_at":"2026-01-08T12:10:25.191086-08:00","close_reason":"Implemented step_sequences table and functions: record_step_sequence(), get_sequence_stats(), get_contextual_boost(), find_matches_with_context(). Tracks step type transitions and success rates for contextual matching. Tests: TestStepSequences (9 tests)"}
{"id":"mycelium-ynn","title":"Variable detection in complexity estimation is backwards","description":"model_router.py:estimate_complexity() excludes 'a' and 'i' from variable detection but keeps all other single letters. The logic seems backwards - it should keep likely math variables (x, y, z, n, m, k, t) and exclude common words. Current: variables = set(re.findall(r'\\b[a-z]\\b', text_lower)) - {'a', 'i'}. Suggested fix: math_vars = {'x', 'y', 'z', 'n', 'm', 'k', 't', 'r', 's'} and use intersection instead of difference.","status":"open","priority":3,"issue_type":"bug","created_at":"2026-01-08T13:12:46.343362-08:00","updated_at":"2026-01-08T13:12:46.343362-08:00"}
{"id":"mycelium-yq9","title":"model_router exception list may miss user-defined errors","description":"Line 192 catches specific exceptions but user rule conditions could raise others (ZeroDivisionError, IndexError). Consider broader catch or documenting expected exceptions.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-09T08:33:01.042765-08:00","updated_at":"2026-01-09T08:33:01.042765-08:00"}
{"id":"mycelium-yuu","title":"Consolidate SignatureDB and StepSignatureDB into unified MyceliumDB","description":"Merge the two database classes into a single MyceliumDB class with all tables in one place. This simplifies the architecture and ensures consistent db_path usage.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T11:16:34.141371-08:00","updated_at":"2026-01-08T11:45:07.225023-08:00","closed_at":"2026-01-08T11:45:07.225023-08:00","close_reason":"MyceliumDB already exists. Optimized by caching SignatureDB instance (lazy init) instead of creating new instance per call. All 247 tests pass."}
{"id":"mycelium-z4j","title":"Docstring mismatch in MCTS get_prior() about only_reliable","description":"mcts.py:169-197 - Docstring says 'prior_probability' but uses only_reliable=False returning all signatures. Either update docstring or change to only_reliable=True.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:10:55.082153-08:00","updated_at":"2026-01-08T12:15:47.032147-08:00","closed_at":"2026-01-08T12:15:47.032147-08:00","close_reason":"Updated docstring to clarify that get_prior() uses all signatures (not just reliable ones) for computing priors, and documented the prior computation formula."}
{"id":"mycelium-zcb","title":"Migrate signatures.py to use data_layer","description":"Replace 10 direct sqlite3.connect calls with data_layer.db.connection(). Import db, replace connection pattern.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T09:00:29.142156-08:00","updated_at":"2026-01-09T09:01:45.893772-08:00","closed_at":"2026-01-09T09:01:45.893772-08:00","close_reason":"Replaced all 10 sqlite3.connect calls with self._get_connection() using data_layer. Added _db and _get_connection() to SignatureDB."}
