{"id":"mycelium-008","title":"Fix PostgreSQL row access patterns in _legacy.py","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-09T10:11:41.4125-08:00","updated_at":"2026-01-09T10:33:44.841047-08:00","closed_at":"2026-01-09T10:33:44.841047-08:00"}
{"id":"mycelium-02nn","title":"System Independence: Refactor forced exploration to use Welford stats","description":"## Problem\n\nPer CLAUDE.md: \"Resist the urge to manually intervene in the tree. We want the system to be independent.\"\n\nThe `_force_exploration` flag (solver.py:682) bypasses UCB1 branching logic and compute budget constraints, overriding data-driven decisions with imperative control.\n\n## Current Behavior\n\n```python\n# solver.py:682\nself._force_exploration: bool = False\n\n# solver.py:2347-2348 - bypasses UCB1 gap check and budget\nis_undecided = routing_result.min_gap \u003c UCB1_GAP_BRANCH_THRESHOLD or self._force_exploration\neffective_budget = max(compute_budget, 3.0) if self._force_exploration else compute_budget\n\n# solver.py:4155, 4188 - manually toggled during reactive exploration\nself._force_exploration = True\n# ... retry logic ...\nself._force_exploration = False\n```\n\nThis is manual intervention that should be replaced with Welford-guided exploration:\n- UCB1 gap threshold should adapt based on routing success variance\n- Compute budget should scale with problem difficulty AND signature confidence\n\n## Expected Behavior\n\nReplace `_force_exploration` flag with Welford-guided adaptive exploration:\n\n1. **Adaptive UCB1 gap threshold**: \n   - Track gap values that led to correct vs incorrect routing\n   - Use Welford to compute adaptive gap threshold: `gap_mean - k*gap_std`\n   \n2. **Adaptive compute budget**:\n   - Track budget used for successful vs failed problems\n   - Adjust budget based on signature confidence (from exec_* stats)\n\n3. **Remove manual toggle**:\n   - Reactive exploration should increase exploration via Welford-guided thresholds\n   - Not via imperative flag\n\n## Files to Modify\n\n- `src/mycelium/solver.py:682` - Remove `_force_exploration` flag\n- `src/mycelium/solver.py:2347-2348` - Use adaptive gap threshold\n- `src/mycelium/solver.py:4141-4189` - Refactor reactive exploration\n- `src/mycelium/config.py` - Add Welford-guided exploration configs\n\n## Implementation Sketch\n\n```python\n# Instead of:\nis_undecided = min_gap \u003c UCB1_GAP_BRANCH_THRESHOLD or self._force_exploration\n\n# Use:\nadaptive_gap_threshold = self._get_adaptive_gap_threshold()  # From Welford stats\nis_undecided = min_gap \u003c adaptive_gap_threshold\n```\n\n## Testing\n\n1. Remove flag and run on GSM8K\n2. Compare exploration rates before/after\n3. Verify reactive exploration still works (via adaptive thresholds)\n4. Run full test suite\n\n## Context\n\nPart of System Independence code review. Related to mycelium-808f.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:37:28.401642-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T11:56:52.472408-08:00","closed_at":"2026-01-28T11:56:52.472408-08:00","close_reason":"Implemented Welford-guided adaptive UCB1 gap threshold. Replaced _force_exploration flag with _reactive_exploration_mode and adaptive multipliers. Added ucb1_gap_stats table, propagation in postmortem, and helper methods in solver.","dependencies":[{"issue_id":"mycelium-02nn","depends_on_id":"mycelium-808f","type":"blocks","created_at":"2026-01-28T11:39:40.784029-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-080","title":"Ablation study: isolate wave term contribution","description":"Run 3 ablations on same 50 problems to isolate what's doing the work:\n\n1. V2 + cosine-only (no wave terms)\n2. V2 + wave terms (current)\n3. V2 + wave terms + normalized score (z-score or min-max to prevent vanishing)\n\nIf (2) \u003e (1) consistently, waves are real value.\nIf (1) ≈ (2), waves are optional polish.\n\nSame seed, same models, same problems.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T09:27:40.406309-08:00","updated_at":"2026-01-08T09:39:31.880155-08:00","closed_at":"2026-01-08T09:39:31.880155-08:00"}
{"id":"mycelium-0ba","title":"Add LLM-based tag extraction for signatures","description":"Currently storing signatures with empty tags=[]. \n\nCould use LLM to extract meaningful tags like:\n- Problem type: algebra, geometry, number_theory\n- Techniques: factoring, substitution, quadratic_formula\n- Structure: word_problem, pure_math, multi_step\n\nThis improves:\n1. Explainability of why signatures match\n2. Tag-based filtering as fallback to embeddings\n3. Debugging and analysis","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T05:32:41.415413-08:00","updated_at":"2026-01-08T06:27:36.947091-08:00","closed_at":"2026-01-08T06:27:36.947091-08:00"}
{"id":"mycelium-0dcx","title":"Audit: Check for dead code in DSL layers","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T11:05:53.821316-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T17:50:06.757415-08:00","closed_at":"2026-01-20T17:50:06.757415-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-0hm","title":"Integrate signature splitting into training pipeline","description":"New signature splitting methods have been added to StepSignatureDB but are not yet integrated into the training pipeline.\n\n## Methods Added (step_signatures.py)\n- find_high_variance_signatures() - Find signatures with high usage but low success rates\n- analyze_signature_variance() - Use DBSCAN to check if examples form distinct clusters  \n- split_signature() - Split a signature into sub-signatures based on clustering\n- auto_split_high_variance_signatures() - Automatically find and split problematic signatures (supports dry-run)\n\n## Integration Tasks\n1. Add --split-signatures flag to pipeline_runner.py\n2. Run auto_split after training passes complete\n3. Consider running periodically during training (every N passes)\n4. Add split statistics to pipeline report\n\n## Usage Example\n```python\ndb.auto_split_high_variance_signatures(\n    min_usage=50,\n    max_success_rate=0.5,\n    min_examples=10,\n    dry_run=False\n)\n```","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T15:16:31.113395-08:00","updated_at":"2026-01-08T15:19:58.8743-08:00","closed_at":"2026-01-08T15:19:58.8743-08:00"}
{"id":"mycelium-0i2w","title":"Perf: Repeated sig count queries create fresh DB connections","description":"get_signature_count() creates new sqlite3 connection on every cache miss.\n\nLocation: solver.py:75-92\n\nImpact: MEDIUM - 5-20ms per step (connection open/close ~1ms each)\n\nCalled twice per step via get_adaptive_match_threshold() and should_force_decompose().\n\nFix: Use singleton StepSignatureDB instance's connection instead of creating new one.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:02:19.320857-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T15:09:12.893528-08:00","closed_at":"2026-01-15T15:09:12.893528-08:00","close_reason":"Replaced manual sqlite3.connect() with singleton ConnectionManager.get_db(). Reuses thread-local pooled connection instead of creating fresh connection on each cache miss."}
{"id":"mycelium-0i3","title":"Feature: Track routing path in StepResult for debugging","description":"When routing fails and falls back to LLM, there's no indication that routing was attempted. StepResult doesn't track the routing path (parent-\u003echild-\u003egrandchild). Fix: Add routing_path field to StepResult, e.g. ['compute_probability', 'prob_conditional'] to show which signatures were traversed.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T06:42:11.162346-08:00","updated_at":"2026-01-12T06:58:27.265793-08:00","closed_at":"2026-01-12T06:58:27.265793-08:00"}
{"id":"mycelium-0k5","title":"Investigate DSL rewrite failures","description":"Improve injection rate by debugging LLM rewrite failures. Current: 67%. Goal: 80%+","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-10T16:58:14.715475-08:00","updated_at":"2026-01-10T17:10:47.853089-08:00","closed_at":"2026-01-10T17:10:47.853089-08:00"}
{"id":"mycelium-0mo","title":"Add smoke benchmark script for CI regression testing","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T11:27:03.577991-08:00","updated_at":"2026-01-08T11:41:57.792602-08:00","closed_at":"2026-01-08T11:41:57.792602-08:00"}
{"id":"mycelium-0ox","title":"Remove/formalize dead code (council.py, solver.py, planner_wavelet.py)","description":"Three files are unclear in status:\n- council.py (36 lines): Deprecated shim, still importable\n- solver.py (300 lines): Replaced by council_v2, no deprecation\n- planner_wavelet.py (406 lines): Alternative strategy, unclear if used\n\nActions:\n1. council.py: Move to optional deps or _archive\n2. solver.py: Add deprecation warning, document migration to council_v2\n3. planner_wavelet.py: Document status or integrate into planner.py as mode\n4. Update README with maintained vs historical files","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:34:52.866325-08:00","updated_at":"2026-01-09T10:54:03.864155-08:00","closed_at":"2026-01-09T10:54:03.864155-08:00","dependencies":[{"issue_id":"mycelium-0ox","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.419435-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-0x1b","title":"Post-mortem: Inform new signature parent selection from interference patterns","description":"When creating new signatures, interference patterns from post-mortem can inform which parent to attach to. If problems of type X consistently succeed under parent A but fail under parent B, new X-like signatures should prefer parent A.","status":"closed","priority":3,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:07.751943-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T14:29:59.443062-08:00","closed_at":"2026-01-25T14:29:59.443062-08:00","close_reason":"Superseded by graph_embedding + Welford match scoring. System is now self-correcting through match_score (similarity + traffic + success + variance)."}
{"id":"mycelium-0ym","title":"No bounds checking on dynamic threshold in resonance","description":"step_signatures.py:3318-3320 - dynamic_threshold calculation can overflow to NaN/infinity with large total_energy. Add np.clip(dynamic_threshold, 0.0, 1.0) bounds checking.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:47.033414-08:00","updated_at":"2026-01-08T12:02:13.278633-08:00","closed_at":"2026-01-08T12:02:13.278633-08:00"}
{"id":"mycelium-0yu","title":"Document decomposition flow for arXiv paper","description":"Document the problem decomposition architecture for the mushroom_math arXiv paper.\n\n**Flow to document**:\n1. MCTS decides whether to decompose (yes/no/simplified)\n2. Planner: LLM generates YAML with steps + depends_on\n3. DAGPlan: Validates structure (no cycles, deps exist)\n4. Execution: Level-by-level (parallel within levels)\n5. Per-step: Embed → Find signature → Route (formula/code/LLM) → Update stats\n6. Synthesize: Combine step results into final answer\n\n**Key insights**:\n- Planner does actual decomposition (LLM → YAML → DAG)\n- MCTS decides WHETHER to decompose, not HOW\n- DAG tracks dependencies via explicit depends_on lists\n- Signatures matched at execution time, not decomposition time\n\nRelated to: mycelium-ryi (arXiv paper project)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:06:57.958042-08:00","updated_at":"2026-01-20T17:50:06.234927-08:00","closed_at":"2026-01-20T17:50:06.234927-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-11n","title":"Extract wave_physics/ module for interference/resonance","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:04.537161-08:00","updated_at":"2026-01-09T06:28:25.759247-08:00","closed_at":"2026-01-09T06:28:25.759247-08:00","dependencies":[{"issue_id":"mycelium-11n","depends_on_id":"mycelium-ib7","type":"blocks","created_at":"2026-01-09T05:54:43.637601-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-11n","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:54:44.827089-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-126","title":"Add concurrent access tests for StepSignatureDB","description":"Missing tests for concurrent access to StepSignatureDB. Need tests for: concurrent add_example_to_cluster, concurrent observe_pending, wave propagation correctness, centroid accuracy under load.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:11:00.211554-08:00","updated_at":"2026-01-08T12:33:38.319155-08:00","closed_at":"2026-01-08T12:33:38.319155-08:00"}
{"id":"mycelium-1407","title":"Perf: DSL expression cache unbounded","description":"solver.py:238-239 has unbounded cache:\nself._dsl_expr_cache: dict[tuple[str, frozenset[str]], tuple[str, list[str]]] = {}\n\nWith millions of unique param combinations, could consume memory.\n\nFix: Add LRU cache decorator or max size limit (1000 entries)\n\nLatency impact: LOW but memory leak over time","status":"closed","priority":3,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:28:57.926351-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:52:59.547102-08:00","closed_at":"2026-01-15T14:52:59.547102-08:00","close_reason":"Added bounded LRU cache for DSL expressions. Changed from dict to OrderedDict with move_to_end() on read and popitem(last=False) eviction on write when exceeding DSL_EXPR_CACHE_MAX_SIZE (1000). Config constant added to config.py per CLAUDE.md."}
{"id":"mycelium-146m","title":"Bug: Silent exception handling masks failures","description":"Multiple places swallow exceptions with 'except: pass' - violates 'failures are valuable data' principle.\n\nLocations:\n- solver.py:84 - signature count retrieval\n- schema.py:195 - migrations\n- client.py:213 - token counting\n- embedding_cache.py:769 - JSON parsing\n\nFix: Add logger.warning() to all exception handlers. Failures should be recorded, not hidden.","status":"closed","priority":0,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:27:28.105757-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T13:33:11.244617-08:00","closed_at":"2026-01-15T13:33:11.244617-08:00","close_reason":"Added logger.warning() to all 4 silent exception handlers: solver.py:84 (signature count), schema.py:199+214 (migrations), client.py:213 (Retry-After), embedding_cache.py:769 (JSON parsing)"}
{"id":"mycelium-1b8w","title":"Epic: Recursive Local Decomposition Architecture","description":"Complete architectural shift to flat prototype classifier + LLM decomposition.\n\n## The New Vision (Pivoted)\n- Tree is a FLAT prototype store (~200 functions, ~1000 signatures)\n- Each signature = prototype with func_name + centroid + description\n- Classification via brute-force k-NN (fast at 5k scale)\n- LLM does recursive decomposition, guided by signature examples\n- High-success signatures become few-shot examples for LLM\n- \"Atomic\" = matches a leaf in the tree\n\n## The Feedback Loop\n1. Tree learns which descriptions succeed for which functions\n2. High-success signatures become few-shot examples for LLM\n3. LLM produces better decompositions\n4. Tree gets even better signal\n\n## Key Insight: 200-Class Classification\n- Input: Step description (one embedding)\n- Middle: Compare to ~1000 signature prototypes\n- Output: One of ~200 functions\n\n## Success Criteria\n- Flat signature store (no hierarchy)\n- Function registry with curated Python functions\n- LLM decomposer using signature examples as guidance\n- Brute-force k-NN classification","status":"open","priority":0,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:16.243178-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T07:02:54.624578-08:00"}
{"id":"mycelium-1b8w.1","title":"Remove LLM planner dependency","description":"Remove LLM calls from decomposition path.\n\nFiles to refactor/remove:\n- src/mycelium/planner.py (1,760 lines) - heavily LLM-dependent, needs major refactor\n- src/mycelium/prompt_templates.py (456 lines) - can be removed entirely\n- src/mycelium/step_signatures/dsl_generator.py - LLM DSL generation\n- src/mycelium/step_signatures/operation_extractor.py - LLM-based\n\nGoal: Decomposition happens locally via embeddings, not LLM.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:50.997589-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T09:25:29.044743-08:00","closed_at":"2026-01-29T09:25:29.044743-08:00","close_reason":"Completed: Removed planner.py, prompt_templates.py, all LLM decomposition code. Solver now 286 lines with no LLM dependencies for planning.","dependencies":[{"issue_id":"mycelium-1b8w.1","depends_on_id":"mycelium-1b8w","type":"parent-child","created_at":"2026-01-29T08:50:50.999449-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1b8w.2","title":"Implement coverage/residual signal","description":"Add coverage score to measure how much of problem embedding is explained by matched leaf.\n\nNew function: compute_coverage_score(problem_emb, leaf_emb) -\u003e float\n- Residual = problem_emb - projection_onto(leaf_emb)\n- Coverage = 1 - ||residual|| / ||problem_emb||\n\nTrack with Welford:\n- coverage_mean, coverage_variance, coverage_count\n- Threshold = mean - k*std (below = needs decomposition)\n\nPer CLAUDE.md The Flow: DB Stats → Welford → Tree Structure","status":"open","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:52.38079-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T08:50:52.38079-08:00","dependencies":[{"issue_id":"mycelium-1b8w.2","depends_on_id":"mycelium-1b8w","type":"parent-child","created_at":"2026-01-29T08:50:52.381596-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-1b8w.2","depends_on_id":"mycelium-1b8w.6","type":"blocks","created_at":"2026-01-29T08:51:21.366305-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1b8w.3","title":"Implement local text splitter","description":"Local decomposition without LLM.\n\nSplitting strategies:\n- Sentence boundaries\n- Conjunctions (and, then, after, before)\n- Question phrases (how much, what is, find)\n- Mathematical operators\n\nInput: problem text\nOutput: list of sub-problems\n\nNo LLM calls - pure text parsing.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:53.206668-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T07:02:52.937797-08:00","closed_at":"2026-01-31T07:02:52.937797-08:00","close_reason":"Obsolete: LLM now handles decomposition instead of local text splitter","dependencies":[{"issue_id":"mycelium-1b8w.3","depends_on_id":"mycelium-1b8w","type":"parent-child","created_at":"2026-01-29T08:50:53.207376-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-1b8w.3","depends_on_id":"mycelium-1b8w.6","type":"blocks","created_at":"2026-01-29T08:51:22.083689-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1b8w.4","title":"Implement recursive decomposition loop","description":"Core recursive algorithm:\n\n1. Embed problem (text embedding)\n2. Find best leaf match\n3. Compute coverage score\n4. If coverage \u003e= threshold → atomic, route to leaf\n5. If coverage \u003c threshold → split locally\n6. Recursively process each split\n7. Track failures for periodic review\n\nReturns: list of (sub-problem, leaf_node) pairs","status":"open","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:54.296871-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T08:50:54.296871-08:00","dependencies":[{"issue_id":"mycelium-1b8w.4","depends_on_id":"mycelium-1b8w","type":"parent-child","created_at":"2026-01-29T08:50:54.297745-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-1b8w.4","depends_on_id":"mycelium-1b8w.6","type":"blocks","created_at":"2026-01-29T08:51:23.337523-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1b8w.5","title":"Add failure tracking for periodic review","description":"Track decomposition failures for batch review.\n\nWhen no good match found (coverage \u003c threshold after all splits):\n- Record failure in DB\n- Track: problem_text, best_match, coverage_score, timestamp\n\nPeriodic review (every N failures):\n- Analyze failure patterns\n- Potentially create new signatures\n\nExisting infrastructure to leverage:\n- decomposition_queue table\n- rejection_count tracking\n- get_rejection_count_threshold()","status":"open","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:55.374687-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T08:50:55.374687-08:00","dependencies":[{"issue_id":"mycelium-1b8w.5","depends_on_id":"mycelium-1b8w","type":"parent-child","created_at":"2026-01-29T08:50:55.375501-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-1b8w.5","depends_on_id":"mycelium-1b8w.4","type":"blocks","created_at":"2026-01-29T08:51:24.323311-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1b8w.6","title":"Massive code cleanup - remove unused LLM code","description":"Remove code not needed for local decomposition.\n\nCANDIDATES FOR REMOVAL:\n- prompt_templates.py (456 lines)\n- Much of planner.py negotiation logic\n- LLM-based decomposition in solver.py\n- operation_extractor.py\n\nCANDIDATES FOR SIMPLIFICATION:\n- solver.py (6,140 lines → target ~2,000)\n- planner.py (1,760 lines → target ~500)\n- step_signatures/db.py (10,426 lines → audit for dead code)\n\nKEEP:\n- Embedding infrastructure\n- Tree structure and routing\n- Welford stats\n- MCTS\n- Answer normalization\n- DSL execution (not generation)","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T08:50:56.096076-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T09:04:36.537826-08:00","closed_at":"2026-01-29T09:04:36.537826-08:00","close_reason":"Deleted 9 LLM-dependent files (5,938 lines), added plan_models.py, all 311 tests pass","dependencies":[{"issue_id":"mycelium-1b8w.6","depends_on_id":"mycelium-1b8w","type":"parent-child","created_at":"2026-01-29T08:50:56.096745-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1c45","title":"Implement GTSDecomposer model wrapper","description":"## Context\nPer CLAUDE.md Big 5 #4 (True Atomic Decomposition), we need GTS to decompose math problems into atomic steps during cold start.\n\n## Dependencies\n- Depends on: mycelium-yhlj (ExprNode data structures)\n\n## Goal\nCreate a wrapper class that:\n1. Loads the trained GTS model\n2. Runs inference on problem text\n3. Returns list of atomic steps ready for routing\n\n## Trained Model Location\n`trained_model/GTS-mawps/` contains:\n- model.pth (53MB)\n- config.json\n- input_vocab.json  \n- output_vocab.json\n\n## Implementation\n\nCreate `src/mycelium/gts_decomposer.py`:\n\n```python\n@dataclass\nclass DecomposedStep:\n    operation: str           # 'add two numbers'\n    expr_tree: ExprNode      # The atomic expression tree\n    extracted_values: dict   # {'NUM_0': 5, 'NUM_1': 3}\n    depends_on: list[int]    # [1] if uses step_1 result\n\nclass GTSDecomposer:\n    def __init__(self, model_path: str = 'trained_model/GTS-mawps'):\n        '''Load GTS model and vocabularies.'''\n        ...\n    \n    def decompose(self, problem_text: str) -\u003e list[DecomposedStep]:\n        '''\n        Main entry point per New Favorite Pattern.\n        \n        1. Extract numbers, replace with NUM tokens\n        2. Run GTS inference -\u003e prefix expression\n        3. Parse prefix -\u003e expression tree\n        4. Recursively decompose to atomic steps\n        5. Return list of DecomposedStep\n        '''\n        ...\n    \n    def _extract_numbers(self, text: str) -\u003e tuple[dict, str]:\n        '''Extract numbers and replace with NUM_0, NUM_1, etc.'''\n        ...\n    \n    def _run_inference(self, normalized_text: str) -\u003e str:\n        '''Run GTS model to get prefix expression.'''\n        ...\n```\n\n## Model Loading Strategy\nSince MWPToolkit has dependency issues, implement custom PyTorch model loading:\n1. Load state dict from model.pth\n2. Reconstruct GTS architecture from config\n3. Run inference without MWPToolkit dependency\n\n## Tests Required\n- test_number_extraction\n- test_model_loading\n- test_inference_output_format\n- test_full_decomposition_pipeline\n\n## Acceptance Criteria\n- [ ] GTSDecomposer loads model without MWPToolkit\n- [ ] decompose() returns list of atomic DecomposedStep\n- [ ] Each step has operation string suitable for graph embedding\n- [ ] Follows New Favorite Pattern (single decompose() entry point)","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T12:27:31.739363-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T12:53:05.428734-08:00","closed_at":"2026-01-29T12:53:05.428734-08:00","close_reason":"All implemented with 208 tests passing. Committed in 2b96e5b.","dependencies":[{"issue_id":"mycelium-1c45","depends_on_id":"mycelium-yhlj","type":"blocks","created_at":"2026-01-29T12:27:51.522626-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-1c45","depends_on_id":"mycelium-nqv7","type":"blocks","created_at":"2026-01-29T12:28:36.970381-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-1hg","title":"Paper: Run experiments and fill in Table 1 results","description":"## Task\nRun experiments on MATH dataset and fill in the results table in paper.md\n\n## Location\n~/Desktop/mycelium/paper.md - Section 4.2 Results\n\n## What to measure\n| Method | Accuracy | Step Reuse |\n|--------|----------|------------|\n| Direct Solve | -- | -- |\n| Chain-of-Thought | -- | -- |\n| Mushroom (ours) | -- | -- |\n\n## How to run\n```bash\ncd ~/Desktop/mycelium\nuv run python scripts/pipeline_runner.py --mode math --category algebra --limit-per-cat 50 --min-level 1 --max-level 3 --workers 2\n```\n\n## Baselines needed\n1. Direct solve: No decomposition, just solve problem directly\n2. Chain-of-thought: Standard CoT prompting\n3. Mushroom: Our full system with signature matching\n\n## Deliverable\nUpdate paper.md Table 1 with actual numbers","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:42:55.192392-08:00","updated_at":"2026-01-09T10:01:38.97243-08:00","closed_at":"2026-01-09T10:01:38.97243-08:00"}
{"id":"mycelium-1jch","title":"Perf: Sync sleep blocks event loop in DB retry","description":"find_or_create() uses time.sleep() for DB retry backoff, blocking entire event loop.\n\nLocation: db.py:421\n\nImpact: HIGH - 100-500ms blocked per retry under DB contention\n\nFix: Ensure solver.py calls find_or_create_async() exclusively, which uses await asyncio.sleep()\n\nCaller at solver.py:635 should await the async version.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:01:53.145963-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T15:06:34.041757-08:00","closed_at":"2026-01-15T15:06:34.041757-08:00","close_reason":"Already fixed: solver.py:635 and umbrella_learner.py:285 both use find_or_create_async(). Sync version only used in tests which run synchronously."}
{"id":"mycelium-1jwx","title":"Add debug logging for step-node stats usage in routing","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-22T10:52:34.895805-08:00","created_by":"Bryce Roche","updated_at":"2026-01-22T10:56:11.494002-08:00","closed_at":"2026-01-22T10:56:11.494002-08:00","close_reason":"Added debug logging for step-node stats in routing"}
{"id":"mycelium-1n91","title":"Refactor: Consolidate database connections through data layer","description":"## Context (CLAUDE.md New Favorite Pattern)\nPer CLAUDE.md: \"consolidate methods - for example all database connections should go through a data layer instead of having multiple database connections\"\n\n## Problem\nSeveral files create their own `sqlite3.connect()` instead of using centralized connection management from `data_layer/connection.py`.\n\n## Files to Update\n\n| File | Lines | Current Pattern |\n|------|-------|-----------------|\n| `src/mycelium/embedding_cache.py` | 289, 310, 745 | Own `sqlite3.connect()` |\n| `src/mycelium/step_signatures/operational_alignment.py` | 44 | Own `_get_connection()` method |\n| `src/mycelium/step_signatures/decay.py` | 196 | Own `sqlite3.connect()` |\n| `src/mycelium/step_signatures/stats.py` | 68 | Direct `sqlite3.connect()` |\n| `src/mycelium/step_signatures/scoring.py` | 83, 108 | Direct `sqlite3.connect()` |\n\n## Solution\n1. Review `data_layer/connection.py` for the canonical connection pattern\n2. Update each file to either:\n   - Accept a db/connection parameter from caller, OR\n   - Use the shared connection factory from data_layer\n3. Ensure consistent timeout, WAL mode, and thread safety settings\n\n## Acceptance Criteria\n- [ ] No direct `sqlite3.connect()` calls outside of `data_layer/connection.py` and `db.py`\n- [ ] All files use consistent connection settings (timeout=30.0, WAL mode)\n- [ ] Tests pass\n- [ ] No performance regression\n\n## Notes\n- `embedding_cache.py` has its own DB file - may need its own connection manager but should follow same pattern\n- Be careful with thread safety - some modules may need thread-local connections","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T17:58:02.406685-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T18:13:28.353553-08:00","closed_at":"2026-01-26T18:13:28.353553-08:00","close_reason":"Consolidated DB connections: embedding_cache.py, operational_alignment.py, scoring.py, stats.py now use data layer. Added lazy imports to break circular dependencies."}
{"id":"mycelium-1pg","title":"Add structured logging to council_v2.py","description":"Replace print statements and add consistent logger.info/debug/warning calls throughout council_v2.py. Use logger = logging.getLogger(__name__) pattern.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:16.110842-08:00","updated_at":"2026-01-09T07:48:22.704275-08:00","closed_at":"2026-01-09T07:48:22.704275-08:00"}
{"id":"mycelium-1pug","title":"Signature repointing \u0026 cosine sim weighting","description":"Two items to address:\n\n1. **Signature Repointing**: Should signatures be able to change their parent-child relationships over time? Currently relationships are fixed once created. Consider:\n   - If a child signature consistently routes better under a different parent\n   - If semantic drift makes current parent less appropriate\n   - Mechanism: periodic re-evaluation of parent-child fit\n\n2. ~~**Cosine Similarity Weighting**~~: ✅ DONE - Updated to 85/15 split (was 70/30)","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-13T05:05:50.246928-08:00","updated_at":"2026-01-13T05:10:44.529364-08:00","closed_at":"2026-01-13T05:10:44.529364-08:00"}
{"id":"mycelium-1s8","title":"Add multi-model routing for different tasks","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T12:24:33.557552-08:00","updated_at":"2026-01-08T12:37:28.79218-08:00","closed_at":"2026-01-08T12:37:28.79218-08:00"}
{"id":"mycelium-1tyx","title":"Cache step embeddings during validation pass","description":"In _validate_step_inputs(), each step's task gets embedded fresh every time. This is redundant when the same step description appears multiple times. Consider caching embeddings within the validation pass to reduce computation, especially for plans with many dependencies.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-14T06:06:42.63049-08:00","updated_at":"2026-01-15T14:22:13.832598-08:00","closed_at":"2026-01-15T14:22:13.832598-08:00","close_reason":"Replaced embedder.embed() with cached_embed() in solver.py and umbrella_learner.py. Embeddings now cached in memory+disk."}
{"id":"mycelium-1zbz","title":"Medium: Hardcoded umbrella routing threshold (0.5) inconsistent with global (0.85)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:48.817295-08:00","updated_at":"2026-01-13T11:52:58.076923-08:00","closed_at":"2026-01-13T11:52:58.076923-08:00"}
{"id":"mycelium-20i","title":"MEDIUM: Fix type inconsistency in embedder.py","description":"embed_text() returns tuple for LRU cache, get_embedding() returns ndarray. Inconsistent types between related functions. Document clearly or make consistent.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:56.243496-08:00","updated_at":"2026-01-09T08:32:43.43366-08:00","closed_at":"2026-01-09T08:32:43.43366-08:00"}
{"id":"mycelium-20n","title":"[BUG] FINAL_SYNTHESIZER and INCREMENTAL_SYNTHESIZER undefined in council_v2.py","description":"## Bug Description\nThe variables `FINAL_SYNTHESIZER` and `INCREMENTAL_SYNTHESIZER` are used in council_v2.py (lines 705, 776, 789) but are never defined or imported. These string templates are only defined in the archived council_v1.py file.\n\n## Impact\n**Severity: CRITICAL** - This will cause a `NameError` at runtime when:\n1. Any problem uses decomposition with synthesis (lines 705, 776)\n2. Incremental synthesis is triggered for complex DAGs (line 789)\n\n## Reproduction\nAny call to `_once_at_end_synthesize()` or `_incremental_synthesize()` will fail.\n\n## Suggested Fix\nEither:\n1. Import from archived file: `from ._archive.council_v1 import FINAL_SYNTHESIZER, INCREMENTAL_SYNTHESIZER`\n2. Or define the templates directly in council_v2.py (preferred for maintainability)\n3. Or use the prompt_templates.py registry which already has these templates registered as 'final_synthesizer' and 'incremental_synthesizer'\n\nThe best fix would be option 3 - use the existing prompt registry:\n```python\nfrom .prompt_templates import get_registry\n# Then replace FINAL_SYNTHESIZER.format(...) with:\nget_registry().format('final_synthesizer', problem=problem, step_results=results_str)\n```\n\n## Files Affected\n- src/mycelium/council_v2.py (lines 705, 776, 789)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:20:22.609977-08:00","updated_at":"2026-01-09T08:25:14.819083-08:00","closed_at":"2026-01-09T08:25:14.819083-08:00"}
{"id":"mycelium-21qe","title":"Consolidation: Create unified StateManager for db_metadata access","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": \"We want to consolidate methods - for example all database connections should go through a data layer instead of having multiple database connections.\"\n\ndb_metadata access is scattered across 4+ files with different query patterns:\n\n## Current Behavior\n\n**scoring.py:87, 115-132**\n```python\n# get_total_problems_solved\nconn.execute(\"SELECT value FROM db_metadata WHERE key = 'total_problems_solved'\")\n\n# increment_total_problems  \nconn.execute(\"INSERT OR REPLACE INTO db_metadata...\")\n```\n\n**decay.py:262**\n```python\nconn.execute(\"SELECT value FROM db_metadata WHERE key = 'total_problems_solved'\")\n```\n\n**mcts.py:3151-3170**\n```python\ndef _get_db_state_value(key, default):\n    # Generic getter\n    \n_KEY_NODES_FOR_SPLIT = \"nodes_for_split\"\n_KEY_HIGH_CONF_WRONG_NODES = \"high_conf_wrong_nodes\"\n_KEY_DSL_REGEN_COUNT = \"dsl_regen_count\"\n# ... more keys scattered\n```\n\n**db.py:399, 7923-7940**\n```python\n# Inline queries for sim_stats_*, last_restructure_count, etc.\n```\n\n## Expected Behavior\n\nSingle `StateManager` class in data_layer with:\n1. All db_metadata keys defined as constants\n2. Type-safe getter/setter methods\n3. Caching (with TTL for frequently accessed values)\n4. Atomic increment/update operations\n\n## Files to Create/Modify\n\n**New file: `src/mycelium/data_layer/state_manager.py`**\n```python\nclass StateManager:\n    \"\"\"Centralized db_metadata access per CLAUDE.md New Favorite Pattern.\"\"\"\n    \n    # All keys defined in one place\n    KEY_TOTAL_PROBLEMS = \"total_problems_solved\"\n    KEY_LAST_RESTRUCTURE = \"last_restructure_count\"\n    KEY_NODES_FOR_SPLIT = \"nodes_for_split\"\n    KEY_HIGH_CONF_WRONG = \"high_conf_wrong_nodes\"\n    KEY_DSL_REGEN_COUNT = \"dsl_regen_count\"\n    KEY_SIM_STATS_MATCH_COUNT = \"sim_stats_match_count\"\n    # ... all keys\n    \n    def get(self, key: str, default=None) -\u003e Any: ...\n    def set(self, key: str, value: Any) -\u003e None: ...\n    def increment(self, key: str, delta: int = 1) -\u003e int: ...\n    def get_welford_stats(self, prefix: str) -\u003e tuple[int, float, float]: ...\n    def update_welford_stats(self, prefix: str, value: float) -\u003e None: ...\n```\n\n**Modify existing files:**\n- `src/mycelium/step_signatures/scoring.py` - Use StateManager\n- `src/mycelium/step_signatures/decay.py` - Use StateManager\n- `src/mycelium/data_layer/mcts.py` - Use StateManager\n- `src/mycelium/step_signatures/db.py` - Use StateManager\n\n## Testing\n\n1. Create StateManager with all existing keys\n2. Migrate one file at a time (scoring.py first)\n3. Run tests after each migration\n4. Verify no duplicate queries remain\n\n## Context\n\nPart of Consolidation code review. High priority per CLAUDE.md.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:38:08.372435-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:15:53.477052-08:00","closed_at":"2026-01-28T12:15:53.477052-08:00","close_reason":"StateManager consolidation complete. All db_metadata access now goes through StateManager (state_manager.py). Includes: WelfordStats namedtuple, get/set/increment methods, caching with TTL, and convenience functions. scoring.py and decay.py migrated."}
{"id":"mycelium-29j","title":"CRITICAL: Replace unsafe eval() with ast.literal_eval","description":"step_signatures.py:449 uses eval() which is a security risk even with restricted builtins. Replace with ast.literal_eval() or a dedicated expression parser.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:21:42.692277-08:00","updated_at":"2026-01-09T08:26:47.406034-08:00","closed_at":"2026-01-09T08:26:47.406034-08:00"}
{"id":"mycelium-2dkk","title":"High: No recursion depth limit in umbrella routing","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:38.785244-08:00","updated_at":"2026-01-13T11:51:48.320923-08:00","closed_at":"2026-01-13T11:51:48.320923-08:00"}
{"id":"mycelium-2pd","title":"Create PromptTemplate registry system","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:16.349886-08:00","updated_at":"2026-01-09T06:40:04.256581-08:00","closed_at":"2026-01-09T06:40:04.256581-08:00"}
{"id":"mycelium-2q1","title":"Improve async error handling in council_v2.py","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T05:54:15.402849-08:00","updated_at":"2026-01-09T06:40:05.652224-08:00","closed_at":"2026-01-09T06:40:05.652224-08:00"}
{"id":"mycelium-2rss","title":"Divergence-point analysis: compare winning vs losing thread paths","description":"When multi-path exploration produces both winning and losing threads, compare their paths to identify the source of failure.\n\n## The Insight\n\n```\nThread A (won):  step1→X → step2→Y → step3→Z ✓\nThread B (lost): step1→X → step2→W → step3→Q ✗\n                          ↑ divergence\n```\n\nThe failure could be caused by:\n1. **Divergence point** (step2→W) - wrong routing choice\n2. **Downstream step** (step3→Q) - divergence was fine, but this choice was bad\n3. **Both** - compounding errors\n\n## Implementation\n\n1. **Find thread pairs**: Identify winning/losing thread pairs that share a common prefix\n2. **Locate divergence**: Find the first (dag_step_id, node_id) where they differ\n3. **Compare suffixes**: For each step AFTER divergence in the losing thread:\n   - Does the winning thread have the same dag_step with a different node? → direct comparison\n   - Did the losing thread's node perform poorly elsewhere? → cross-reference\n4. **Assign targeted blame**:\n   - Divergence point node in losing thread → blame (made wrong choice)\n   - Divergence point node in winning thread → credit (made right choice)\n   - Downstream nodes unique to losing thread → proportional blame based on step distance from divergence\n5. **Track patterns**: Accumulate which (dag_step, node) pairs consistently appear in losing paths\n\n## Data needed\n\nQuery mcts_thread_steps joined with mcts_threads:\n- Group by dag_id to get all threads for a problem\n- Order steps by dag_step_id (or step sequence)\n- Compare paths between winning (success=1) and losing (success=0) threads\n\n## Expected outcome\n\nMore precise credit/blame assignment:\n- Instead of \"high confidence in losing thread → partial credit\"\n- We get \"this specific node at this specific step caused the failure\"","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T06:46:12.895028-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:23:51.037954-08:00","closed_at":"2026-01-21T08:23:51.037954-08:00","close_reason":"Implemented divergence-point analysis: ThreadPath/DivergencePoint dataclasses, get_thread_paths(), find_divergence_points(), assign_divergence_blame(). Wired into run_postmortem_with_interference(). Commit 30ed62a."}
{"id":"mycelium-2spk","title":"Big 3: Move restructure cluster thresholds to config","description":"Per CLAUDE.md 'The Flow': Hardcoded thresholds in restructure logic.\n\n**Violations**:\n- db.py:8985 - `0.85` min threshold, `2.0` std multiplier\n- db.py:8988 - `0.90` cold start fallback\n\n**Fix**: Add to config.py:\n```python\nRESTRUCTURE_CLUSTER_MIN_THRESHOLD = 0.85\nRESTRUCTURE_CLUSTER_STD_MULTIPLIER = 2.0\nCOLD_START_CLUSTER_FALLBACK_THRESHOLD = 0.90\n```","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:32.78291-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T06:12:39.493251-08:00","closed_at":"2026-01-29T06:12:39.493251-08:00","close_reason":"Restructure logic (line 9054) now uses compute_cluster_threshold() which uses config constants CLUSTER_THRESHOLD_*. No hardcoded 0.85/0.90/2.0 values remain. All 395 tests pass."}
{"id":"mycelium-2szo","title":"Refactor: db.py is 2000 lines - identify simplification opportunities","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:01:13.040965-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:14:23.470668-08:00","closed_at":"2026-01-15T09:14:23.470668-08:00","close_reason":"Analysis complete. db.py has 2027 lines organized into 10 logical sections.\n\n## Simplification Opportunities\n\n### 1. Extract hierarchy.py (~400 lines)\n- route_through_hierarchy(), _route_hierarchical()\n- get_children(), get_parent(), add_child(), remove_child()\n- promote_to_umbrella(), get_umbrella_signatures(), find_deeper_signature()\n- propagate_centroid_to_parents()\n\n### 2. Extract usage_tracking.py (~260 lines)\n- record_usage(), get_signature_examples()\n- update_problem_outcome(), _collect_parent_credits()\n\n### 3. Extract centroids.py (~150 lines)\n- update_centroid(), _update_centroid_atomic()\n- _ensure_centroid_matrix(), invalidate_centroid_matrix()\n\n### 4. Potentially Dead Code (~150 lines)\nMethods defined but never called:\n- get_signatures_with_dsl()\n- get_signatures_needing_nl()\n- merge_duplicates()\n- clear_all_data() (may be useful for testing)\n\n## Result\nAfter extractions, db.py would be ~1100 lines, focused on core find/create operations.\n\n## Recommendation\nPer CLAUDE.md 'smooth refactoring - not all at once', extract one module at a time starting with hierarchy.py (largest, clearest boundary)."}
{"id":"mycelium-2tf6","title":"MCTS Phase 3: Implement multi-path exploration","description":"Part of mycelium-5vp4 (Adaptive compute budget)\n\nCore implementation:\n- get_alternative_paths() returns top-k routing paths\n- Execute each path, collect results\n- Pick best result by confidence\n- Backpropagate success/failure to ALL paths (learning signal)\n\nThis completes the MCTS loop per CLAUDE.md.\n\nFiles: solver.py, db.py","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:01:39.444093-08:00","created_by":"Bryce Roche","updated_at":"2026-01-16T04:59:46.1243-08:00","closed_at":"2026-01-16T04:59:46.1243-08:00","close_reason":"Implemented multi-path exploration with backpropagation to all explored signatures","dependencies":[{"issue_id":"mycelium-2tf6","depends_on_id":"mycelium-hl01","type":"blocks","created_at":"2026-01-15T20:02:04.808863-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-2ul","title":"Minimize signature injection friction, maximize usefulness","description":"How do we maximize the usefulness of each signature injection?\n\nCurrent friction points to investigate:\n- Are injected signatures too verbose? Too terse?\n- Is the method_template format optimal for LLM consumption?\n- Do we inject too much context or too little?\n- Are we injecting the right signatures (precision vs recall tradeoff)?\n\nIdeas to explore:\n- Signature compression: distill to essential pattern only\n- Adaptive verbosity: more detail for complex steps, less for simple\n- Parameter extraction: clearly separate reusable logic from problem-specific params\n- Confidence-weighted injection: stronger signal for high-reliability signatures\n- Format optimization: what prompt structure minimizes reasoning tokens?\n\nGoal: each injection should feel like giving the LLM a well-documented function to call, not a wall of text to parse.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T16:31:31.387-08:00","updated_at":"2026-01-08T17:07:50.237564-08:00","closed_at":"2026-01-08T17:07:50.237564-08:00"}
{"id":"mycelium-2v27","title":"High: Stale routing scores - last_used_at updated on match not success","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:38.147084-08:00","updated_at":"2026-01-13T11:44:15.525757-08:00","closed_at":"2026-01-13T11:44:15.525757-08:00"}
{"id":"mycelium-2x6j","title":"Cleanup: Remove dead code (disabled LLM rewriting feature)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:34:58.170656-08:00","updated_at":"2026-01-13T12:02:02.579155-08:00","closed_at":"2026-01-13T12:02:02.579155-08:00"}
{"id":"mycelium-2y2","title":"Migrate council_v2.py to use PromptTemplate registry","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:47:11.474003-08:00","updated_at":"2026-01-09T08:32:17.052389-08:00","closed_at":"2026-01-09T08:32:17.052389-08:00"}
{"id":"mycelium-2ye","title":"arXiv paper: Mycelium step-level signature networks","description":"# arXiv Paper: Mycelium Step-Level Signature Networks\n\n## Core Innovation\nStep-level signature networks with wave-theoretic matching for self-improving math problem solving.\n\n## Novel Contributions (Paper-Worthy)\n\n| Contribution | Novelty | Evidence |\n|--------------|---------|----------|\n| **Step-level decomposition + signature reuse** | High | V1→V2 evolution shows step-level outperforms whole-problem |\n| **Wave interference matching** | High | +4% accuracy over cosine baseline (ABLATION_REPORT.md) |\n| **Superposition execution** | Medium-High | Present top-k weighted methods instead of hard collapse |\n| **Essence subspace + wave compensation** | Medium | Essence alone hurts (-4%), wave restores (+8%) |\n| **Lift-gated injection** | Medium | Only inject methods with demonstrated positive lift |\n| **Resonance model** | Experimental | Physics-inspired frequency overlap matching |\n\n## Experimental Results Summary\n- **Wave+Normalized**: 84% accuracy, 34% reuse rate (best)\n- **Cosine baseline**: 78-80% accuracy\n- **Essence-only**: 74% (-4% vs baseline) - key negative result\n- **MCTS on hard problems (L3)**: +33% improvement\n\n## Proposed Paper Structure\n\n### Title Options\n1. \"Mycelium: Self-Improving Problem Solving through Step-Level Signature Networks\"\n2. \"Wave-Theoretic Matching for Reusable Solution Patterns in Mathematical Reasoning\"\n\n### Venue: cs.AI (primary) + cs.LG (cross-list)\n\n### Outline\n1. Abstract (150 words)\n2. Introduction (1-1.5 pages)\n3. Related Work (0.75 page)\n4. Method: Mycelium (2-3 pages)\n5. Experiments (2 pages)\n6. Analysis \u0026 Discussion (1 page)\n7. Limitations \u0026 Future Work\n8. Conclusion\n\n## Data Collection Tasks\n- [ ] Run 50 problems × 5 modes (cosine, essence, interference, resonance, auto)\n- [ ] Statistical significance analysis (need n=200+ for 10% effects)\n- [ ] Compare against published baselines (MathPrompter, PAL)\n\n## Key Figures Needed\n1. Architecture diagram\n2. Ablation bar chart: Accuracy by matching mode\n3. Reuse rate over training\n4. Wave function visualization\n5. Signature lifecycle diagram","status":"blocked","priority":2,"issue_type":"feature","created_at":"2026-01-09T05:12:31.216552-08:00","updated_at":"2026-01-09T07:40:36.5844-08:00"}
{"id":"mycelium-3447","title":"Bug: refinement.py references non-existent model fields","description":"refinement.py (lines 211-269) references model fields that don't exist in the current StepSignature model:\n- injected_uses\n- injected_successes  \n- non_injected_uses\n- non_injected_successes\n- dsl_version\n\nIt also calls db methods that don't exist:\n- get_signatures_for_dsl_improvement()\n- reset_lift_stats_for_dsl_version()\n- get_signatures_with_successful_dsls()\n- create_child_signature()\n\nOptions:\n1. Add these fields/methods to implement A/B testing lift tracking\n2. Refactor refinement.py to use existing uses/successes fields\n3. Remove refinement.py if it's unused prototype code\n\nTests currently mock these to pass, but the module is not functional.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-14T06:27:21.426714-08:00","updated_at":"2026-01-14T06:55:19.211146-08:00","closed_at":"2026-01-14T06:55:19.211146-08:00","close_reason":"Removed dead code - module was never used"}
{"id":"mycelium-3bt","title":"I/O schema backfill process","description":"## Summary\nCreated `scripts/backfill_io_schemas.py` to populate io_schema for signatures after training runs.\n\n## The Problem\nOnly 6% of signatures had I/O schemas stored, meaning:\n- Structured prompts weren't being used\n- Input/output validation wasn't happening\n- `general_step` (42% of uses) had no schema at all\n\n## Solution\nPost-training backfill process that:\n1. Finds reliable signatures (uses \u003e= 5) without io_schema\n2. Applies default schemas based on step_type\n3. Optionally uses LLM to generate schemas for unknown types\n\n## Coverage\n- **Before**: 6% of signatures had I/O schema\n- **After**: 60% total, **100% of reliable signatures**\n\n## Default Schemas Defined\n14 step types covered:\n- Core math: solve_equation, simplify_expression, substitute_value\n- Arithmetic: compute_sum, compute_product, compute_division, compute_percentage\n- Specialized: compute_geometry, evaluate_function, factor_expression\n- Meta: synthesize_answer, compare_values, apply_formula, general_step\n\n## Usage\n```bash\n# Dry run first\nuv run python scripts/backfill_io_schemas.py --dry-run\n\n# Apply defaults\nuv run python scripts/backfill_io_schemas.py\n\n# Use LLM for unknown types\nuv run python scripts/backfill_io_schemas.py --use-llm\n```\n\n## Next Steps\n- Run backfill after each training session\n- Track whether I/O schema usage improves success rate\n- Consider auto-running backfill in pipeline_runner post-training","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:54:36.86585-08:00","updated_at":"2026-01-08T13:54:42.958094-08:00","closed_at":"2026-01-08T13:54:42.958094-08:00"}
{"id":"mycelium-3d5","title":"Paper: Analyze and visualize signature growth over training","description":"## Task\nAnalyze how the signature library grows over training and write up findings\n\n## Location\n~/Desktop/mycelium/paper.md - Section 5, \"Signature Growth Over Training\"\n\n## Analysis to perform\n1. Track number of signatures over time/problems solved\n2. Plot signature count vs problems solved (or create ASCII/markdown table)\n3. Identify: Does growth slow down? (suggesting finite \"prime\" set)\n4. Show convergence toward a stable signature library\n\n## Data source\n```bash\nsqlite3 ~/Desktop/mycelium/results/mycelium.db\nSELECT COUNT(*), DATE(created_at) FROM step_signatures GROUP BY DATE(created_at);\n```\n\n## Deliverable\n- 1-2 paragraphs describing growth pattern\n- Table or description of growth curve\n- Key insight: library converges, supporting \"finite primes\" analogy","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:42:59.395678-08:00","updated_at":"2026-01-09T09:52:58.895627-08:00","closed_at":"2026-01-09T09:52:58.895627-08:00"}
{"id":"mycelium-3ew","title":"HIGH: Remove unused _data_layer_db import","description":"step_signatures.py:52 imports _data_layer_db but it appears unused. Remove if dead code or document why needed.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:48.893837-08:00","updated_at":"2026-01-09T08:25:32.478725-08:00","closed_at":"2026-01-09T08:25:32.478725-08:00"}
{"id":"mycelium-3g7","title":"[EPIC] Codebase refactoring","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-09T08:34:21.648647-08:00","updated_at":"2026-01-09T10:56:05.822721-08:00","closed_at":"2026-01-09T10:56:05.822721-08:00"}
{"id":"mycelium-3i5","title":"Add LLM-based step type classification","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T12:24:25.542582-08:00","updated_at":"2026-01-08T12:35:49.610207-08:00","closed_at":"2026-01-08T12:35:49.610207-08:00"}
{"id":"mycelium-3pdn","title":"Modify StepSignature model: dsl_script → func_pointer","description":"## Goal\nUpdate `src/mycelium/step_signatures/models.py` to use function pointers instead of DSL scripts.\n\n## Changes to StepSignature dataclass\n\n### Remove\n- `dsl_script: Optional[str]`\n- `dsl_type: str`\n\n### Add\n- `func_name: Optional[str]`  # Key into FUNCTION_REGISTRY\n- `func_arity: int = 2`       # Expected number of arguments\n\n### Keep\n- All embedding/centroid fields\n- All Welford statistics fields\n- All routing fields\n\n## Update Methods\n- `has_dsl` property → `has_func` property\n- `from_row()` - handle new columns\n- Any serialization methods\n\n## Database Migration\n- Add columns: func_name, func_arity\n- Deprecate: dsl_script, dsl_type (can keep for backwards compat initially)\n\n## Acceptance Criteria\n- [ ] StepSignature uses func_name instead of dsl_script\n- [ ] Database schema updated\n- [ ] Existing code doesn't break (gradual migration)","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:53:19.868063-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:04:15.108456-08:00","closed_at":"2026-01-31T06:04:15.108456-08:00","close_reason":"Model updated: removed dsl_script/dsl_type, added func_name/func_arity, has_dsl→has_func","dependencies":[{"issue_id":"mycelium-3pdn","depends_on_id":"mycelium-icv4","type":"blocks","created_at":"2026-01-31T05:54:33.025725-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-3qq","title":"Add mypy strict mode type checking","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:29.496259-08:00","updated_at":"2026-01-09T06:36:37.073253-08:00","closed_at":"2026-01-09T06:36:37.073253-08:00"}
{"id":"mycelium-3s6r","title":"Refactor: Split db.py into smaller modules","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T11:05:47.875457-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T17:50:06.780544-08:00","closed_at":"2026-01-20T17:50:06.780544-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-3vy","title":"Standardize I/O format for step signatures to help solver","description":"## Exploration: Standardize I/O Format for Step Signatures\n\n### Current State Analysis\n\n**Method Templates (current)**:\n```\ncompute_percentage: \"Convert percentage to decimal (divide by 100) and multiply.\"\ncompute_product: \"Multiply all values together.\"\nsolve_equation: \"Isolate the variable by performing inverse operations on both sides.\"\ncompute_sum: \"Add all values together.\"\n```\n\n**Step Examples (current)**:\n```\nType: compute_percentage\nStep: \"Convert the percentage to a decimal\"\n\nType: compute_product  \nStep: \"Multiply the decimal by the number (80)\"\n\nType: solve_equation\nStep: \"Subtract 5 from both sides of the equation\"\n```\n\n**Problems Identified**:\n\n1. **Unstructured context passing**: Previous step results passed as raw strings\n   ```python\n   ctx_str += f\"- {dep_id}: {context[dep_id]}\\n\"\n   # Results in: \"- step_1: 0.25\\n- step_2: The product is 20\"\n   ```\n\n2. **No input specification**: Method templates don't say what inputs they need\n   - \"compute_product\" needs 2+ numbers, but doesn't specify where to get them\n\n3. **Inconsistent output formats**: Results vary wildly\n   - \"0.25\" vs \"The decimal is 0.25\" vs \"25% = 0.25\"\n   - Solver has to parse natural language\n\n4. **No validation possible**: Can't check if step produced expected output type\n\n### Proposed I/O Schema Design\n\n```python\n@dataclass\nclass StepIOSchema:\n    \"\"\"Input/Output specification for a step type.\"\"\"\n    \n    # What this step needs from previous steps\n    inputs: list[InputSpec]  # e.g., [InputSpec(name=\"value\", type=\"numeric\")]\n    \n    # What this step produces\n    output: OutputSpec  # e.g., OutputSpec(type=\"numeric\", format=\"decimal\")\n    \n    # Enhanced method template with I/O placeholders\n    method_template_v2: str  # \"Given {value}, divide by 100 to get decimal. Output: {result}\"\n\n@dataclass  \nclass InputSpec:\n    name: str  # \"value\", \"percentage\", \"quantity\"\n    type: str  # \"numeric\", \"expression\", \"text\"\n    source: str = \"previous\"  # \"previous\", \"problem\", \"computed\"\n    description: str = \"\"\n\n@dataclass\nclass OutputSpec:\n    type: str  # \"numeric\", \"expression\", \"boolean\", \"text\"\n    format: str = \"\"  # \"decimal\", \"integer\", \"fraction\", \"equation\"\n    unit: str = \"\"  # \"$\", \"%\", \"units\", etc.\n```\n\n### Example: compute_percentage with I/O schema\n\n**Current**:\n```\nmethod_template: \"Convert percentage to decimal (divide by 100) and multiply.\"\n```\n\n**With I/O Schema**:\n```python\nStepIOSchema(\n    inputs=[\n        InputSpec(name=\"percentage\", type=\"numeric\", description=\"The percentage value\"),\n        InputSpec(name=\"base_value\", type=\"numeric\", description=\"The value to take percentage of\"),\n    ],\n    output=OutputSpec(type=\"numeric\", format=\"decimal\"),\n    method_template_v2=\"\"\"\n    Given percentage={percentage} and base_value={base_value}:\n    1. Convert percentage to decimal: {percentage} / 100 = {decimal}\n    2. Multiply: {decimal} × {base_value} = {result}\n    \n    OUTPUT: {result} (numeric decimal)\n    \"\"\"\n)\n```\n\n### Enhanced Prompt with I/O Schema\n\n```python\nSTEP_SOLVER_WITH_IO = \"\"\"You are solving ONE step of a multi-step math problem.\n\n**Input values from previous steps:**\n{formatted_inputs}\n\n**Your task:** {task}\n\n**Method:** {method_template}\n\n**Expected output format:** {output_format}\n\nSolve this step. Output your result as:\nRESULT: [single value matching expected format]\n\"\"\"\n```\n\n### Benefits\n\n1. **Structured input extraction**: Parse previous results into named variables\n2. **Explicit dependencies**: Know exactly what values a step needs\n3. **Output validation**: Check result matches expected type/format\n4. **Better method templates**: More specific with placeholder variables\n5. **Chaining reliability**: Clear contract between steps\n\n### Implementation Approach\n\n**Phase 1: Schema definition**\n- Add `input_schema` and `output_schema` to StepSignature\n- Define common input/output types\n\n**Phase 2: Schema inference**\n- Analyze existing step_type to infer likely I/O schema\n- Use LLM to extract I/O spec from step text\n\n**Phase 3: Enhanced execution**\n- Format inputs according to schema\n- Validate outputs match schema\n- Track schema compliance in success metrics\n\n### Open Questions\n\n1. Should schema be strict (reject non-conforming) or advisory (best effort)?\n2. How to handle steps with variable number of inputs?\n3. Should we auto-infer schema from successful examples?\n4. How complex should output format validation be?\n\n### Recommendation\n\nStart with **advisory mode**: use I/O schema to improve prompts but don't hard-fail on non-conformance. Track conformance as a metric to evaluate impact before making it strict.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:17:26.931977-08:00","updated_at":"2026-01-08T08:39:45.915853-08:00","closed_at":"2026-01-08T08:39:45.915853-08:00"}
{"id":"mycelium-3wcq","title":"Refactor: dsl_templates.py is 640 lines - review operation inference bloat","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:01:18.859309-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:22:24.756378-08:00","closed_at":"2026-01-15T09:22:24.756378-08:00","close_reason":"Removed dead _OPERATION_ANCHORS code. 644→626 lines."}
{"id":"mycelium-3zti","title":"Big 3: Direct DB access in umbrella_learner.py","description":"Per CLAUDE.md 'System Independence': umbrella_learner.py:493-512 has direct DB query for failing step descriptions.\n\n**Fix**: Create `mcts.get_failing_step_descriptions(node_id)` function in data_layer.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:26.813347-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T05:58:36.387293-08:00","closed_at":"2026-01-29T05:58:36.387293-08:00","close_reason":"Created get_failing_step_descriptions() in data_layer. Removed direct DB access from umbrella_learner.py."}
{"id":"mycelium-41xa","title":"Bug: Planner doesn't generate dsl_hint for complex multi-reference steps","description":"\n## Problem\nSome steps like 'Calculate remaining time after traffic and slow drive' don't get dsl_hint from the planner, causing empty predictions.\n\n## Root Cause\nThe planner's Phase 2 step generation doesn't always create dsl_hints for steps that require multiple intermediate values.\n\n## Impact\n- Empty predictions in gsm8k_8, gsm8k_19\n- Steps fail with 'No dsl_hint for step X, skipping DSL'\n\n## Evidence\nSteps in decomposition list that fail:\n- 'Calculate remaining time after traffic'\n- 'Calculate remaining distance'\n- 'Calculate distance traveled during traff'\n\n## Potential Fix\n1. Ensure Phase 2 always generates dsl_hint for arithmetic steps\n2. Or fallback to LLM-generated expression when dsl_hint missing","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T16:47:11.601324-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T17:30:57.682761-08:00","closed_at":"2026-01-26T17:30:57.682761-08:00","close_reason":"Implemented dsl_hint inference from operation/task and formula evaluation for extracted_values. Accuracy improved from 70% to 75%."}
{"id":"mycelium-42ny","title":"Consolidation: Move cache size magic numbers to config.py","description":"## Problem\n\nPer CLAUDE.md \"The Flow\": Minimize usage of magic numbers.\n\nSeveral cache sizes are hardcoded in modules instead of config.py:\n\n| File | Constant | Value |\n|------|----------|-------|\n| operation_extractor.py:144 | `_CACHE_MAX_SIZE` | 1000 |\n| graph_extractor.py:396 | `_GRAPH_CACHE_MAX_SIZE` | 500 |\n| utils.py:17 | `_CENTROID_CACHE_MAX_SIZE` | 10000 |\n\nMeanwhile, config.py already has similar constants:\n- `DSL_EXPR_CACHE_MAX_SIZE = 1000`\n- `SIGNATURE_CACHE_MAX_SIZE = 1000`\n- `CHILDREN_CACHE_MAX_SIZE = 500`\n\n## Solution\n\n1. Add to config.py:\n   - `OPERATION_EMBEDDING_CACHE_MAX_SIZE = 1000`\n   - `GRAPH_EMBEDDING_CACHE_MAX_SIZE = 500`\n   - `CENTROID_CACHE_MAX_SIZE = 10000`\n\n2. Update modules to import from config.py\n\n## Files to Modify\n\n- src/mycelium/config.py\n- src/mycelium/step_signatures/operation_extractor.py\n- src/mycelium/step_signatures/graph_extractor.py\n- src/mycelium/step_signatures/utils.py","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:40:04.627976-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:49:18.405259-08:00","closed_at":"2026-01-28T12:49:18.405259-08:00","close_reason":"Moved cache size magic numbers to config.py: CENTROID_CACHE_MAX_SIZE (10000) and GRAPH_EMBEDDING_CACHE_MAX_SIZE (500). Updated utils.py and graph_extractor.py to import from config. Per The Flow: thresholds from config, not magic numbers. 369 tests pass."}
{"id":"mycelium-42o","title":"Standardize datetime handling to UTC","description":"Mix of datetime.now() and datetime.utcnow() causes timezone inconsistencies","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T11:20:27.882324-08:00","updated_at":"2026-01-09T11:29:08.878936-08:00","closed_at":"2026-01-09T11:29:08.878936-08:00"}
{"id":"mycelium-473","title":"Fix answer normalization: convert % to decimal instead of stripping","description":"Answer normalization strips %/percent instead of converting to a decimal, so \"50%\" normalizes to \"50\" and can produce false-positive equivalence. Fix in answer_norm.py (line 165) - should convert 50% to 0.5 instead of just removing the percent sign.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:17:18.160238-08:00","updated_at":"2026-01-08T13:22:16.551556-08:00","closed_at":"2026-01-08T13:22:16.551556-08:00"}
{"id":"mycelium-4ai9","title":"Refactor: Create ValidationContext class to unify validation functions","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T14:55:38.96765-08:00","updated_at":"2026-01-20T17:50:06.440627-08:00","closed_at":"2026-01-20T17:50:06.440627-08:00","close_reason":"Stale - older than Jan 15, deprioritizing","dependencies":[{"issue_id":"mycelium-4ai9","depends_on_id":"mycelium-g4mt","type":"blocks","created_at":"2026-01-13T14:55:54.132021-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-4nsb","title":"Perf: Embedding cache has no auto-prune","description":"Disk cache grows unbounded between manual prune cycles.\n\nLocation: embedding_cache.py:462-488\n\nImpact: MEDIUM - 5-50ms per lookup after weeks of runtime (cache DB grows to 100s MB)\n\nprune_old() exists but is never automatically called. TTL is 30 days.\n\nFix: Add prune on startup or background task every N hours.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:02:56.547601-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.12371-08:00","closed_at":"2026-01-20T18:00:01.12371-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-4ome","title":"Infra: Add DB/log pruning strategy (unbounded growth)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:34:59.162809-08:00","updated_at":"2026-01-20T17:50:06.553252-08:00","closed_at":"2026-01-20T17:50:06.553252-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-4sw5","title":"Consolidate routing to single pathway","description":"**Current State:** 5 routing entry points with code duplication:\n- route_through_hierarchy (DFS with path tracking)\n- route_with_confidence (DFS with MCTS confidence)\n- _route_hierarchical (DFS with cold-start fork logic)\n- route_by_graph_embedding (BFS wrapper)\n- _route_by_graph_hierarchical (BFS top-k)\n\n**Goal:** Single internal _route_core() that all variations use, with options for:\n- Algorithm: DFS vs BFS\n- Return type: single best vs top-k\n- Features: confidence scoring, path tracking, fork logic\n\n**Files:** src/mycelium/step_signatures/db.py","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T13:21:59.421771-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T13:30:42.736075-08:00","closed_at":"2026-01-25T13:30:42.736075-08:00","close_reason":"Consolidated DFS routing to _route_core(). Both route_through_hierarchy and route_with_confidence now use this single pathway. Removed ~150 lines of duplicated logic."}
{"id":"mycelium-4u3","title":"HIGH: Add logging to silent exception handlers","description":"model_router.py:189 has 'except Exception: continue' with no logging. Routing failures go undetected. Add logging and catch specific types only.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:21:46.169648-08:00","updated_at":"2026-01-09T08:27:23.38883-08:00","closed_at":"2026-01-09T08:27:23.38883-08:00"}
{"id":"mycelium-54ag","title":"Feature: Expand decomposition triggers beyond DSL confidence","description":"Currently we only decompose on low DSL confidence. Expand triggers to also decompose when: (1) LLM outputs symbolic when numeric values are available, (2) Output doesn't reflect actual context values, (3) Output type mismatches expected type. This catches more failure modes and routes them to decomposition for better accuracy.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T10:45:24.566505-08:00","updated_at":"2026-01-20T17:50:06.304293-08:00","closed_at":"2026-01-20T17:50:06.304293-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-5cn0","title":"Feature: Cold start mode (first 20 problems flat under root)","description":"## Summary\nImplement cold start mode where the first 20 problems create flat leaf nodes as children of root, collecting Welford stats before any restructuring.\n\n## Config\n```python\n# config.py\nCOLD_START_THRESHOLD = 20  # problems before restructuring begins\n```\n\n## Behavior\n### During Cold Start (problems 1-20)\n1. All new signatures auto-accepted as ROOT children (flat structure)\n2. No umbrella promotions\n3. No sibling vs child decisions - everything is a sibling under root\n4. Welford stats accumulate for every routing and execution\n\n### After Cold Start (problems 21+)\n1. Welford stats guide sibling vs child decisions\n2. Auto-restructure process can create umbrella nodes\n3. Proposals may be rejected/merged based on stats\n\n## Implementation\n1. Add `get_total_problems_solved()` to db.py (count distinct problem_ids in mcts_threads)\n2. Add `is_cold_start() -\u003e bool` helper\n3. Modify signature creation to check cold start:\n   - If cold start: always add as child of root\n   - If not cold start: use Welford decision logic\n4. Disable umbrella promotion during cold start\n\n## Rationale\nPer CLAUDE.md: \"System is designed to aggressively branch out early, tapering off later.\"\nCold start collects the statistical foundation needed for principled branching decisions.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-27T06:38:00.987139-08:00","created_by":"Bryce Roche","updated_at":"2026-01-27T08:13:50.416012-08:00","closed_at":"2026-01-27T08:13:50.416012-08:00","close_reason":"Implemented in commit 1f1ee9e: flat structure + blocked umbrella promotions during cold start","dependencies":[{"issue_id":"mycelium-5cn0","depends_on_id":"mycelium-bjrf","type":"blocks","created_at":"2026-01-27T06:38:08.639837-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-5cn0","depends_on_id":"mycelium-xv09","type":"blocks","created_at":"2026-01-27T06:38:08.740934-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-5f5","title":"Implement soft matching (superposition of methods)","description":"Instead of hard collapse at similarity \u003e= 0.75, present top-3 methods weighted by similarity. Let the LLM consider multiple approaches when solving a step.\n\nFrom wave function analysis: This is 'superposition of methods' - don't force collapse to single eigenstate.\n\nImplementation:\n1. Add get_method_superposition() to StepSignatureDB\n2. Modify STEP_SOLVER_WITH_METHOD prompt to accept multiple weighted approaches\n3. Track which approach the LLM actually used for feedback","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:33:49.229472-08:00","updated_at":"2026-01-08T08:37:45.721676-08:00","closed_at":"2026-01-08T08:37:45.721676-08:00"}
{"id":"mycelium-5f67","title":"Consolidate failure recording functions","description":"## Problem\nTwo separate functions in src/mycelium/step_signatures/db.py record failures differently:\n\n- `record_failure()` (line ~3704) - Inserts to step_failures table with rich context (problem, step_id, error_type, error_message, signature_id)\n- `record_operational_failure()` (line ~2814) - Increments operational_failures counter on signature + propagates to parents\n\nWhen a signature produces a wrong answer:\n- `record_failure()` logs the detailed failure context\n- `record_operational_failure()` updates the stat for routing decisions\n\nCurrently these are called independently. In solver.py:\n- 10+ calls to `record_failure()` for various error types\n- Only 1 call to `record_operational_failure()` (line ~4071)\n\nThis means most failures are logged but don't affect routing stats.\n\n## Pattern to Follow\nSee `propagate_graph_centroid_to_parents()` - single entry point with optional behaviors.\n\n## Proposed Solution\nMerge into single function:\n```python\ndef record_failure(\n    self,\n    problem: str,\n    step_id: str,\n    error_type: str,\n    error_message: str,\n    signature_id: int = None,\n    increment_operational_failures: bool = False,  # NEW: optionally update stats\n):\n    '''Record failure to log table, optionally increment signature failure stats.'''\n```\n\nOr add parameter to control stat increment based on error_type:\n- 'dsl_error' -\u003e increment operational_failures (DSL produced wrong answer)\n- 'validation' -\u003e don't increment (input validation, not DSL fault)\n- 'llm_error' -\u003e don't increment (LLM failed, not signature fault)\n\n## Acceptance Criteria\n- [ ] Single function handles both failure logging and stat increment\n- [ ] Clear rules for which error_types increment stats\n- [ ] Remove separate `record_operational_failure()` function\n- [ ] Update all call sites in solver.py\n- [ ] Failure stats correctly reflect signature performance","status":"closed","priority":4,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:08:44.869106-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:39:22.025404-08:00","closed_at":"2026-01-25T08:39:22.025404-08:00","close_reason":"Consolidated failure recording: record_failure() now has increment_operational_failures param. Removed separate record_operational_failure(). Updated solver.py call site. Uses _increment_signature_stat() from previous refactor. All 401 tests pass."}
{"id":"mycelium-5gev","title":"Selective branching: only branch when undecided","description":"Per ideas.md: Dont branch on every dag step, only when undecided. Use ucb1_gap threshold to decide. Set was_undecided=1 when branching.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:24.985266-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T16:54:20.081727-08:00","closed_at":"2026-01-20T16:54:20.081727-08:00","close_reason":"Implemented selective branching using UCB1 gap threshold (0.15). Only branches when min_gap \u003c threshold (undecided). Updated fork_reason to 'undecided'."}
{"id":"mycelium-5go","title":"[IMPROVE] MCTS db parameter accepts SignatureDB but uses StepSignatureDB methods","description":"## Issue\nIn mcts.py, the MCTS class constructor accepts a `db: SignatureDB` parameter, but actually calls methods like `find_matches()` which only exist on `StepSignatureDB`. \n\nLooking at council_v2.py:\n```python\nself._mcts = MCTS(\n    db=self.step_db,  # StepSignatureDB/MyceliumDB has find_matches()\n    step_db=self.step_db,\n    ...\n)\n```\n\nThe comment in council_v2.py acknowledges this ('StepSignatureDB/MyceliumDB has find_matches()').\n\n## Problem\nThe type hint `db: SignatureDB` is misleading since:\n1. SignatureDB has `find_similar()` but NOT `find_matches()`\n2. StepSignatureDB has `find_matches()` which is what's actually used\n3. Passing a pure SignatureDB would cause an AttributeError\n\n## Suggested Fix\nUpdate the type hints in mcts.py:\n```python\ndef __init__(\n    self,\n    db: Union[SignatureDB, StepSignatureDB],  # Or just StepSignatureDB\n    step_db: Optional[StepSignatureDB] = None,\n    ...\n):\n```\n\nOr add a Protocol type that defines the interface MCTS actually needs.\n\n## Files Affected\n- src/mycelium/mcts.py (line 204-206)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:20:49.817357-08:00","updated_at":"2026-01-09T08:28:23.511127-08:00","closed_at":"2026-01-09T08:28:23.511127-08:00"}
{"id":"mycelium-5i2","title":"Add type hints to answer_norm.py","description":"Add complete type annotations to answer_norm.py functions. Use Optional, Union where needed. Prepare for mypy strict mode.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:42.533116-08:00","updated_at":"2026-01-09T07:47:07.888566-08:00","closed_at":"2026-01-09T07:47:07.888566-08:00"}
{"id":"mycelium-5jr","title":"Measure MCTS decomposition impact end-to-end","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T12:24:18.556686-08:00","updated_at":"2026-01-20T16:51:28.557396-08:00","closed_at":"2026-01-20T16:51:28.557396-08:00","close_reason":"Superseded by MCTS wave function implementation - tables wired up, analysis queries available in mcts.py"}
{"id":"mycelium-5md","title":"Add DB schema migration system","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T12:25:04.807026-08:00","updated_at":"2026-01-20T17:50:06.165974-08:00","closed_at":"2026-01-20T17:50:06.165974-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-5mm","title":"Make essence similarity primary ranking in find_matches()","description":"Update find_matches() so that:\n- Candidates are ranked by cosine_essence (primary signal)\n- Full cosine is used only as secondary signal\n- Thresholding and top-K selection operate on essence similarity\n- Keep cosine-only mode available behind a flag\n\nConstraints:\n- Backward compatible API\n- No regressions if essence_dims missing\n\nDeliverables:\n- Updated matcher\n- Debug logs showing essence vs full similarity","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T10:57:34.728726-08:00","updated_at":"2026-01-08T11:02:29.99353-08:00","closed_at":"2026-01-08T11:02:29.99353-08:00"}
{"id":"mycelium-5nt3","title":"Cleanup: Move scattered thresholds from dsl_executor.py to config.py","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-13T14:55:45.690781-08:00","updated_at":"2026-01-20T17:50:06.643868-08:00","closed_at":"2026-01-20T17:50:06.643868-08:00","close_reason":"Stale - older than Jan 15, deprioritizing","dependencies":[{"issue_id":"mycelium-5nt3","depends_on_id":"mycelium-g4mt","type":"blocks","created_at":"2026-01-13T14:55:54.181932-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-5pg","title":"O(n²) similarity computation in find_similar - scalability concern","description":"step_signatures.py:1410-1433 - find_similar() loads ALL signatures and computes cosine similarity with each. O(n*d) per call. Consider approximate nearest neighbor (FAISS, Annoy) for scalability with thousands of signatures.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T09:10:58.64773-08:00","updated_at":"2026-01-08T12:30:33.187996-08:00","closed_at":"2026-01-08T12:30:33.187996-08:00"}
{"id":"mycelium-5vp4","title":"Feature: Adaptive compute budget with multi-path exploration (MCTS)","description":"## Summary\nImplement adaptive compute budget that scales exploration effort based on problem difficulty. Single-pass for easy problems (training), multi-pass for hard problems (inference).\n\nPer CLAUDE.md: 'MCTS, but learned from embeddings' - this completes the MCTS loop by adding proper exploration + backpropagation from multiple paths.\n\n## Hardness Signals\n- Routing confidence: max(child similarities) - low = ambiguous\n- UCB1 spread: gap between top-2 children - small = toss-up  \n- Historical failure rate: signature stats\n- Execution confidence: DSL validation quality\n\n## Design\n\n```python\ndef solve_with_budget(problem, budget=1.0):\n    result, confidence, path = single_pass_solve(problem)\n    \n    if confidence \u003e= THRESHOLD or budget \u003c= 1.0:\n        return result  # Easy or budget exhausted\n    \n    # Hard problem: explore alternatives\n    alternative_paths = get_alternative_paths(problem, k=int(budget))\n    results = [(result, confidence, path)]\n    \n    for alt_path in alternative_paths:\n        alt_result, alt_conf = execute_path(problem, alt_path)\n        results.append((alt_result, alt_conf, alt_path))\n    \n    # Learn from ALL paths (backpropagation)\n    best = max(results, key=lambda x: x[1])\n    for r, c, p in results:\n        record_path_result(p, success=(r == best[0]))\n    \n    return best[0]\n```\n\n## Key Insight\nMulti-path exploration generates training data even in inference mode - this is the MCTS backpropagation step.\n\n## Implementation Phases\n1. Add confidence scoring to routing (no behavior change)\n2. Add budget parameter, default 1.0 (backward compatible)\n3. Implement multi-path exploration\n4. Auto-detect hard problems, adaptive budget\n\n## Config Values Needed\n- COMPUTE_BUDGET_DEFAULT = 1.0\n- CONFIDENCE_THRESHOLD = 0.8\n- MAX_ALTERNATIVE_PATHS = 5\n\n## Files to Modify\n- db.py: route_through_hierarchy() returns top-k with scores\n- solver.py: add budget param, implement multi-path\n- config.py: new thresholds","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:01:08.40864-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.027638-08:00","closed_at":"2026-01-20T18:00:01.027638-08:00","close_reason":"Stale - Jan 15, deprioritizing","dependencies":[{"issue_id":"mycelium-5vp4","depends_on_id":"mycelium-wc9q","type":"blocks","created_at":"2026-01-15T21:10:49.037562-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-652a","title":"Bug: Unsafe lastrowid usage across transactions in db.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:43.436939-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:31:09.251582-08:00","closed_at":"2026-01-15T05:31:09.251582-08:00","close_reason":"Added defensive check for lastrowid after INSERT - falls back to querying by signature_id if lastrowid is None/0"}
{"id":"mycelium-6o3","title":"Extract matching/ package with MatchMode base class","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:03.640334-08:00","updated_at":"2026-01-09T06:11:16.554109-08:00","closed_at":"2026-01-09T06:11:16.554109-08:00","dependencies":[{"issue_id":"mycelium-6o3","depends_on_id":"mycelium-ib7","type":"blocks","created_at":"2026-01-09T05:54:42.884013-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-6pk9","title":"Bug: Auto-demotion triggers on multi-path losers (not DSL failures)","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T14:33:21.473376-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T14:35:14.520212-08:00","closed_at":"2026-01-25T14:35:14.520212-08:00","close_reason":"Fixed: only demote on historical success rate, not step_completed (which conflates DSL failure with multi-path loss)"}
{"id":"mycelium-6sj8","title":"Big 3: Move placement similarity thresholds to config","description":"Per CLAUDE.md 'The Flow': Hardcoded thresholds for signature placement.\n\n**Violations**:\n- db.py:9492 - `0.75` for child placement\n- db.py:9500 - `0.50` for sibling placement\n\n**Fix**: Add to config.py:\n```python\nSIGNATURE_CHILD_PLACEMENT_SIMILARITY = 0.75\nSIGNATURE_SIBLING_PLACEMENT_SIMILARITY = 0.50\n```\n\nConsider making these Welford-adaptive based on observed similarity distributions.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:30.035429-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T06:12:32.125705-08:00","closed_at":"2026-01-29T06:12:32.125705-08:00","close_reason":"Moved placement similarity thresholds to config.py: PLACEMENT_DEDUP_SIMILARITY=0.97, PLACEMENT_WELL_COVERED_ZSCORE=-0.5, PLACEMENT_WELL_COVERED_SIMILARITY=0.85, PLACEMENT_CHILD_SIMILARITY=0.75, PLACEMENT_SIBLING_SIMILARITY=0.50. Updated db.py _decide_proposal_fate to use config constants."}
{"id":"mycelium-6wu0","title":"Audit: Verify centroid averaging is actually implemented","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:00:54.444441-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:05:34.249788-08:00","closed_at":"2026-01-15T09:05:34.249788-08:00","close_reason":"Verified: centroid averaging IS implemented. Running average updates in observe_pending_hierarchical (db.py:469-504), parent propagation in propagate_centroid_to_parents (db.py:144-234). Found dead code: unused update_centroid() method. No tests exist for this functionality."}
{"id":"mycelium-6wx","title":"Measure signature coverage: ideal is 100% step injection","description":"Best case scenario: a problem gets decomposed into N steps (e.g., 4), and each step maps to a unique signature that gets injected. This means only parameters flow through with minimal reasoning effort.\n\nQuestions to answer:\n- What % of steps currently get signature injection vs novel reasoning?\n- How many unique signatures does an average math problem touch?\n- What's the distribution of step counts per problem?\n- Are we converging toward full coverage as training progresses?\n\nSuccess metric: approaching 100% injection rate on trained problem types.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T16:30:25.024321-08:00","updated_at":"2026-01-20T17:48:37.55667-08:00","closed_at":"2026-01-20T17:48:37.55667-08:00","close_reason":"Stale - 11+ days old, deprioritizing"}
{"id":"mycelium-70a","title":"Measure average step count per math problem decomposition","description":"How many step signatures does the average math problem get decomposed into?\n\nCollect metrics:\n- Average number of steps per problem\n- Distribution (min/max/median)\n- Breakdown by problem difficulty level (L1-L5)\n- Breakdown by category (algebra, geometry, etc.)\n\nThis helps understand the granularity of our decomposition strategy.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T16:30:31.134714-08:00","updated_at":"2026-01-08T16:50:25.300507-08:00","closed_at":"2026-01-08T16:50:25.300507-08:00"}
{"id":"mycelium-72mc","title":"Implement Chain Node detection and creation","description":"## Context\nPer CLAUDE.md Big 5 #5 (Primitive vs Chain Nodes):\n1. Cold start bootstraps primitives (ADD, SUB, MUL, DIV)\n2. Success patterns reveal which primitives chain together\n3. Chains become new 'atomic' units for L5 routing\n\n## Dependencies\n- Depends on: mycelium-s2uz (Solver integration)\n\n## Goal\nDetect when a sequence of primitives should become a chain node:\n- Track successful (step_sequence, problem_type) pairs\n- When a sequence succeeds N times, create a chain node\n- Chain nodes can be matched directly for similar problems\n\n## Implementation\n\n### 1. Track Step Sequences\nIn data layer, track which sequences of leaf_nodes succeed together:\n\n```python\n# New table\nCREATE TABLE step_sequences (\n    id INTEGER PRIMARY KEY,\n    sequence TEXT,          -- JSON: ['leaf_1', 'leaf_2', 'leaf_3']\n    success_count INTEGER,\n    failure_count INTEGER,\n    created_at TIMESTAMP\n);\n```\n\n### 2. Chain Detection Logic\n```python\ndef check_for_chain_creation(\n    step_sequence: list[str],  # List of leaf_node IDs used\n    success: bool\n) -\u003e Optional[ChainNode]:\n    '''\n    Per The Flow: Database Statistics -\u003e Welford -\u003e Tree Structure\n    \n    If a sequence has:\n    - success_count \u003e= CHAIN_CREATION_THRESHOLD (config)\n    - success_rate \u003e= CHAIN_MIN_SUCCESS_RATE (config)\n    \n    Create a chain node that represents this sequence.\n    '''\n    ...\n```\n\n### 3. Chain Node Structure\n```python\n@dataclass\nclass ChainNode:\n    id: str\n    sequence: list[str]      # Ordered list of leaf_node IDs\n    description: str         # 'average two numbers' = [ADD, DIV]\n    graph_embedding: list[float]  # Embedding for routing\n```\n\n### 4. Chain Matching\nWhen a new problem comes in:\n1. First check if it matches an existing chain (high similarity)\n2. If yes, execute the chain sequence directly\n3. If no, decompose to primitives and track for future chain creation\n\n## Config Constants\nAdd to config.py:\n- CHAIN_CREATION_THRESHOLD = 5  # Successes before creating chain\n- CHAIN_MIN_SUCCESS_RATE = 0.8  # Minimum success rate\n\n## Tests Required\n- test_sequence_tracking\n- test_chain_creation_threshold\n- test_chain_matching\n- test_chain_execution\n\n## Acceptance Criteria\n- [ ] Step sequences tracked in database\n- [ ] Chains created when threshold met\n- [ ] Chain nodes have graph embeddings for routing\n- [ ] Mature tree can route to chains directly\n- [ ] Follows The Flow (stats -\u003e structure)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T12:28:07.715558-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T12:53:05.432129-08:00","closed_at":"2026-01-29T12:53:05.432129-08:00","close_reason":"All implemented with 208 tests passing. Committed in 2b96e5b.","dependencies":[{"issue_id":"mycelium-72mc","depends_on_id":"mycelium-s2uz","type":"blocks","created_at":"2026-01-29T12:28:13.059528-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-74u","title":"Add connection pooling to Groq client","description":"Replace single httpx.AsyncClient with connection pool. Add configurable pool size and connection timeout. Helps with parallel LLM calls.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:52.017742-08:00","updated_at":"2026-01-09T07:47:59.48491-08:00","closed_at":"2026-01-09T07:47:59.48491-08:00"}
{"id":"mycelium-7ar","title":"Add logging for step failures in council_v2.py","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-09T06:47:13.770132-08:00","updated_at":"2026-01-09T06:56:03.707551-08:00","closed_at":"2026-01-09T06:56:03.707551-08:00"}
{"id":"mycelium-7bp","title":"Race condition in ConnectionManager singleton","description":"Lines 123-135: _initialized check can allow double initialization under concurrent access","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:26.993544-08:00","updated_at":"2026-01-09T11:22:06.686355-08:00","closed_at":"2026-01-09T11:22:06.686355-08:00"}
{"id":"mycelium-7dm","title":"Failed step error messages propagate to downstream context","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-09T06:47:15.666191-08:00","updated_at":"2026-01-15T05:49:22.925713-08:00","closed_at":"2026-01-15T05:49:22.925713-08:00","close_reason":"Fixed: _execute_composite_step now aborts on sub-step failure instead of continuing execution. Previously, failed sub-steps stored empty strings in sub_context and downstream sub-steps would try to use those empty values, causing cascading failures."}
{"id":"mycelium-7dx1","title":"Wire up mcts_threads table logging","description":"Create mcts_thread record for root thread at problem start. Create fork records when MCTS branches. Track fork_at_step, fork_reason, final_answer.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:08.866386-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T14:24:13.438738-08:00","closed_at":"2026-01-20T14:24:13.438738-08:00","close_reason":"Wired up mcts_threads table logging: root thread creation at problem start, fork records when MCTS branches, and thread completion/grading"}
{"id":"mycelium-7e9","title":"LOW: Add test coverage for council_v2.py and db.py","description":"No test files exist for council_v2.py (main solver) or db.py. Add tests for: solve() with various problem types, error handling, synthesis strategy selection, database operations.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:57.558593-08:00","updated_at":"2026-01-09T08:34:39.200158-08:00","closed_at":"2026-01-09T08:34:39.200158-08:00"}
{"id":"mycelium-7ec6","title":"Feature: Detect ungrounded LLM outputs","description":"Add contextual grounding detection: flag when an LLM output doesn't reference/use values from context when it should. For example, if context has step_1=42 and step_2=10, but LLM outputs '50' without any apparent relationship to these values, flag as potentially ungrounded.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T10:45:23.230991-08:00","updated_at":"2026-01-20T17:50:06.327379-08:00","closed_at":"2026-01-20T17:50:06.327379-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-7eqw","title":"Consolidation: Unify database connection paths in db.py","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": \"All database connections should go through a data layer instead of having multiple database connections.\"\n\ndb.py has TWO parallel connection paths:\n1. `_direct_conn` - Direct sqlite3.connect for performance\n2. `_db` - Via data layer get_db()\n\n## Current Behavior\n\n```python\n# db.py:683-689\nclass StepSignatureDB:\n    def __init__(self, db_path: str = None):\n        self._direct_conn = sqlite3.connect(db_path, ...)  # Direct connection\n        self._db = get_db(db_path)  # Data layer connection\n\n# db.py:809-813 - conditional logic choosing which to use\ndef _connection(self):\n    if self._direct_conn:\n        return self._direct_conn\n    else:\n        return self._db.get_connection()\n```\n\nThis creates:\n- Two separate connection pools\n- Potential consistency issues\n- Harder to reason about transaction boundaries\n\n## Expected Behavior\n\nSingle connection pathway through data layer:\n\nOption A: **Remove direct connection, always use data layer**\n```python\nclass StepSignatureDB:\n    def __init__(self, db_path: str = None):\n        self._db = get_db(db_path)\n    \n    def _connection(self):\n        return self._db.get_connection()\n```\n\nOption B: **Move direct connection logic to data layer**\n```python\n# data_layer/database.py\nclass Database:\n    def __init__(self, db_path: str):\n        self._conn = sqlite3.connect(db_path, check_same_thread=False)\n        # ... configure for performance\n    \n    def get_connection(self):\n        return self._conn\n```\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/db.py:683-813` - Simplify connection logic\n- `src/mycelium/data_layer/database.py` - Ensure performance optimizations\n\n## Implementation Notes\n\n1. Performance is critical - current direct connection is for speed\n2. Data layer must support same performance characteristics\n3. Migrate gradually with benchmarks\n\n## Testing\n\n1. Benchmark current performance (signature lookups/sec)\n2. Migrate to single path\n3. Benchmark again, ensure no regression\n4. Run full test suite\n\n## Context\n\nPart of Consolidation code review. High priority per CLAUDE.md.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:39:26.477295-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:28:35.85635-08:00","closed_at":"2026-01-28T12:28:35.85635-08:00","close_reason":"Unified database connection paths: removed _direct_conn from StepSignatureDB, added create_connection_manager() factory to data layer. All 394 tests pass."}
{"id":"mycelium-7f4","title":"Contextual boost formula too aggressive (0-2x range)","description":"step_signatures.py:get_contextual_boost() uses 'success_rate * 2.0' which gives a 0-2x range. A 0% success rate completely eliminates matches (0x boost). Consider a gentler formula like '0.5 + success_rate' (0.5-1.5x range) or '0.8 + success_rate * 0.4' (0.8-1.2x range) to avoid completely suppressing otherwise-good signatures.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T12:15:30.72846-08:00","updated_at":"2026-01-12T09:14:40.722501-08:00","closed_at":"2026-01-12T09:14:40.722501-08:00"}
{"id":"mycelium-7g55","title":"Bug: High cosine-sim nodes not clustered together in tree","description":"Signatures with identical graph_embeddings are scattered as siblings instead of clustered. Example: 11 compute_sum signatures all at depth=1 as siblings, should be ONE node or clustered under common parent.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T15:06:19.784757-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T10:03:33.060439-08:00","closed_at":"2026-01-26T10:03:33.060439-08:00","close_reason":"Added sibling dedup check in CLUSTER path - now checks find_best_child_match before creating new signatures under same parent"}
{"id":"mycelium-7hk","title":"[IMPROVE] Large step_signatures.py file (5000+ lines) should be split","description":"## Issue\nThe file `src/mycelium/step_signatures.py` is extremely large with over 5000 lines of code. This makes it difficult to maintain and understand.\n\n## Suggested Refactoring\nSplit into multiple focused modules:\n\n1. **step_signatures/models.py** - Data classes (StepSignature, StepExample, MatchResult, etc.)\n2. **step_signatures/db.py** - Core StepSignatureDB class with CRUD operations\n3. **step_signatures/matching.py** - find_similar, find_matches, find_by_resonance\n4. **step_signatures/clustering.py** - Cluster analysis, merge suggestions\n5. **step_signatures/wave.py** - Wave propagation, amplitude updates\n6. **step_signatures/sequences.py** - Step sequence tracking and contextual boosts\n7. **step_signatures/relationships.py** - Signature relationship management\n\nCurrent organization makes it hard to:\n- Find relevant code quickly\n- Understand the full API surface\n- Add targeted tests\n\n## Files Affected\n- src/mycelium/step_signatures.py (needs to be split)\n- tests/test_step_signatures.py (may need updates)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:51.538226-08:00","updated_at":"2026-01-09T10:46:56.282902-08:00","closed_at":"2026-01-09T10:46:56.282902-08:00"}
{"id":"mycelium-7khj","title":"The Flow: Replace hardcoded thresholds with Welford-computed values","description":"Hardcoded thresholds bypass The Flow (DB Stats → Welford → Tree): solver.py:1473 (0.90), divergence.py:31 (0.20), mcts.py:4071 (3, 0.5), db.py:3074-3078 (0.7, 5, 0.85), solver.py:238 sigmoid (0.7, 0.15). All should derive from Welford-computed distributions.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:00:45.32845-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:09:49.977815-08:00","closed_at":"2026-01-28T12:09:49.977815-08:00","close_reason":"Moved hardcoded thresholds to config: GRAPH_ROUTING_HIGH_CONFIDENCE (0.90), DIVERGENCE_CLOSE_DISTANCE (0.20), EXPANSION_SIGMOID_MIDPOINT/STEEPNESS (0.7/0.15). Values are now centralized and tunable. True Welford-computed dynamic thresholds could be a future enhancement."}
{"id":"mycelium-7n6e","title":"Codebase Refactoring Plan","description":"## Current State\n\n### Large Files (lines)\n- `dsl_executor.py`: 2583 (DSL execution + math ops)\n- ~~`solver_v1.py`: 2013 **DEAD** - delete~~ DELETED\n- `db.py`: 1184 lines (down from 1294 - extracted scoring.py and dsl_templates.py)\n- `refinement.py`: 1265 (used by scripts/refine_signatures.py - keep)\n- `solver.py`: 1053 (main solver)\n\n### Confirmed Dead Code (safe to delete)\n| File | Lines | Reason | Status |\n|------|-------|--------|--------|\n| `solver_v1.py` | 2013 | Old solver, not imported | DELETED |\n| `step_decomposer.py` | 205 | Only used by solver_v1 | DELETED |\n| `step_classifier.py` | 328 | Not imported anywhere | DELETED |\n| `step_output.py` | 460 | Not imported anywhere | DELETED |\n| `semantic_extractor.py` | 284 | Not imported anywhere | DELETED |\n| `phase_constraints.py` | ~50 | Not imported anywhere | DELETED |\n| `step_signatures/schema.py` | 547 | Duplicate of data_layer/schema.py | DELETED |\n| **TOTAL** | ~3956 | Lines deleted | COMPLETE |\n\n## Refactoring Phases\n\n### Phase 1: Delete Dead Code - COMPLETE (commit f05e07c)\nDeleted ~3956 lines of unused code.\n\n### Phase 2: Split db.py - COMPLETE (commit 11c5241)\nCreated focused modules:\n- `scoring.py`: compute_routing_score, normalize_step_text (52 lines)\n- `dsl_templates.py`: DSL_TEMPLATES, DSL_INFERENCE_PATTERNS, infer_dsl_for_signature (104 lines)\n\ndb.py now imports from these modules (backward compatible).\n\n### Phase 3: Split dsl_executor.py - TODO\nTarget 2583 lines to split into:\n- `dsl_executor.py` (core DSL execution)\n- `math_ops.py` (math functions)\n- `sympy_bridge.py` (symbolic math)\n- `dsl_runtime.py` (execution context)\n\n### Phase 4: Improve solver.py - TODO\nBreak up large functions, improve async handling.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-13T05:59:25.293306-08:00","updated_at":"2026-01-20T17:50:06.57593-08:00","closed_at":"2026-01-20T17:50:06.57593-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-7o0v","title":"Docs: Terminology glossary - synonyms in codebase","description":"## Terminology Synonyms\n\nThe codebase uses different terms for the same concepts:\n\n### Node-level (the same thing)\n- **sig** / **signature** - code term\n- **node** - graph theory term\n- **centroid** - embedding term (the average embedding)\n- **neuron** - neural network analogy\n\n### Edge-level (the same thing)\n- **edge** - graph theory term\n- **synapse** - neural network analogy\n- **router** - routing/dispatch term\n\n## Action\nConsider standardizing terminology in docs/comments, or at minimum document the equivalences.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-13T08:22:14.602432-08:00","updated_at":"2026-01-20T17:50:06.665955-08:00","closed_at":"2026-01-20T17:50:06.665955-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-7o8i","title":"Partial credit for correct steps in failed problems","description":"Currently if a 5-step problem fails, ALL 5 signatures get no credit - even if 4 were correct.\n\nGap: update_problem_outcome() is all-or-nothing. Correct steps in failed problems get nothing.\n\nImplementation:\n1. Track step_success separately from thread_success\n2. When problem fails, identify which steps were likely correct:\n   - Steps that produced intermediate results matching expected patterns\n   - Steps with high amplitude_post despite thread failure\n3. Give partial credit to correct steps (fractional successes increment)\n4. Only blame the step(s) that caused the failure\n\nThis prevents good signatures from being punished for a single bad step in the chain.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T06:25:08.511822-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T06:41:47.324673-08:00","closed_at":"2026-01-21T06:41:47.324673-08:00","close_reason":"Implemented partial credit for correct steps in failed problems - high-confidence steps in losing threads get 0.5 credit instead of blame","dependencies":[{"issue_id":"mycelium-7o8i","depends_on_id":"mycelium-itkn","type":"blocks","created_at":"2026-01-21T06:25:32.891231-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-7oh","title":"Extract duplicate pack/unpack embedding functions","description":"pack_embedding() and unpack_embedding() are duplicated in:\n- signatures.py:29-37\n- step_signatures.py:782-793\n\nCreate shared/vectors.py with single implementation.\n~80 lines removed, 1 source of truth.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:34:39.644215-08:00","updated_at":"2026-01-09T10:55:13.995241-08:00","closed_at":"2026-01-09T10:55:13.995241-08:00","dependencies":[{"issue_id":"mycelium-7oh","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.326525-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-7oj1","title":"Bug: Unbounded recursion if UMBRELLA_MAX_DEPTH misconfigured","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:13.600543-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:23:08.552116-08:00","closed_at":"2026-01-15T05:23:08.552116-08:00","close_reason":"Added validation for UMBRELLA_MAX_DEPTH: config.py now validates/clamps to [1, 100], and db.py routing functions have local guards (max(1, min(int(value), 100))) for defense in depth"}
{"id":"mycelium-7qo","title":"Bug: Child DSLs skip negative-lift avoidance check","description":"In solver.py:1628-1637, child DSL execution skips the should_avoid_dsl_for_signature() check that parent signatures go through at line 1078. This means child DSLs with negative lift will still execute and systematically fail. Fix: Call avoidance check before executing child DSL.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T06:42:08.309099-08:00","updated_at":"2026-01-12T09:12:19.84711-08:00","closed_at":"2026-01-12T09:12:19.84711-08:00"}
{"id":"mycelium-7yq","title":"IndexError in execution_plan_optimizer.py","description":"Line 450: json_str.split()[1] can fail if response doesnt contain backticks","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:26.140458-08:00","updated_at":"2026-01-09T11:22:06.543758-08:00","closed_at":"2026-01-09T11:22:06.543758-08:00"}
{"id":"mycelium-808f","title":"System Independence: Remove ALWAYS_ROUTE_TO_BEST bypass","description":"## Problem\n\nPer CLAUDE.md: \"We want to minimize the number of arbitrary magic numbers... all decisions should be guided by Welfords which gets good and current stats from the db.\"\n\n`ALWAYS_ROUTE_TO_BEST = True` (config.py:53) completely disables rejection thresholds, bypassing the Welford-guided adaptive threshold system.\n\n## Current Behavior\n\n```python\n# config.py:53\nALWAYS_ROUTE_TO_BEST = True  # If True, ignore thresholds and always use best match\n\n# db.py:1532\nsimilarity_ok = best_sim \u003e= min_similarity if not ALWAYS_ROUTE_TO_BEST else True\n```\n\nWhen enabled, ALL matches are accepted regardless of similarity. This:\n- Removes adaptive threshold mechanism entirely\n- Prevents learning from bad matches (they're accepted anyway)\n- Contradicts CLAUDE.md: thresholds should be Welford-guided, not disabled\n\n## Expected Behavior\n\nRejection thresholds should ALWAYS be active and guided by Welford stats:\n- Use `get_adaptive_thresholds()` which computes `mean - k*std` from observed data\n- Low similarity matches should be rejected and recorded as failures\n- Failures feed decomposition decisions per CLAUDE.md\n\n## Files to Modify\n\n- `src/mycelium/config.py:53` - Remove or deprecate ALWAYS_ROUTE_TO_BEST\n- `src/mycelium/step_signatures/db.py:1532` - Remove conditional bypass\n- `src/mycelium/step_signatures/db.py:1929, 2013` - Similar bypasses\n\n## Testing\n\nAfter removal:\n1. Run with fresh DB on GSM8K easy problems\n2. Verify rejection thresholds are active (check logs for \"rejection\" messages)\n3. Verify accuracy doesn't drop significantly (adaptive thresholds should work)\n4. Run full test suite: `uv run pytest tests/ -v`\n\n## Context\n\nPart of System Independence code review. See commit c6c9ff2 for related Welford fixes.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:37:09.110425-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T11:48:32.032682-08:00","closed_at":"2026-01-28T11:48:32.032682-08:00","close_reason":"Removed ALWAYS_ROUTE_TO_BEST bypass from config.py, db.py (lines 1531-1532, 1929, 2013), and CLAUDE.md. System now uses Welford-guided thresholds for routing decisions. All 395 tests pass."}
{"id":"mycelium-80q1","title":"System Independence: Remove forced parent_id in umbrella_learner decomposition","description":"umbrella_learner.py:634,665,685-689,731 forces parent_id during decomposition instead of letting routing/matching decide placement. Manual add_child/remove_child calls bypass Welford-guided decisions. Should let propose_signature() handle placement.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:00:41.205936-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:06:26.053841-08:00","closed_at":"2026-01-28T12:06:26.053841-08:00","close_reason":"Not a violation - umbrella_learner decomposition is automated. System Independence means humans don't manually intervene, not that automated decomposition is forbidden."}
{"id":"mycelium-8150","title":"Train value predictor for amplitude_post (AlphaGo approach)","description":"## Motivation\nCurrent post-mortem uses fixed multipliers (1.1, 1.4, 0.85, 0.5) to compute amplitude_post.\nThis is a heuristic. AlphaGo would train a value network to predict win probability.\n\n## Idea\nInstead of:\n```python\nif won and high_conf:\n    amplitude_post = amp * 1.4\n```\n\nTrain a predictor:\n```python\namplitude_post = value_network.predict(\n    routing_confidence=amp,\n    signature_features=sig.embedding,\n    step_features=step_embedding,\n    historical_success_rate=sig.successes/sig.uses,\n)\n```\n\n## Benefits\n- Learns the actual relationship between confidence and outcomes\n- Can incorporate more features (signature history, step complexity, etc.)\n- Adapts as the system matures\n\n## Approach\n1. Collect (amplitude, outcome, features) pairs during training\n2. Train simple regressor (could even be linear initially)\n3. Use predicted value for credit propagation\n4. Periodically retrain as more data accumulates\n\n## Questions\n- What features matter? (amplitude, similarity, depth, sig age, etc.)\n- How often to retrain?\n- Cold start - need minimum data before predictor is useful","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T07:10:59.404646-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T07:22:34.093761-08:00","closed_at":"2026-01-25T07:22:34.093761-08:00","close_reason":"Implemented AlphaGo-style value predictor for amplitude_post: collects training samples with features (amplitude, similarity, ucb1_gap, etc.), learns linear model weights via SGD, falls back to fixed multipliers during cold start"}
{"id":"mycelium-824","title":"suggest_cluster_merges O(n²) memory for large signature sets","description":"step_signatures.py:suggest_cluster_merges() computes full pairwise similarity matrix: similarity_matrix = centroids_normalized @ centroids_normalized.T. For n=10,000 signatures this creates 100M elements (~400MB float32). For n=100,000 it's 10B elements (~40GB). Consider chunked processing: compute similarity in blocks, or use approximate nearest neighbors (FAISS, Annoy) for large DBs.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T13:12:54.52444-08:00","updated_at":"2026-01-20T17:50:06.143483-08:00","closed_at":"2026-01-20T17:50:06.143483-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-833","title":"Prove it: V2 vs CQR benchmark comparison","description":"**Role**: Prove this wasn't just 'cool math'.\n\n**Objective**: Measure whether wave-based Mycelium actually improves learning speed and reuse.\n\n**Constraints**:\n- Use existing MATH dataset scripts\n- No subjective metrics\n- Must compare V2 vs CQR directly\n\n**Metrics to track**:\n1. **Time to signature reliability** - How many problems until a signature hits reliable status (3+ uses, 70%+ success)?\n2. **Reuse rate of learned methods** - What % of steps use injected methods vs solving fresh?\n3. **Error recovery after failure** - Does the system recover faster when a method fails?\n\n**Deliverables**:\n1. Metrics collection hooks in council_v2.py and signatures\n2. Comparison report with side-by-side plots and tables\n3. Recommendation: keep / modify / rollback\n\nThis is the 'show me the data' moment.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T08:49:15.381397-08:00","updated_at":"2026-01-08T09:16:54.062333-08:00","closed_at":"2026-01-08T09:16:54.062333-08:00"}
{"id":"mycelium-83j","title":"Implement confidence wave propagation","description":"Replace discrete success updates with confidence wave propagation across nearby signatures.\n\nOn successful step execution:\n- Boost amplitude of the matched signature\n- Propagate a decayed amplitude boost to nearby signatures: ΔA_neighbor = A_source × similarity × decay_factor\n- Ensure total injected energy is conserved or decays\n- Failures should cause localized damping, not global penalties\n\nDeliverables:\n- propagate_confidence() method\n- Updated record_usage() logic\n- Metrics logging to observe wave spread","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:47:28.524763-08:00","updated_at":"2026-01-08T08:57:00.692438-08:00","closed_at":"2026-01-08T08:57:00.692438-08:00"}
{"id":"mycelium-84p","title":"Add FAISS/annoy for approximate nearest neighbor search","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-09T05:54:27.111486-08:00","updated_at":"2026-01-20T17:48:37.602888-08:00","closed_at":"2026-01-20T17:48:37.602888-08:00","close_reason":"Stale - 11+ days old, deprioritizing","dependencies":[{"issue_id":"mycelium-84p","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:55:10.118838-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-84s","title":"Fix circular import: step_signatures \u003c-\u003e matching","description":"Circular import chain detected:\nstep_signatures → matching.normalization → matching.types → step_signatures\n\nActions:\n- Move types used by step_signatures OUT of matching.types\n- Use TYPE_CHECKING in matching.types to avoid importing step_signatures\n- Create test_no_circular_imports.py to detect regressions\n\nReference: step_signatures.py:78-95, matching/types.py, matching/__init__.py:12-20","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:35:01.645449-08:00","updated_at":"2026-01-09T10:54:47.720523-08:00","closed_at":"2026-01-09T10:54:47.720523-08:00","dependencies":[{"issue_id":"mycelium-84s","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.465685-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-89tq","title":"Perf: Redundant DB queries in umbrella routing","description":"After find_or_create() returns umbrella, _try_umbrella_routing() fetches children again.\n\nLocation: solver.py:620-664\n\nCould return children with signature object or use eager loading.\n\nLatency impact: MEDIUM - extra query per umbrella hit","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:28:03.859829-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:40:38.131259-08:00","closed_at":"2026-01-15T14:40:38.131259-08:00","close_reason":"Passed pre-fetched children to _try_umbrella_routing to avoid redundant DB query"}
{"id":"mycelium-8aq","title":"Extract prompt templates from council_v2.py to prompts/ module","description":"Move STEP_SOLVER_*, FINAL_SYNTHESIZER, INCREMENTAL_SYNTHESIZER templates to src/mycelium/prompts/. Create PromptTemplate dataclass with name, template, and variables fields.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:29.420914-08:00","updated_at":"2026-01-09T07:49:10.763173-08:00","closed_at":"2026-01-09T07:49:10.763173-08:00"}
{"id":"mycelium-8gie","title":"Perf: Precompute routing similarity matrix","description":"Currently: Compute similarity at routing time. Opportunity: Precompute child similarity matrix once, update on centroid change. Makes UCB1 routing O(1) lookup vs O(children) dot products.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:30:42.6622-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.287856-08:00","closed_at":"2026-01-20T18:00:01.287856-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-8hpl","title":"Add proper type hints to semantic_validation.py","description":"Functions validate_plan_coherence() and _validate_step_inputs() use informal type comments instead of proper type hints. Add proper typing for DAGPlan, StepSignatureDB, Embedder, and Step parameters to enable IDE support and static analysis.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:06:19.423157-08:00","updated_at":"2026-01-15T14:39:59.434952-08:00","closed_at":"2026-01-15T14:39:59.434952-08:00","close_reason":"File semantic_validation.py and functions validate_plan_coherence/_validate_step_inputs do not exist in codebase"}
{"id":"mycelium-8ii","title":"Brainstorm: Frequency decomposition - high freq = parameters, low freq = math essence","description":"## Core Finding (REVISED from brainstorm)\n\n**Original hypothesis**: High-frequency = parameters, Low-frequency = essence\n**Actual finding**: HIGH-VARIANCE dimensions = essence, LOW-VARIANCE = noise\n\n### Key Results\n\n| Method | Within-group | Between-group | Gap | Discrimination Ratio |\n|--------|-------------|---------------|-----|---------------------|\n| Full embedding (384d) | 0.478 | 0.248 | 0.230 | 1.93x |\n| High-var dims (64d) | 0.508 | 0.132 | **0.376** | **3.85x** |\n| Low-var dims (64d) | 0.414 | 0.332 | 0.082 | 1.25x |\n\n**High-variance dimensions provide 2x better discrimination\\!**\n\n### Why This Works\n\nThe embedding model (all-MiniLM-L6-v2) learned to:\n- Use certain dimensions to encode 'what type of problem is this'\n- These dimensions VARY A LOT across different categories\n- But remain CONSISTENT within the same category\n\nExample - matching 'What is 18% of 350?':\n- Full embedding: percentage=0.59, linear_eq=0.22, addition=0.26\n- High-var only: percentage=**0.68**, linear_eq=-0.01, addition=0.04\n\nHigh-var projection nearly eliminates false matches\\!\n\n### Implementation Strategy\n\n1. Compute dimension variances from signature centroids (periodic)\n2. Extract 'essence dimensions' = top 20% highest variance (~76 dims)\n3. Two-stage matching:\n   - First pass: essence dims only (fast category detection)\n   - Second pass: full embedding for fine-grained matching\n4. Use essence similarity for wave propagation threshold\n\n### Why NOT FFT-based frequency decomposition\n\n- FFT treats embedding as 1D signal with arbitrary ordering\n- Variance-based approach respects the model's learned structure\n- Embedding dimensions are NOT ordered by frequency\n- High-variance dims = dims the model ACTUALLY USES to distinguish concepts\n\n### Connection to Wave Propagation (mycelium-cqr)\n\nCould enhance wave propagation by:\n- Propagating based on essence similarity (high-var dims)\n- Ignoring surface differences (low-var dims)\n- 'Same essence' = strong wave, 'different essence' = no wave","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T09:23:56.188416-08:00","updated_at":"2026-01-20T17:38:44.39956-08:00","closed_at":"2026-01-20T17:38:44.39956-08:00","close_reason":"Stale brainstorm - 12 days old, deprioritizing"}
{"id":"mycelium-8mu","title":"Split step_signatures.py into modular packages","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-09T05:53:54.127069-08:00","updated_at":"2026-01-09T10:35:01.717639-08:00","closed_at":"2026-01-09T10:35:01.717639-08:00","dependencies":[{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:54:55.013292-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-11n","type":"blocks","created_at":"2026-01-09T05:55:01.540125-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-ivm","type":"blocks","created_at":"2026-01-09T05:55:02.575695-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-8mu","depends_on_id":"mycelium-o1a","type":"blocks","created_at":"2026-01-09T05:55:03.720574-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-93ox","title":"Infra: Upgrade beads CLI from 0.27.2 to latest","description":"Current bd CLI version is outdated (0.27.2 vs 0.47.1).\n\nUpgrade command:\n  brew upgrade bd\n\nBenefits:\n- bd sync worktree issues fixed\n- New features and bug fixes\n- Better sync-branch handling","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:20:11.510373-08:00","updated_at":"2026-01-14T06:38:23.179413-08:00","closed_at":"2026-01-14T06:38:23.179413-08:00","close_reason":"Upgraded bd CLI from 0.27.2 to 0.47.1"}
{"id":"mycelium-948","title":"LOW: Pre-compile regexes in answer_norm.py","description":"Regexes in answer_norm.py are recompiled on every call. Use re.compile() at module level for hot paths to improve performance.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:00.576691-08:00","updated_at":"2026-01-09T08:32:43.327207-08:00","closed_at":"2026-01-09T08:32:43.327207-08:00"}
{"id":"mycelium-973c","title":"Perf: Centroid propagation on every signature match","description":"propagate_centroid_to_parents() called on every signature match, recomputing all ancestor centroids.\n\nLocation: db.py:159-276, called at lines 581, 601\n\nImpact: MEDIUM - 10-30ms per match for high-traffic leaf nodes\n\nFix: Batch updates - accumulate N matches before propagating, or use async background task.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:02:33.708119-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.171202-08:00","closed_at":"2026-01-20T18:00:01.171202-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-97n4","title":"Refactor: Create SemanticAnchor class to consolidate embedding anchor patterns","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T14:55:31.042785-08:00","updated_at":"2026-01-13T16:56:25.234627-08:00","closed_at":"2026-01-13T16:56:25.234627-08:00","dependencies":[{"issue_id":"mycelium-97n4","depends_on_id":"mycelium-g4mt","type":"blocks","created_at":"2026-01-13T14:55:54.035401-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-98p","title":"Split step_signatures.py (5827 lines) into package","description":"CRITICAL: step_signatures.py is 5827 lines with mixed concerns.\n\nSplit into step_signatures/ package:\n- models.py (StepSignature, StepExample dataclasses)\n- schema.py (StepIOSchema, InputSpec, OutputSpec) \n- formulas.py (try_execute_formula, formula validation)\n- amplitude.py (amplitude control, wave effects)\n- matching.py (blended_similarity, find_matching_cluster)\n- db.py (StepSignatureDB with CRUD ops)\n- __init__.py (re-exports)\n\nTarget: \u003c1500 lines per file","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:34:32.114267-08:00","updated_at":"2026-01-09T08:51:38.925827-08:00","closed_at":"2026-01-09T08:51:38.925827-08:00","dependencies":[{"issue_id":"mycelium-98p","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.27974-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-9aer","title":"Bug: Centroid cache invalidation incomplete","description":"invalidate_centroid_cache() only called on propagation. Missing hooks for:\n- Embedding added to signature\n- Child removed from parent\n- Signature archived\n\nLocation: db.py:229, utils.py:46+\n\nCould cause stale routing decisions.\n\nPer CLAUDE.md: routing uses embeddings, stale centroids = wrong routing","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:28:27.62245-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:53:28.949753-08:00","closed_at":"2026-01-15T14:53:28.949753-08:00","close_reason":"Added cache invalidation hooks for add_child, remove_child, archive, and restore"}
{"id":"mycelium-9f38","title":"Perf: Centroid matrix lazy load causes 1-3s startup penalty","description":"_ensure_centroid_matrix() loads ALL signatures from DB on first find_similar() call.\n\nLocation: db.py:942-975\n\nImpact: HIGH - 1-3s latency on first call (full table scan + embedding unpacking)\n\nOptions:\n1. Pre-warm matrix on DB initialization\n2. Persist matrix to disk, load on startup\n3. Incremental matrix updates instead of full rebuild\n\nAffects every new StepSignatureDB instance.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:02:00.393619-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T15:10:54.255041-08:00","closed_at":"2026-01-15T15:10:54.255041-08:00","close_reason":"Implemented disk persistence for centroid matrix. Cache file (.npz) saved after matrix build, loaded on startup. Lazy row fetching for rows not cached. ~12x speedup (22ms → 1.8ms on 100 sigs). All 302 tests pass."}
{"id":"mycelium-9h6d","title":"Refactor: Simplify dsl_validation.py (811 lines)","status":"closed","priority":4,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T11:06:05.542969-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T17:50:06.802831-08:00","closed_at":"2026-01-20T17:50:06.802831-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-9hg","title":"How do we ensure step_signatures are unique and separate in embedding space","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T05:58:26.458238-08:00","updated_at":"2026-01-08T06:11:54.570941-08:00","closed_at":"2026-01-08T06:11:54.570941-08:00"}
{"id":"mycelium-9ktb","title":"Persist StepFailureFeedback for pattern learning","description":"StepFailureFeedback is currently captured and logged but not persisted. Future work could:\n1. Store failure patterns in the signature DB\n2. Use accumulated failures to identify signatures that need decomposition\n3. Feed historical failures into planner hints\n\nThis would close the learning loop - failures today inform better decompositions tomorrow.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-14T06:06:50.516714-08:00","updated_at":"2026-01-15T14:24:18.51645-08:00","closed_at":"2026-01-15T14:24:18.51645-08:00","close_reason":"Implemented step_failures table for pattern learning. Added record_failure(), get_failure_patterns(), and get_signatures_needing_decomposition() methods. Failures now recorded from solver when DSL execution fails."}
{"id":"mycelium-9loh","title":"Perf: Lazy centroid propagation with batch flush","description":"Currently: Propagate centroid on every match (O(depth) DB writes per step). Alternative: Queue updates, batch flush every N problems or on idle. Tradeoff: Slight staleness vs major write reduction. Aligns with CLAUDE.md 'slow decay' principle.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:30:30.82914-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.075525-08:00","closed_at":"2026-01-20T18:00:01.075525-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-9mrv","title":"Critical: Invalid DAG plans still execute (is_valid not checked)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:31.203486-08:00","updated_at":"2026-01-13T11:38:14.757792-08:00","closed_at":"2026-01-13T11:38:14.757792-08:00"}
{"id":"mycelium-9mu0","title":"Bug: Index out of bounds in param extraction in dsl_templates.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:49.342615-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:33:47.819421-08:00","closed_at":"2026-01-15T05:33:47.819421-08:00","close_reason":"Added defensive guards for non-string keys in extracted_values: _build_dsl_from_hint now checks isinstance(k, str), _infer_dsl_from_values skips non-string keys. Prevents AttributeError on .startswith() if dict has non-string keys."}
{"id":"mycelium-9r8","title":"CRITICAL: Replace bare except Exception with specific types","description":"step_signatures.py:451 and 4777 use bare 'except Exception' which swallows KeyboardInterrupt, SystemExit, MemoryError. Replace with specific types: (ValueError, TypeError, SyntaxError, ZeroDivisionError)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:21:44.593302-08:00","updated_at":"2026-01-09T08:26:48.277678-08:00","closed_at":"2026-01-09T08:26:48.277678-08:00"}
{"id":"mycelium-9txu","title":"Monitor: Track LLM vs embedding disagreement in routing","description":"Monitor logs for '[routing] LLM chose X but embedding prefers Y' pattern. High frequency indicates the LLM routing prompt may need tuning, or embedding-based selection should be preferred. Consider adding metrics/counters to track disagreement rate over time.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-12T10:44:06.119249-08:00","updated_at":"2026-01-20T17:50:06.34978-08:00","closed_at":"2026-01-20T17:50:06.34978-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-9tz","title":"Improve answer normalization for LaTeX","description":"Some false negatives in answer matching due to LaTeX formatting:\n\nExamples seen:\n- '$17' vs '17' (currency)  \n- '\\frac{1}{2}' vs '0.5' vs '1/2'\n- '\\sqrt{2}' vs '1.414...'\n\nCurrent normalize_answer() handles some cases but needs:\n1. More LaTeX patterns\n2. Numeric equivalence checking\n3. Fraction/decimal conversion","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T05:33:09.2229-08:00","updated_at":"2026-01-08T07:29:44.203376-08:00","closed_at":"2026-01-08T07:29:44.203376-08:00"}
{"id":"mycelium-9xa","title":"DBSCAN epsilon allows lower cohesion than intended","description":"step_signatures.py:2265-2269 - eps=1-MIN_COHESION_FOR_NEW_CLUSTER=0.25 allows similarity 0.75 (VARIANT_THRESHOLD) not 0.85 (EXACT_MATCH_THRESHOLD). Adjust constant or formula to match intent.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:51.871791-08:00","updated_at":"2026-01-09T08:30:18.901639-08:00","closed_at":"2026-01-09T08:30:18.901639-08:00"}
{"id":"mycelium-9z3y","title":"P2: Consolidate 3 rejection tracking systems to single entry point","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": We have 3 different rejection tracking mechanisms that should be consolidated.\n\n## Current State\n\n### 1. check_rejection() in rejection_utils.py:39\n```python\ndef check_rejection(similarity: float, threshold: float) -\u003e bool:\n    \"\"\"Validates against threshold\"\"\"\n```\n\n### 2. increment_rejection_count() in db.py:3480\n```python\ndef increment_rejection_count(self, signature_id: int):\n    \"\"\"Increments counter field on signature\"\"\"\n```\n\n### 3. record_leaf_rejection() in data_layer/mcts.py\n```python\ndef record_leaf_rejection(dag_step_id: str, leaf_node_id: int, similarity: float):\n    \"\"\"Records in rejection stats table for MCTS analysis\"\"\"\n```\n\n## Why This Is a Problem\n\n- 3 different places tracking rejections\n- Risk of inconsistent state (one gets called, others don't)\n- Duplicated logic for calculating adaptive thresholds\n- Hard to get unified view of rejection patterns\n\n## Solution\n\nConsolidate to single entry point in data_layer:\n\n```python\n# data_layer/mcts.py (or new rejection.py)\n\ndef record_rejection(\n    dag_step_id: str,\n    leaf_node_id: int,\n    similarity: float,\n    *,\n    threshold: float = None,  # None = use adaptive\n) -\u003e RejectionResult:\n    \"\"\"Single entry point for ALL rejection recording.\n    \n    Per CLAUDE.md \"New Favorite Pattern\": Consolidated pathway.\n    \n    This function:\n    1. Checks if similarity \u003c threshold (adaptive if not specified)\n    2. Records in rejection_stats table for MCTS\n    3. Increments rejection_count on signature\n    4. Returns result with rejection decision and stats\n    \"\"\"\n    # Determine threshold (Welford-adaptive or provided)\n    # Record in rejection_stats table\n    # Increment signature.rejection_count\n    # Return unified result\n```\n\n## Implementation Steps\n\n1. Read all 3 current implementations\n2. Create unified `record_rejection()` in data_layer\n3. Update all callers to use new function:\n   - Search for `check_rejection`, `increment_rejection_count`, `record_leaf_rejection`\n4. Remove old functions\n5. Run tests\n\n## Files to Modify\n\n- `src/mycelium/data_layer/mcts.py` - Add consolidated function\n- `src/mycelium/step_signatures/rejection_utils.py` - Remove or deprecate\n- `src/mycelium/step_signatures/db.py` - Remove increment_rejection_count\n- All callers\n\n## Testing\n\n- Verify rejection stats are recorded correctly\n- Verify signature rejection_count increments\n- Verify adaptive thresholds work\n\n## Context\n\nP2 priority per Big 3 audit - New Favorite Pattern violation.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:50:53.533691-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:04:37.770125-08:00","closed_at":"2026-01-28T13:04:37.770125-08:00","close_reason":"Already consolidated: record_leaf_rejection() is single entry point for all rejection recording. increment_rejection_count() only called from record_leaf_rejection(). check_rejection() handles low-similarity decisions. Consolidation done in mycelium-tgpx."}
{"id":"mycelium-a0t0","title":"Update cold start flow for graph-based signatures","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T07:03:41.716778-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:59:59.396855-08:00","closed_at":"2026-01-21T08:59:59.396855-08:00","close_reason":"Cold start now auto-embeds computation graphs for new signatures","dependencies":[{"issue_id":"mycelium-a0t0","depends_on_id":"mycelium-j9cq","type":"blocks","created_at":"2026-01-21T07:03:49.313922-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-a1ec","title":"Doc: Clarify threshold relationships in config","description":"Magic numbers in config.py have unclear relationships:\n- MIN_MATCH_THRESHOLD = 0.85\n- MIN_MATCH_THRESHOLD_COLD_START = 0.92\n- UMBRELLA_ROUTING_THRESHOLD = 0.5 (why different?)\n- DSL operation inference: 0.35 vs 0.60\n\nPer CLAUDE.md: 'Move all magic numbers to config' - done, but add comments explaining WHY different thresholds exist and how they relate.","status":"closed","priority":4,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:29:04.08815-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.382293-08:00","closed_at":"2026-01-20T18:00:01.382293-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-a4i","title":"Use RLock instead of Lock in StepSignatureDB","description":"Double lock acquisition pattern in observe_pending() (step_signatures.py:2111-2174) risks deadlock if refactored. Replace threading.Lock with threading.RLock in StepSignatureDB.__init__.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:36.767316-08:00","updated_at":"2026-01-08T11:26:34.268762-08:00","closed_at":"2026-01-08T11:26:34.268762-08:00"}
{"id":"mycelium-a6pe","title":"Test: Add unit tests for umbrella_learner.py","description":"Missing test coverage for auto-decomposition system. Need tests for:\n- UmbrellaLearner.generate_nl_interface() \n- UmbrellaLearner._extract_json() edge cases\n- UmbrellaLearner.get_decomposition_candidates() filtering logic\n- UmbrellaLearner.decompose_signature() child creation\n- learn_from_failures() end-to-end flow\n\nReference: src/mycelium/step_signatures/umbrella_learner.py (377 lines)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:19:51.065878-08:00","updated_at":"2026-01-14T06:23:14.138404-08:00","closed_at":"2026-01-14T06:23:14.138404-08:00"}
{"id":"mycelium-a7gi","title":"Brainstorm: Semantic Parameter Mapping via Step Descriptions","description":"## Status: Uncertain / Brainstorming\n\n## The Idea\nUse semantic matching based on step task descriptions to map DSL parameters.\n\nWhen each step executes, track:\n- **Value**: The numeric result (e.g., `25.0`)\n- **Meaning**: What it represents (e.g., \"area of triangle ABC\")\n- **Type**: Category (e.g., \"area\", \"length\", \"count\", \"coefficient\")\n\n## Example Flow\n\n```\nStep 1: \"Calculate the base of triangle ABC\" → 10.0\nStep 2: \"Calculate the height of triangle ABC\" → 5.0\nStep 3: \"Compute the area\" → needs base, height\n\nDSL for Step 3: area = (base * height) / 2\n```\n\nParameter mapping via semantic similarity:\n- DSL param \"base\" ↔ Step 1 meaning \"base of triangle\" → high match\n- DSL param \"height\" ↔ Step 2 meaning \"height of triangle\" → high match\n\n## Current Approach\n- Context is flat dict of step results\n- DSL params matched by key name or alias patterns\n- LLM generates aliases at signature creation time\n\n## Proposed Enhancement\n- Embed step meanings at execution time\n- Match DSL param names to step meanings via cosine similarity\n- Use type constraints (e.g., \"area\" param expects \"area\" type output)\n\n## Open Questions\n- Overhead of embedding every step output meaning?\n- How to handle ambiguous matches (two \"length\" values)?\n- Is this better than current alias-based approach?\n- Could this replace LLM-generated aliases entirely?\n\n## Related\n- mycelium-b4ny: Rich Typed Step Outputs (similar direction)\n- Current: DSL aliases in dsl_executor.py","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-13T07:05:19.52765-08:00","updated_at":"2026-01-20T17:50:06.689331-08:00","closed_at":"2026-01-20T17:50:06.689331-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-acf","title":"PromptTemplate regex matches escaped braces incorrectly","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-09T06:47:12.242811-08:00","updated_at":"2026-01-09T06:56:02.811607-08:00","closed_at":"2026-01-09T06:56:02.811607-08:00"}
{"id":"mycelium-addq","title":"Wire up mcts_dags table logging","description":"Create mcts_dag record when problem starts. Log problem_id, problem_desc, benchmark, difficulty_level. Set success/graded_at after final answer comparison.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:06.317292-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T14:22:37.937134-08:00","closed_at":"2026-01-20T14:22:37.937134-08:00","close_reason":"Wired up mcts_dags table logging: create_dag() called at solve() start with problem_id, problem_desc, benchmark, difficulty_level, ground_truth; grade_dag() called in record_problem_outcome() to set success/graded_at"}
{"id":"mycelium-aeu3","title":"Consolidate decomposition to single pathway","description":"**Current State:** 10+ decomposition entry points across 3 files:\n- planner.py: Planner.decompose(), decompose()\n- solver.py: should_force_decompose(), compute_maturity_decompose_prob(), should_try_decompose_first(), _decompose_and_resolve(), _blocking_decompose_complex_steps(), _decompose_complex_step(), _auto_decompose_signature()\n- umbrella_learner.py: decompose_signature()\n- mcts.py: compute_decompose_score()\n\n**Goal:** Single internal _decompose_core() with helper functions as thin wrappers. Clarify which are decision functions vs execution functions.\n\n**Files:** src/mycelium/planner.py, src/mycelium/solver.py, src/mycelium/step_signatures/umbrella_learner.py","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T13:22:00.167401-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T13:30:27.287177-08:00","closed_at":"2026-01-25T13:30:27.287177-08:00","close_reason":"Consolidated decomposition: DecompositionDecision dataclass + get_decomposition_decision() unified interface. Decision functions (should_force_decompose, should_try_decompose_first) are thin wrappers. planner.decompose() is THE CORE for execution. Documentation block added explaining hierarchy."}
{"id":"mycelium-ag3l","title":"Bug: Repeated decomposition attempts on atomic signatures","description":"When umbrella decomposition fails (LLM returns 1 step), the system doesn't track this. Result: repeated LLM calls trying to decompose atomic operations like compute_sum and compute_product.\n\n**Fix:** Add decomposition_attempts counter or cannot_decompose flag to signature model. Skip decomposition if attempts \u003e threshold or flag is set.\n\n**Evidence from logs:**\n- 'Cannot decompose compute_sum further (got 1 steps)' appears 6+ times\n- 'Cannot decompose compute_product further (got 1 steps)' appears 8+ times\n- Each attempt is a wasted LLM call","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T13:53:41.136971-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T14:00:27.269145-08:00","closed_at":"2026-01-25T14:00:27.269145-08:00","close_reason":"Fixed: Signatures now marked as atomic after failed decomposition. Skip check added at start of decompose_signature(). 67% reduction in repeated decomposition attempts."}
{"id":"mycelium-aicb","title":"Refactor: Break down solver._execute_step() (136 lines) into phases","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T14:55:39.693928-08:00","updated_at":"2026-01-20T17:50:06.417536-08:00","closed_at":"2026-01-20T17:50:06.417536-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-aj5","title":"Paper: Write step-level vs problem-level reusability analysis","description":"## Task\nWrite the analysis section showing steps are more reusable than whole problems\n\n## Location\n~/Desktop/mycelium/paper.md - Section 5, \"Step-Level vs Problem-Level Reusability\"\n\n## Analysis to perform\n1. Query the signature DB for step reuse statistics\n2. Compare: How often do identical/similar steps appear across different problems?\n3. Compare: How often do identical/similar whole problems appear?\n4. Show that step-level matching has much higher hit rate\n\n## Data source\n```bash\nsqlite3 ~/Desktop/mycelium/results/mycelium.db\n```\n\nKey tables: step_signatures, step_examples, step_usage_log\n\n## Deliverable\nWrite 1-2 paragraphs with concrete numbers showing step reusability \u003e\u003e problem reusability","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:42:56.770555-08:00","updated_at":"2026-01-09T09:46:40.582771-08:00","closed_at":"2026-01-09T09:46:40.582771-08:00"}
{"id":"mycelium-ajau","title":"Spike: Validate GTS for expression tree decomposition","description":"## Goal\nValidate that GTS (Goal-driven Tree-Structured) model from MWPToolkit can decompose English math word problems into expression trees we can parse and use.\n\n## Success Criteria\n1. Successfully install MWPToolkit\n2. Train GTS on MAWPS or ASDiv (English datasets)\n3. Run inference on 10+ test problems\n4. Verify prefix output is parseable to expression tree\n5. Check that recursive decomposition produces depth-1 atomic steps\n\n## Steps\n1. Install MWPToolkit: `pip install mwptoolkit` or clone repo\n2. Prepare English dataset (MAWPS preferred)\n3. Train GTS: `python run_mwptoolkit.py --model=GTS --dataset=mawps --task_type=single_equation --equation_fix=prefix`\n4. Write simple test script to run inference\n5. Parse prefix output to tree structure\n6. Document findings: accuracy, output format, edge cases\n\n## Decision Point\nIf GTS works well → proceed with full integration (create follow-up beads)\nIf GTS struggles → evaluate alternatives (small LLM, different model)\n\n## Context\nPer CLAUDE.md Big 5: Primitive vs Chain Nodes - we need a way to decompose problems into depth-1 atomic steps during cold start. GTS is the leading candidate.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T10:34:34.058237-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T12:25:28.984664-08:00","closed_at":"2026-01-29T12:25:28.984664-08:00","close_reason":"Spike successful. GTS trained on MAWPS (4746 problems). Results: 55.2% atomic (1 op), 44.8% need decomposition (2+ ops). Prefix parser works, depth calculation works. DECISION: Proceed with GTS integration for recursive math problem decomposition per CLAUDE.md Big 5."}
{"id":"mycelium-apgr","title":"Bug: Credit propagation uses 0.7 decay, CLAUDE.md specifies 0.5","description":"config.py:140 sets PARENT_CREDIT_DECAY=0.7, but CLAUDE.md:92 specifies 'decay^depth credit (default 0.5 per level)'. With 0.7 decay over 5 levels: 0.7^5=0.168, barely above MIN threshold 0.1. This biases learning toward shallow signatures. Per CLAUDE.md 'Credit propagation guided by decay by depth function' - hierarchy doesn't mature properly. Fix: Change to 0.5 as documented.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:31:12.460441-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:01:18.94824-08:00","closed_at":"2026-01-15T14:01:18.94824-08:00","close_reason":"Updated PARENT_CREDIT_DECAY from 0.7 to 0.5 and PARENT_CREDIT_MAX_DEPTH from 5 to 3, aligning with CLAUDE.md defaults. Added inline comments referencing CLAUDE.md. All 302 tests pass."}
{"id":"mycelium-arw","title":"Brainstorm: Should we partition the project into modules?","description":"Evaluate whether the project should be partitioned into separate modules/packages. Questions to explore:\n\n1. Current structure analysis - are we already modular?\n2. What are the natural boundaries in the codebase?\n3. Benefits: separation of concerns, independent testing, clearer APIs\n4. Costs: import complexity, versioning, dependency management\n5. Candidates for extraction: step_signatures, mcts, council, planner\n\nThis is a brainstorming/architecture discussion issue.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:07:18.357153-08:00","updated_at":"2026-01-20T17:38:44.37402-08:00","closed_at":"2026-01-20T17:38:44.37402-08:00","close_reason":"Stale brainstorm - 12 days old, deprioritizing"}
{"id":"mycelium-aur","title":"MEDIUM: Add logging to answer_norm.py silent exceptions","description":"answer_norm.py:86-89, 135-138 have bare 'except ValueError: pass' blocks. Conversion failures silently ignored. Add debug logging for troubleshooting.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:51.604366-08:00","updated_at":"2026-01-09T08:32:43.381566-08:00","closed_at":"2026-01-09T08:32:43.381566-08:00"}
{"id":"mycelium-auwn","title":"Create decomposition grading rules module","description":"## Goal\nCreate `src/mycelium/mathdecomp/grader.py` with the 10 core rules for grading decomposition quality.\n\n## The 10 Rules\n\n### Structural (Auto-gradable)\n1. **Atomic Operations** - Each step is single function call\n2. **Explicit References** - All inputs are typed Ref objects\n3. **No Dangling Refs** - Every ref resolves to extraction or prior step\n4. **Acyclic DAG** - Topological sort succeeds\n5. **No Orphaned Extractions** - Every extraction is used\n6. **Arithmetic Integrity** - Claimed results match computation\n7. **Single Answer Path** - One answer_ref to final result\n\n### Semantic (May need LLM)\n8. **Complete Parsing** - All quantities from problem captured\n9. **Valid Operation Choice** - Function matches semantic intent\n10. **Answer Alignment** - Final result answers what was asked\n\n## Interface\n```python\n@dataclass\nclass GradeResult:\n    passed: bool\n    rule_name: str\n    message: str\n\ndef grade_decomposition(decomp: Decomposition) -\u003e List[GradeResult]\ndef grade_rule_1_atomic(decomp: Decomposition) -\u003e GradeResult\n# ... one function per rule\n\ndef summary(results: List[GradeResult]) -\u003e str\n# Returns \"8/10 rules passed\" with details\n```\n\n## Acceptance Criteria\n- [ ] All 10 rules implemented\n- [ ] Each rule returns pass/fail with explanation\n- [ ] Summary function for overall score\n- [ ] Tests with known good/bad decompositions","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:53:44.396379-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:04:15.213019-08:00","closed_at":"2026-01-31T06:04:15.213019-08:00","close_reason":"Created grader.py with 10 core rules for decomposition quality","dependencies":[{"issue_id":"mycelium-auwn","depends_on_id":"mycelium-rqys","type":"blocks","created_at":"2026-01-31T05:54:33.228195-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-avlk","title":"Bug: Uninitialized centroid_sum can cause TypeError in db.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:19.031799-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:06:50.981885-08:00","closed_at":"2026-01-15T05:06:50.981885-08:00","close_reason":"Added None check to pack_embedding() in utils.py to match unpack_embedding() pattern. Now returns None instead of causing TypeError when passed None."}
{"id":"mycelium-b121","title":"Modify mathdecomp executor: use function registry","description":"## Goal\nUpdate `src/mycelium/mathdecomp/executor.py` to execute steps via function registry instead of custom operator logic.\n\n## Changes\n\n### Before\n```python\nOPS = {\"+\": lambda a, b: a + b, \"-\": lambda a, b: a - b, ...}\nresult = OPS[step.op](left_val, right_val)\n```\n\n### After\n```python\nfrom mycelium.function_registry import call_function\nresult = call_function(step.func, *resolved_inputs)\n```\n\n## Functions to Update\n- `execute_decomposition()` - use registry for execution\n- `verify_decomposition()` - verify using registry\n- `_resolve_ref()` - may need updates for new Ref structure\n\n## Acceptance Criteria\n- [ ] Execution uses function_registry.call_function()\n- [ ] Handles variable arity (1 arg for sqrt, 2 for add)\n- [ ] All existing tests pass with new implementation\n- [ ] Error handling for missing functions","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:53:41.452339-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:07:28.26359-08:00","closed_at":"2026-01-31T06:07:28.26359-08:00","close_reason":"Completed in commit bdca455 - executor uses function_registry, prompts updated with new schema","dependencies":[{"issue_id":"mycelium-b121","depends_on_id":"mycelium-icv4","type":"blocks","created_at":"2026-01-31T05:54:32.823127-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-b121","depends_on_id":"mycelium-rqys","type":"blocks","created_at":"2026-01-31T05:54:32.925043-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-b4ny","title":"Brainstorm: Rich Typed Step Outputs for Symbolic DSL","description":"## Status: Uncertain / Brainstorming\n\n## The Problem\nComplex DSL scripts need structured symbolic inputs, not just numbers from prior steps.\n\nTraditional step outputs are strings: \"42\" or \"k² - 16 = 0\". DSL scripts operating on symbolic expressions need the structure, not just the string representation.\n\n## Proposed Solution: StepOutput with Type Information\n\nAdjustments to DSL Parameter Flow:\n1. `detect_output_type()` - Parse step result strings into StepOutput\n2. DSL executor - Use `output.for_dsl(prefer_type=\"symbolic\")` for sympy operations\n3. Context passing - Replace string context with StepOutput objects\n\n## Example\n\n```python\nclass StepOutput:\n    value: Any           # The actual value (42, Eq(x**2-16, 0), etc.)\n    raw_string: str      # Original string representation\n    output_type: str     # \"numeric\", \"symbolic\", \"expression\", \"list\"\n    \n    def for_dsl(self, prefer_type: str = \"auto\") -\u003e Any:\n        \"\"\"Return value in format suitable for DSL execution.\"\"\"\n        if prefer_type == \"symbolic\" and self.output_type == \"symbolic\":\n            return self.value  # Return sympy object directly\n        return self.raw_string\n```\n\n## Open Questions\n- How much parsing complexity is worth it?\n- Does this solve a real bottleneck or is string parsing in DSL executor good enough?\n- Performance implications of carrying structured objects through context?","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-13T07:03:06.224854-08:00","updated_at":"2026-01-20T17:50:06.734696-08:00","closed_at":"2026-01-20T17:50:06.734696-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-b51p","title":"Skip coherence validation for single-step plans","description":"Currently validation runs on every solve, even for single-step plans where coherence checking is meaningless (no dependencies to validate). Consider skipping validation when len(plan.steps) \u003c= 1 to save embedding costs.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:06:56.224118-08:00","updated_at":"2026-01-15T14:41:18.699071-08:00","closed_at":"2026-01-15T14:41:18.699071-08:00","close_reason":"Added early-exit in solver.py:459 - skip plan.validate() when len(plan.steps) \u003c= 1 since single-step plans have no dependencies or cycles to check. Saves validation overhead on simple problems."}
{"id":"mycelium-b5tq","title":"LLM-assisted failure diagnosis to identify exact failing (dag_step, leaf_node) pair","description":"## Problem\nWhen a problem fails, we blame ALL (dag_step, leaf_node) pairs in the execution path equally. Only one pair actually caused the failure, but statistical convergence over many problems is needed to identify it.\n\n## Proposal\nOn failure, ask LLM to inspect the dag_steps and results to identify which specific step likely failed.\n\n### Approach: Weighted blame (hybrid)\n```python\n# On failure, ask LLM which step likely failed\nllm_blamed_step = await diagnose_failure(dag_steps, results, ground_truth)\n\n# Apply partial blame: LLM-blamed step gets more weight\nfor step, node in path:\n    if step == llm_blamed_step:\n        record_failure(step, node, weight=0.7)  # Higher blame\n    else:\n        record_failure(step, node, weight=0.3)  # Lower but still some\n```\n\n### Why hybrid?\n- LLM might be wrong - can't fully trust its diagnosis\n- Statistical accumulation over time corrects LLM mistakes\n- But LLM insight can accelerate convergence when correct\n\n## Latency impact\n- ~1-3 seconds per failed problem (LLM call)\n- Only on failures, not on hot path for successes\n- Failures are \"wasted\" time anyway - might as well extract learning signal\n\n## Questions to resolve\n1. What model to use? (fast/cheap like gpt-4o-mini vs accurate like gpt-4o)\n2. How to weight LLM blame vs statistical blame?\n3. Should this be optional/feature-flagged?\n4. What context to include in prompt? (problem, steps, results, ground_truth)\n\n## References\n- Per CLAUDE.md: \"Failures are valuable data points\"\n- Per CLAUDE.md: \"(dag_step, leaf_node) is what we're learning\"","status":"closed","priority":3,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:38:28.824009-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T05:49:10.63593-08:00","closed_at":"2026-01-29T05:49:10.63593-08:00","close_reason":"Implemented LLM failure diagnosis: when a problem fails, LLM identifies likely culprit step, which gets 0.7 weight vs 0.3 for others. Data tracked in weighted_failures and llm_blamed_count columns."}
{"id":"mycelium-b8ea","title":"Perf: LRU cache for find_signature hot path","description":"Hot signatures get repeated queries. Add in-memory LRU cache with TTL to skip DB entirely for frequent lookups. Invalidate on centroid update.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:30:36.766687-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.05194-08:00","closed_at":"2026-01-20T18:00:01.05194-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-bb2","title":"Validate wave+essence combo on larger dataset","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T12:24:01.352783-08:00","updated_at":"2026-01-20T16:51:28.5327-08:00","closed_at":"2026-01-20T16:51:28.5327-08:00","close_reason":"Superseded by MCTS wave function implementation - tables wired up, analysis queries available in mcts.py"}
{"id":"mycelium-bbp","title":"MEDIUM: Validate step IDs in planner.py","description":"planner.py:232-236 - Step ID extraction doesn't validate format. Silent fallback to 'unnamed_N' could cause downstream issues. Validate against pattern (alphanumeric, underscores).","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:54.727695-08:00","updated_at":"2026-01-09T08:31:30.49987-08:00","closed_at":"2026-01-09T08:31:30.49987-08:00"}
{"id":"mycelium-bdt","title":"Expand training to more MATH categories and levels","description":"Currently only training on L1-3 algebra.\n\nExpand to:\n- More categories: geometry, number_theory, counting_probability, prealgebra, intermediate_algebra\n- Harder levels: L4, L5\n\nThis will:\n1. Build a richer signature library\n2. Test decomposition on harder problems\n3. See if cross-category patterns emerge","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T05:32:56.599776-08:00","updated_at":"2026-01-08T11:44:03.167035-08:00","closed_at":"2026-01-08T11:44:03.167035-08:00","dependencies":[{"issue_id":"mycelium-bdt","depends_on_id":"mycelium-mpg","type":"blocks","created_at":"2026-01-08T05:33:18.519883-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-bey","title":"Fragile timezone handling in decay_unused_signatures","description":"decay_unused_signatures() strips timezone info from timestamps and compares against datetime.utcnow(). If last_used_at is stored in local time instead of UTC, decay calculations will be wrong. Consider: (1) Standardizing all timestamps to UTC with 'Z' suffix, (2) Using timezone-aware datetime comparisons, or (3) Adding validation that timestamps are UTC.","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-08T12:15:57.182868-08:00","updated_at":"2026-01-15T05:53:18.865023-08:00","closed_at":"2026-01-15T05:53:18.865023-08:00","close_reason":"Fixed timezone handling in compute_staleness_penalty() - now handles naive timestamps (assumes UTC), 'Z' suffix, and '+00:00' suffix. Added utc_now_iso() helper for future use."}
{"id":"mycelium-bjrf","title":"Feature: Welford stats table for signature statistics","description":"## Summary\nCreate a welford_stats table to track running mean and variance for signature statistics using Welford's online algorithm.\n\n## Schema\n```sql\nCREATE TABLE welford_stats (\n    signature_id INTEGER PRIMARY KEY REFERENCES step_signatures(id),\n    -- Routing similarity stats (how well does routing work to this node?)\n    route_n INTEGER DEFAULT 0,\n    route_mean REAL DEFAULT 0.0,\n    route_m2 REAL DEFAULT 0.0,  -- sum of squared differences from mean\n    -- Child similarity stats (how tight is the cluster?)\n    child_n INTEGER DEFAULT 0,\n    child_mean REAL DEFAULT 0.0,\n    child_m2 REAL DEFAULT 0.0,\n    -- Execution success rate\n    exec_n INTEGER DEFAULT 0,\n    exec_successes INTEGER DEFAULT 0,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n```\n\n## Implementation\n1. Add table to schema in `db.py` `_ensure_tables()`\n2. Create `WelfordStats` dataclass in `db.py`\n3. Add methods to db.py:\n   - `update_welford_route(sig_id, similarity)` - update routing stats\n   - `update_welford_child(sig_id, similarity)` - update child cluster stats\n   - `update_welford_exec(sig_id, success: bool)` - update execution stats\n   - `get_welford_stats(sig_id) -\u003e WelfordStats`\n   - `get_welford_variance(sig_id) -\u003e float` - convenience method\n\n## Welford Update Formula\n```python\ndef welford_update(n, mean, m2, new_value):\n    n += 1\n    delta = new_value - mean\n    mean += delta / n\n    delta2 = new_value - mean\n    m2 += delta * delta2\n    return n, mean, m2\n\ndef welford_variance(n, m2):\n    if n \u003c 2:\n        return 0.0\n    return m2 / (n - 1)  # sample variance\n```\n\n## Integration Points\n- Call `update_welford_route()` after every routing decision in solver.py\n- Call `update_welford_exec()` after every step execution\n- Auto-create welford_stats row when signature is created","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-27T06:37:59.030239-08:00","created_by":"Bryce Roche","updated_at":"2026-01-27T06:49:05.106214-08:00","closed_at":"2026-01-27T06:49:05.106214-08:00","close_reason":"Implemented welford_stats table with route/child/exec tracking, config thresholds, and cold start detection"}
{"id":"mycelium-bkz","title":"Superposition of Methods (Soft Execution)","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:54:41.22211-08:00","updated_at":"2026-01-08T08:54:48.605031-08:00","closed_at":"2026-01-08T08:54:48.605031-08:00"}
{"id":"mycelium-bl85","title":"Bug: Blocking time.sleep() in async context (db.py:376)","description":"In db.py:376, time.sleep() is used inside retry logic for sqlite3.OperationalError. This blocks the entire async event loop, causing severe latency degradation under database contention. Per CLAUDE.md 'Everything must be automated - system must be independent' - this makes the system unreliable under load. Fix: Use asyncio.sleep() or refactor retry logic to be non-blocking.","status":"closed","priority":0,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:30:47.050985-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T13:42:17.401967-08:00","closed_at":"2026-01-15T13:42:17.401967-08:00","close_reason":"Added runtime warning when find_or_create() is called from async context. Fixed 5 broken test mocks in test_umbrella_learner.py to correctly mock find_or_create_async."}
{"id":"mycelium-bod","title":"Add structured logging to mcts.py","description":"Add logging for MCTS tree search iterations, node selection, and strategy evaluation.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:18.612936-08:00","updated_at":"2026-01-09T07:48:38.750517-08:00","closed_at":"2026-01-09T07:48:38.750517-08:00"}
{"id":"mycelium-br28","title":"Feature: Welford-based sibling vs child decision logic","description":"## Summary\nImplement Welford-based decision logic for sibling vs child placement when adding new signatures after cold start.\n\n## Decision Logic\n```python\ndef decide_placement(new_embedding, parent_node, welford_stats) -\u003e Decision:\n    \"\"\"\n    Decide whether new signature should be:\n    - SIBLING: Add as sibling (child of same parent)\n    - CHILD: Add as child of existing sibling (promote sibling to umbrella)\n    - MERGE: Merge into existing signature (too similar)\n    - NEW_CLUSTER: Create as child of root (too different from all)\n    \"\"\"\n    # Get Welford stats for the parent's cluster\n    mean_sim = welford_stats.child_mean\n    std_sim = sqrt(welford_stats.child_m2 / max(1, welford_stats.child_n - 1))\n    \n    # Compute similarity to best matching sibling\n    best_sibling, best_sim = find_best_sibling(new_embedding, parent_node)\n    \n    # Z-score: how many std devs from cluster mean?\n    z_score = (best_sim - mean_sim) / max(0.01, std_sim)\n    \n    if z_score \u003e 3.0:  # Very similar to existing (\u003e3σ above mean)\n        return Decision.MERGE\n    elif z_score \u003e -2.0:  # Within normal range\n        return Decision.SIBLING\n    elif z_score \u003e -3.0:  # Somewhat different\n        return Decision.CHILD  # Create sub-cluster\n    else:  # Very different (\u003e3σ below mean)\n        return Decision.NEW_CLUSTER\n```\n\n## Thresholds\n```python\n# config.py\nWELFORD_MERGE_THRESHOLD = 3.0    # z-score above which to merge\nWELFORD_SIBLING_THRESHOLD = -2.0  # z-score above which to add as sibling\nWELFORD_CHILD_THRESHOLD = -3.0    # z-score above which to add as child\n# Below CHILD_THRESHOLD: new cluster under root\n```\n\n## Implementation\n1. Add `decide_signature_placement()` method to db.py\n2. Integrate into `find_or_create_async()` after cold start\n3. Add Decision enum: SIBLING, CHILD, MERGE, NEW_CLUSTER\n\n## Rationale\nPer CLAUDE.md: \"The tree's goal is to match (leaf_node, dag_step) pairs with high similarity and low variance.\"\nWelford stats give us principled thresholds based on observed data, not arbitrary magic numbers.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-27T06:38:03.232992-08:00","created_by":"Bryce Roche","updated_at":"2026-01-27T07:03:49.330372-08:00","closed_at":"2026-01-27T07:03:49.330372-08:00","close_reason":"Implemented in commit 11fb77d","dependencies":[{"issue_id":"mycelium-br28","depends_on_id":"mycelium-bjrf","type":"blocks","created_at":"2026-01-27T06:38:08.946189-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-bt0","title":"Document: How problem decomposition maps to step signatures","description":"Investigate and document the current decomposition flow:\n\n1. How does the Planner decompose problems into DAG steps?\n2. How are steps embedded and matched to signature clusters?\n3. What determines when a step joins an existing cluster vs creates a new one?\n4. How does the injection decision get made (reliable threshold)?\n\nGoal: Understand and document the current approach to identify improvement opportunities.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T08:18:14.057531-08:00","updated_at":"2026-01-08T08:25:21.576307-08:00","closed_at":"2026-01-08T08:25:21.576307-08:00"}
{"id":"mycelium-bt8","title":"Race condition in centroid update - non-atomic operations","description":"step_signatures.py:1193-1230 - add_example_to_cluster() reads centroid, computes new value in memory, writes back. Not atomic. Two concurrent calls can lose an example. Fix with SQL-based computation or row-level locks.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:43.686028-08:00","updated_at":"2026-01-08T11:26:34.331746-08:00","closed_at":"2026-01-08T11:26:34.331746-08:00"}
{"id":"mycelium-bx2h","title":"Refactor: Break down try_execute_dsl() (100 lines) into smaller functions","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T14:55:38.165452-08:00","updated_at":"2026-01-20T17:50:06.463031-08:00","closed_at":"2026-01-20T17:50:06.463031-08:00","close_reason":"Stale - older than Jan 15, deprioritizing","dependencies":[{"issue_id":"mycelium-bx2h","depends_on_id":"mycelium-g4mt","type":"blocks","created_at":"2026-01-13T14:55:54.082987-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-c2u","title":"Improve planner cycle detection and precision handling","description":"Minor improvements from code review: (1) Cycle detection traverses dependencies backwards - works but confusing, consider reversing for clarity. (2) Only reports first cycle found - could report all independent cycles. (3) answer_norm percent conversion uses .10f precision which could truncate extreme values like 0.0001%.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T13:35:49.148277-08:00","updated_at":"2026-01-08T13:37:39.769687-08:00","closed_at":"2026-01-08T13:37:39.769687-08:00"}
{"id":"mycelium-c5l5","title":"Bug: Steps flagged for decomposition not getting decomposed","description":"## Problem\nThe MCTS post-mortem repeatedly identifies steps needing decomposition:\n```\n[solver] Post-mortem: 1 steps need decomposition: ['Calculate number of students in jazz dan']\n```\n\nBut these steps don't seem to get decomposed. The same step appears flagged across multiple problems.\n\n## Expected Behavior\nSteps flagged for decomposition should trigger umbrella_learner to decompose them.\n\n## Questions\n1. Why isn't decomposition happening?\n2. Is there a missing connection between post-mortem flagging and umbrella_learner?\n3. Should inline decomposition handle these?\n\n## Files\n- src/mycelium/solver.py (post-mortem)\n- src/mycelium/data_layer/mcts.py (flagging)\n- src/mycelium/step_signatures/umbrella_learner.py (decomposition)","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T18:35:03.594225-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T18:38:11.528047-08:00","closed_at":"2026-01-26T18:38:11.528047-08:00","close_reason":"Fixed: steps_needing_decomposition was only logged but never acted upon. Added loop to call _mark_step_for_decomposition for each flagged step."}
{"id":"mycelium-chv","title":"Implement full MCTS with decomposition execution","description":"Current MCTS implementation:\n- Creates nodes with priors from signatures\n- Returns prior score without full tree search\n\nFull implementation would:\n1. Generate multiple decomposition strategies\n2. Actually execute each strategy (simulation)\n3. Backpropagate success/failure\n4. Select best strategy based on UCB1\n\nThis is the 'learning to decompose' core idea - MCTS explores which decomposition strategies work best.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T05:33:02.449954-08:00","updated_at":"2026-01-08T07:01:53.749096-08:00","closed_at":"2026-01-08T07:01:53.749096-08:00"}
{"id":"mycelium-civ6","title":"MCTS Phase 4: Auto-detect hard problems, adaptive budget","description":"Part of mycelium-5vp4 (Adaptive compute budget)\n\nAuto-scale budget based on difficulty:\n- estimate_difficulty() combines hardness signals\n- Easy problems: budget=1.0 (cheap)\n- Hard problems: budget=3.0+ (more exploration)\n- Very hard: budget=10.0 or graceful degradation\n\nSignals: routing confidence, UCB1 gap, historical failure rate\n\nFiles: solver.py, config.py","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:01:45.636926-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T20:16:47.177258-08:00","closed_at":"2026-01-15T20:16:47.177258-08:00","close_reason":"DAG architecture already handles composition - each step routes through tree independently. Multi-path exploration for routing uncertainty may still be useful but deprioritized.","dependencies":[{"issue_id":"mycelium-civ6","depends_on_id":"mycelium-2tf6","type":"blocks","created_at":"2026-01-15T20:02:10.73575-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-cj9a","title":"Feature: Add signature step-level stats table","description":"Per CLAUDE.md: 'DB audit for signature step level stats'\n\nCurrently no analytics tables for:\n- Query performance (slow query log)\n- Cache hit rates\n- Signature lifecycle events\n- DSL execution times\n\nAdd optional analytics table (feature flagged) to track:\n- Per-signature latency distribution\n- Routing path depth histogram\n- Cache efficiency metrics","status":"closed","priority":3,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:28:33.773448-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.358686-08:00","closed_at":"2026-01-20T18:00:01.358686-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-cjkc","title":"Bug: High cosine-sim nodes created as duplicates instead of matching","description":"Nodes with graph_embedding similarity ~1.0 are being created as new signatures instead of routing to existing identical ones. Example: 11 compute_sum signatures all with 0.996-1.000 similarity.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T15:06:14.485529-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T10:03:33.064709-08:00","closed_at":"2026-01-26T10:03:33.064709-08:00","close_reason":"Added sibling dedup check in CLUSTER path - now checks find_best_child_match before creating new signatures under same parent"}
{"id":"mycelium-clc","title":"Improve embedding-based sub-problem clustering","description":"Focus on using embeddings to better match and group sub-problems.\n\nCurrent state:\n- Signatures have embeddings for semantic matching\n- Need to improve how we cluster similar sub-problems across different problem solves\n\nGoals:\n1. Better similarity thresholds for grouping related sub-problems\n2. Clustering algorithm to find canonical sub-problem types\n3. Track which sub-problems are variations of the same underlying pattern\n4. Use clusters to inform MCTS - if we've solved similar sub-problems before, reuse that knowledge\n\nThis replaces hash-based fingerprinting with pure embedding-based identity.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-08T06:27:45.979346-08:00","updated_at":"2026-01-08T07:03:01.353682-08:00","closed_at":"2026-01-08T07:03:01.353682-08:00"}
{"id":"mycelium-cq5","title":"Paper: Ablation study on reliability threshold","description":"## Task\nRun ablation study on the reliability threshold (3 uses, 70% success) and write up findings\n\n## Location\n~/Desktop/mycelium/paper.md - Section 5, \"Reliability Threshold Ablation\"\n\n## Ablation conditions\n1. No threshold (inject all signatures immediately)\n2. Uses only (3+ uses, any success rate)\n3. Success only (any uses, 70%+ success)\n4. Full threshold (3+ uses AND 70%+ success) - current default\n\n## How to run\nModify the reliability check in step_signatures.py or run with different configs\n\n## Metrics to measure\n- Accuracy on held-out problems\n- False injection rate (injected bad methods)\n- Coverage (% of steps with injection)\n\n## Deliverable\n- Table comparing ablation conditions\n- 1-2 paragraphs explaining why the threshold matters","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:43:00.938661-08:00","updated_at":"2026-01-20T17:53:29.413174-08:00","closed_at":"2026-01-20T17:53:29.413174-08:00","close_reason":"Stale - Jan 9, deprioritizing"}
{"id":"mycelium-cqe","title":"Add energy normalization to prevent runaway amplitude","description":"Implement energy normalization to prevent unbounded amplitude growth:\n\nOptions:\n1. Hard cap: amplitude = min(amplitude, AMP_MAX) where AMP_MAX = 0.35-0.5\n2. Soft cap: amplitude = AMP_MAX * tanh(amplitude / AMP_MAX)\n\nAlso track:\n- field_energy = Σ amplitude (already done)\n- energy_delta_per_problem\n\nAcceptance: energy doesn't grow without bound across runs.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T09:41:28.572656-08:00","updated_at":"2026-01-08T09:47:45.079029-08:00","closed_at":"2026-01-08T09:47:45.079029-08:00"}
{"id":"mycelium-cqr","title":"Brainstorm: Incorporate mathematical waves into mycelium","description":"Brainstorm: Deep integration of mathematical WAVES into mycelium\n\nThis is an exploratory issue to brainstorm how wave mathematics could enhance the system.\n\n## Initial Ideas to Explore\n\n### 1. Embedding Space as Wave Interference\n- Treat signature embeddings as wave functions in high-dimensional space\n- Similarity matching becomes constructive/destructive interference\n- Clusters form at interference maxima (standing waves)\n\n### 2. Fourier Analysis of Problem Structure\n- Decompose problems into frequency components\n- Low-frequency = core concept, high-frequency = surface details\n- Filter out noise, identify fundamental patterns\n\n### 3. Wave Propagation for Knowledge Transfer\n- When a signature succeeds, 'ripple' confidence to similar signatures\n- Damped waves: closer signatures get stronger signal\n- Could replace/enhance the current variant relationship system\n\n### 4. Resonance for Pattern Matching\n- Signatures 'resonate' with problems at characteristic frequencies\n- Strong resonance = good match, weak = poor match\n- Natural frequency could encode problem difficulty/complexity\n\n### 5. Superposition of Solution Methods\n- Multiple method templates as superposition of states\n- 'Collapse' to specific method based on problem context\n- Quantum-inspired exploration vs exploitation\n\n### 6. Wavelet Transform for Multi-scale Decomposition\n- Analyze problems at multiple scales simultaneously\n- Local details + global structure\n- Natural fit for hierarchical problem decomposition\n\n### 7. Phase as Temporal/Sequential Information\n- Encode step ordering as phase relationships\n- Dependencies become phase constraints\n- DAG execution order emerges from phase alignment\n\n## Questions to Answer\n- Which wave concepts map most naturally to our domain?\n- What mathematical framework (Fourier, wavelets, etc)?\n- Where would waves add value vs being over-engineering?\n- Are there existing papers on wave-based ML/reasoning?\n\n## Next Steps\n- Research existing work on wave-based representations\n- Prototype one concept (maybe embedding interference?)\n- Evaluate if the added complexity is worth it","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T07:43:12.604723-08:00","updated_at":"2026-01-08T11:19:58.015797-08:00","closed_at":"2026-01-08T11:19:58.015797-08:00"}
{"id":"mycelium-cqs","title":"Multiple decompositions (superposition of solution paths)","description":"Generate N different problem decompositions, solve all in parallel, return the one with highest confidence.\n\nFrom wave function analysis: Instead of collapsing to single decomposition immediately, maintain superposition of possible solution paths.\n\nImplementation:\n1. Add decompose_superposition(n=3) to Planner\n2. Use higher temperature for variation\n3. Add solve_superposition() that runs all paths\n4. Score results by confidence/consistency\n5. Consider: expensive but may help hard problems","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:34:21.542519-08:00","updated_at":"2026-01-20T17:32:52.059766-08:00","closed_at":"2026-01-20T17:32:52.059766-08:00","close_reason":"Superseded by multi-path MCTS exploration - solver already forks at low-confidence nodes and tracks alternative paths via thread system"}
{"id":"mycelium-cqv","title":"Replace raw interference with normalized scoring","description":"Per ablation findings: raw wave scores vanish, causing 0% reuse.\n\nImplementation:\n1. In find_by_resonance: compute raw interference scores for all candidates\n2. Normalize within that candidate set using max-abs scaling:\n   s_norm = s_raw / (max(|s_raw|) + eps)\n\nThis prevents vanishing and doesn't assume normality.\n\nOptional secondary: z-score with tanh squash, but start with max-abs for stability.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T09:44:31.53466-08:00","updated_at":"2026-01-08T09:49:59.65573-08:00","closed_at":"2026-01-08T09:49:59.65573-08:00"}
{"id":"mycelium-ctz","title":"Server disconnection errors during parallel LLM calls","description":"When running 8 parallel workers, some problems fail with 'Server disconnected without sending a response'. Seen on problems 67-68 in 100-problem run. May need retry logic or rate limiting.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T14:03:28.51142-08:00","updated_at":"2026-01-09T08:30:18.949826-08:00","closed_at":"2026-01-09T08:30:18.949826-08:00"}
{"id":"mycelium-cwbb","title":"Test: Add unit tests for refinement.py","description":"Signature refinement module lacks tests. Need tests for:\n- decay_unused_signatures() time-based decay\n- suggest_cluster_merges() similarity grouping  \n- refine_signature_boundaries() centroid updates\n- Various edge cases and error handling\n\nReference: src/mycelium/step_signatures/refinement.py (473 lines)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:20:03.948358-08:00","updated_at":"2026-01-14T06:24:49.91533-08:00","closed_at":"2026-01-14T06:24:49.91533-08:00"}
{"id":"mycelium-cxpi","title":"P1: Consolidate 4 signature stat update methods to single entry point","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": We have 4 different methods for incrementing signature stats, creating maintenance burden and risk of inconsistent behavior.\n\n## Current State (db.py)\n\n1. `_increment_signature_stat()` - Line 2759, base implementation with parent credit propagation\n2. `increment_signature_successes()` - Line 2817, wrapper for success column\n3. `increment_signature_failures()` - Line 2841, wrapper for failure column\n4. `increment_signature_partial_success()` - Line 2865, wrapper for partial success\n\n## Why This Is a Problem\n\n- Only `_increment_signature_stat()` handles parent credit propagation correctly\n- Public wrappers are thin but pattern is error-prone\n- Easy to accidentally add new stat type without propagation\n- Violates \"New Favorite Pattern\" - should have ONE entry point\n\n## Solution\n\nConsolidate to single public method with stat_type enum:\n\n```python\nclass SignatureStat(Enum):\n    SUCCESS = \"successes\"\n    FAILURE = \"failures\"\n    PARTIAL = \"partial_successes\"\n\ndef increment_signature_stat(\n    self,\n    signature_id: int,\n    stat_type: SignatureStat,\n    *,\n    propagate_to_parents: bool = True,\n    difficulty: float = 0.5,\n) -\u003e None:\n    \"\"\"Single entry point for all signature stat updates.\n    \n    Per CLAUDE.md \"New Favorite Pattern\": Consolidated pathway.\n    Per CLAUDE.md \"Credit Propagation\": Automatically propagates to parents.\n    \"\"\"\n    column = stat_type.value\n    # ... existing _increment_signature_stat logic\n```\n\n## Implementation Steps\n\n1. Create `SignatureStat` enum in db.py or a types module\n2. Rename `_increment_signature_stat()` to `increment_signature_stat()` (make public)\n3. Add `stat_type: SignatureStat` parameter\n4. Update all callers to use new signature:\n   - `increment_signature_successes(id)` → `increment_signature_stat(id, SignatureStat.SUCCESS)`\n   - `increment_signature_failures(id)` → `increment_signature_stat(id, SignatureStat.FAILURE)`\n   - etc.\n5. Deprecate old wrapper methods\n6. Run tests\n7. Remove deprecated wrappers\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/db.py` - Main consolidation\n- Search for callers: `increment_signature_successes`, `increment_signature_failures`, `increment_signature_partial_success`\n\n## Testing\n\n- All existing tests must pass\n- Verify parent credit propagation works for all stat types\n- Add test for new consolidated API\n\n## Context\n\nThis is a P1 priority per Big 3 audit. Other Claude instances can pick this up.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:50:03.586558-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:06:24.397093-08:00","closed_at":"2026-01-28T13:06:24.397093-08:00","close_reason":"Consolidated 4 stat update methods to single increment_signature_stat(id, stat_type, amount). Added SignatureStat enum. Updated all callers in mcts.py. Old methods deprecated with warnings."}
{"id":"mycelium-cyf8","title":"DSL Auto-Rewriter: Automatically fix underperforming DSLs","description":"When a signature has low success rate but high traffic, automatically analyze failures and use LLM to rewrite the DSL script. Per CLAUDE.md: 'rewrite DSL if centroid avg outside confidence bounds'. ~400 lines in src/mycelium/step_signatures/dsl_rewriter.py","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:38:00.063572-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:44:57.124622-08:00","closed_at":"2026-01-15T09:44:57.124622-08:00","close_reason":"Implemented DSL auto-rewriter (364 lines). Identifies underperforming sigs, uses LLM to generate better DSLs."}
{"id":"mycelium-d0b","title":"Add comprehensive integration tests for matching pipeline","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:18.249476-08:00","updated_at":"2026-01-09T10:50:40.847089-08:00","closed_at":"2026-01-09T10:50:40.847089-08:00","dependencies":[{"issue_id":"mycelium-d0b","depends_on_id":"mycelium-8mu","type":"blocks","created_at":"2026-01-09T05:55:04.533609-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-d0b","depends_on_id":"mycelium-6o3","type":"blocks","created_at":"2026-01-09T05:55:11.111149-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-d0uf","title":"Consolidate signature stats update pathway","description":"## Problem\n5 functions in src/mycelium/step_signatures/db.py do parent credit propagation with nearly identical logic (~150 lines duplicated):\n\n- `increment_signature_successes()` (line ~2908) - Updates successes + propagates with decay\n- `increment_signature_failures()` (line ~2954) - Updates operational_failures + propagates with decay  \n- `increment_signature_partial_success()` (line ~3000) - Updates successes with weight + propagates\n- `record_interference_outcome()` (line ~2852) - Updates successes OR failures based on type\n- `update_problem_outcome()` (line ~3838) - Updates successes via SQL, then calls _collect_parent_credits()\n\nAll use identical:\n- Recursive CTE to fetch ancestors\n- Same config imports: PARENT_CREDIT_DECAY, PARENT_CREDIT_MAX_DEPTH, PARENT_CREDIT_MIN\n- Same propagation logic with decay^depth\n\n## Pattern to Follow\nSee `propagate_graph_centroid_to_parents()` (line ~989) as the model - we just consolidated all graph_centroid updates to use this single pathway with `include_self` parameter.\n\n## Proposed Solution\nCreate unified internal function:\n```python\ndef _increment_signature_stat(\n    self,\n    conn,\n    signature_id: int,\n    stat_column: str,  # 'successes' or 'operational_failures'\n    amount: float = 1.0,\n    propagate_to_parents: bool = True,\n    _depth: int = 0,\n):\n    '''Single pathway for all signature stat increments with parent propagation.'''\n```\n\nThen simplify all 5 functions to be thin wrappers calling this.\n\n## Acceptance Criteria\n- [ ] Single internal function handles all stat increments + parent propagation\n- [ ] All 5 existing functions become thin wrappers\n- [ ] Parent propagation logic exists in exactly one place\n- [ ] Existing tests still pass\n- [ ] Credit propagation behavior unchanged","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:08:41.137051-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:34:08.342346-08:00","closed_at":"2026-01-25T08:34:08.342346-08:00","close_reason":"Created _increment_signature_stat() as single internal pathway for stat updates with parent propagation. 4 functions now use it: increment_signature_successes, increment_signature_failures, increment_signature_partial_success, record_interference_outcome. update_problem_outcome intentionally uses different batch semantics (MAX dedup, last_used_at, umbrella-only parents) - documented why it's separate. All 401 tests pass."}
{"id":"mycelium-ddx","title":"Implement Essence Subspace - high-variance dimension selection","description":"Identify and persist the embedding dimensions that carry the most semantic discrimination between step signatures. Compute per-dimension variance from centroids, select top 20% (configurable), store as essence_dims in signature DB metadata. Recompute only when DB grows significantly (+20% signatures).","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T10:55:30.879165-08:00","updated_at":"2026-01-08T11:09:19.424358-08:00","closed_at":"2026-01-08T11:09:19.424358-08:00"}
{"id":"mycelium-dp4y","title":"DSL blocked by symbolic inputs - need numeric decomposition","description":"DSL injections are blocked when step inputs are symbolic (e.g., math expressions) instead of numeric. The planner should decompose problems to produce numeric intermediate results before arithmetic DSL steps. This is why we see TYPE_MISMATCH errors like: param 'values' expected numeric, got symbolic expression.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T11:58:00.43308-08:00","updated_at":"2026-01-12T12:18:28.563863-08:00","closed_at":"2026-01-12T12:18:28.563863-08:00"}
{"id":"mycelium-dpo","title":"Non-deterministic exploration in should_inject() cold-start","description":"StepSignature.should_inject() uses np.random.random() for cold-start exploration, making results non-reproducible. This can cause flaky tests and unpredictable behavior. Options: (1) Accept a seed parameter, (2) Use hash(signature.id) % 100 \u003c exploration_rate*100 for deterministic exploration, (3) Document the randomness and accept it for production use.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T13:13:01.896583-08:00","updated_at":"2026-01-20T17:50:06.118542-08:00","closed_at":"2026-01-20T17:50:06.118542-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-dt9","title":"Paper: Add architecture diagram figure","description":"## Task\nCreate an architecture diagram for the paper\n\n## Location\n~/Desktop/mycelium/paper.md - Add as Figure 1 in Section 3\n\n## Diagram should show\n1. Problem input\n2. Decomposition into DAG\n3. Signature DB lookup (with cosine similarity)\n4. Hybrid execution (formula/procedure/LLM branches)\n5. Final merge/synthesis\n6. Learning loop (new signatures stored)\n\n## Reference\nThe ASCII diagram in ~/Desktop/mycelium/README.md can be adapted\n\n## Format\n- ASCII art for markdown, or\n- Create proper figure and reference it\n\n## Deliverable\nAdd figure to paper.md with caption explaining the flow","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:43:01.801603-08:00","updated_at":"2026-01-09T09:47:48.983733-08:00","closed_at":"2026-01-09T09:47:48.983733-08:00"}
{"id":"mycelium-dtj","title":"Migrate execution_plan_optimizer.py to data_layer","description":"Replace 1 direct sqlite3.connect call with data_layer.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:00:32.653375-08:00","updated_at":"2026-01-09T10:16:28.743373-08:00","closed_at":"2026-01-09T10:16:28.743373-08:00"}
{"id":"mycelium-e3o","title":"Feature: Decompose steps when LLM outputs symbolic but context has concrete values","description":"## Problem\nWhen context has concrete numeric values (e.g., coordinates [3, 0]) but the LLM outputs symbolic expressions (e.g., (x - 3, y)), this indicates a grounding failure that decomposition could fix.\n\n## Current Behavior\n- Decomposition triggered only on low DSL confidence\n- LLM execution doesn't trigger decomposition even when output is clearly wrong\n\n## Proposed Solution\nAdd post-execution validation that checks:\n1. If context has numeric values for relevant variables\n2. And output contains symbolic variables not grounded to context\n3. Then trigger decomposition\n\n## Example\nStep: 'Calculate vector BC'\nContext: {'B': [3, 0], 'C': [0, 5]}\nLLM Output: '(x - 3, y)'  ← Contains ungrounded 'x', 'y'\nExpected: '(-3, 5)'  ← Uses actual values\n\nThis step should be decomposed into:\n1. Extract B coordinates from context\n2. Extract C coordinates from context\n3. Compute difference: C - B","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T10:42:31.698046-08:00","updated_at":"2026-01-20T17:50:06.394819-08:00","closed_at":"2026-01-20T17:50:06.394819-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-e90b","title":"Feature: Validate LLM output type matches context","description":"We validate DSL outputs but not LLM outputs. When context has concrete numbers and the step asks for a computation, the output should BE numeric, not symbolic. Add validation that flags when LLM returns symbolic expressions (e.g., 'x + 2') when numeric values are available in context.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T10:45:22.398813-08:00","updated_at":"2026-01-12T11:07:59.895345-08:00","closed_at":"2026-01-12T11:07:59.895345-08:00"}
{"id":"mycelium-eal","title":"Silent failures in wave propagation","description":"step_signatures.py:1979-1997 - _propagate_wave() returns empty dict when get_signature_by_id() returns None. Callers (like record_usage at line 1856) don't know propagation failed. Add logging or raise explicit exceptions.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:40.206731-08:00","updated_at":"2026-01-08T11:26:34.39181-08:00","closed_at":"2026-01-08T11:26:34.39181-08:00"}
{"id":"mycelium-eccq","title":"Big 3: Move rejection thresholds to config.py (The Flow)","description":"Per CLAUDE.md 'The Flow': Thresholds come from config, not magic numbers.\n\n## Problem\nmcts.py lines 806-808 have hardcoded thresholds at module level:\n```python\nREJECTION_COUNT_THRESHOLD = 10\nREJECTION_RATE_THRESHOLD = 0.30\nREJECTION_SIM_THRESHOLD = 0.85\n```\n\n## Solution\nMove to config.py and make Welford-adaptive:\n- REJECTION_COUNT_THRESHOLD → config with cold-start ramping\n- REJECTION_RATE_THRESHOLD → Welford-guided based on historical rates\n- Remove REJECTION_SIM_THRESHOLD (already deprecated)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T14:16:28.251091-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T14:23:28.610605-08:00","closed_at":"2026-01-28T14:23:28.610605-08:00","close_reason":"Completed: Added cold-start adaptive rejection thresholds. REJECTION_COUNT_THRESHOLD now ramps from 3 (cold) to 10 (mature) based on signature count. Added get_rejection_count_threshold() function that interpolates based on system maturity. Updated get_leaf_rejection_stats() and get_leaves_needing_decomposition() to use adaptive threshold. Fixed broken exports in data_layer/__init__.py."}
{"id":"mycelium-edd","title":"Zero centroid not validated in compute_interference_score","description":"step_signatures.py:557-580 - compute_interference_score() checks for None centroid but not zero vector. Add validation: if np.allclose(signature.centroid, 0): return 0.0","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:48.491494-08:00","updated_at":"2026-01-08T12:22:19.592697-08:00","closed_at":"2026-01-08T12:22:19.592697-08:00"}
{"id":"mycelium-eg1","title":"Unsafe JSON response parsing in client.py","description":"Line 159: No validation that API response has expected structure - can cause KeyError/IndexError","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:25.210434-08:00","updated_at":"2026-01-09T11:22:06.131211-08:00","closed_at":"2026-01-09T11:22:06.131211-08:00"}
{"id":"mycelium-eghw","title":"Medium: Background tasks fire-and-forget with no error handling","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:49.442684-08:00","updated_at":"2026-01-13T11:54:42.975162-08:00","closed_at":"2026-01-13T11:54:42.975162-08:00"}
{"id":"mycelium-elr","title":"Bug: Depth tracking fragmented across routing strategies","description":"Three separate depth counters exist: _execute_step_recursive() uses 'depth', _route_to_child_signature() uses separate 'depth', _decompose_and_solve_step() uses 'decomposition_depth'. These are tracked independently, so total effective depth can exceed RECURSIVE_MAX_DEPTH=3. Fix: Unify into single depth counter passed through all strategies.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T06:42:09.23602-08:00","updated_at":"2026-01-12T06:48:16.083213-08:00","closed_at":"2026-01-12T06:48:16.083213-08:00"}
{"id":"mycelium-eog7","title":"P3: Move embedding_cache.py to use data_layer connection factory","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": All database connections should go through the data layer.\n\n`embedding_cache.py` creates its own SQLite connections instead of using `create_connection_manager()` from data_layer.\n\n## Current State (embedding_cache.py:71)\n\n```python\nclass EmbeddingCacheConnectionManager:\n    def _get_connection(self) -\u003e sqlite3.Connection:\n        if not hasattr(self._local, \"conn\") or self._local.conn is None:\n            self._local.conn = sqlite3.connect(\n                str(self._db_path), \n                check_same_thread=False, \n                timeout=30.0\n            )\n            # Manual PRAGMA configuration...\n```\n\n## Why This Is a Problem\n\n- Duplicate connection management logic\n- Different PRAGMA settings if not coordinated with data_layer\n- Violates consolidation principle\n- Harder to maintain consistent DB behavior\n\n## Solution\n\nUse `create_connection_manager()` from data_layer:\n\n```python\nfrom mycelium.data_layer import create_connection_manager\n\nclass EmbeddingCacheConnectionManager:\n    def __init__(self, db_path: Path):\n        self._db_path = db_path\n        self._conn_mgr = create_connection_manager(str(db_path))\n    \n    @contextmanager\n    def connection(self):\n        with self._conn_mgr.connection() as conn:\n            yield conn\n```\n\n## Implementation Steps\n\n1. Import `create_connection_manager` from data_layer\n2. Replace custom connection logic with data_layer factory\n3. Remove duplicate PRAGMA configuration\n4. Ensure embedding_cache.db gets same settings as main DB\n5. Test cache operations still work\n\n## Files to Modify\n\n- `src/mycelium/embedding_cache.py`\n\n## Testing\n\n- Verify embedding cache read/write works\n- Verify PRAGMA settings are consistent\n- Run full test suite\n\n## Context\n\nP3 priority per Big 3 audit - cleanup task.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:51:44.32241-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T14:18:07.456177-08:00","closed_at":"2026-01-28T14:18:07.456177-08:00","close_reason":"Refactored embedding_cache.py to use create_connection_manager from data_layer. Removed duplicate EmbeddingCacheConnectionManager class. Added enable_foreign_keys param to factory for flexibility."}
{"id":"mycelium-epua","title":"Critical: Database deadlock retry logic fragile (no jitter, string match)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:30.268609-08:00","updated_at":"2026-01-13T11:41:47.847195-08:00","closed_at":"2026-01-13T11:41:47.847195-08:00"}
{"id":"mycelium-ern","title":"Migrate db.py (MyceliumDB) to use data_layer","description":"Replace 2 direct sqlite3.connect calls in _init_unified_db and _get_connection with data_layer.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T09:00:31.051065-08:00","updated_at":"2026-01-09T09:02:34.458691-08:00","closed_at":"2026-01-09T09:02:34.458691-08:00"}
{"id":"mycelium-esii","title":"Bug: Database lock with multiple workers","description":"With num_workers=2, SQLite throws 'database is locked' error. Problem math_algebra_213 failed with this error. Need to either use single worker mode, WAL mode, or add better retry logic.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T07:08:05.034394-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:46:57.197484-08:00","closed_at":"2026-01-15T05:46:57.197484-08:00","close_reason":"Added timeout=30.0 and PRAGMA busy_timeout=30000 to all SQLite connections. Also enabled WAL mode in data_layer/connection.py and plans/db.py. Fixed connections in: solver.py, scoring.py (2 places), plans/db.py, data_layer/connection.py"}
{"id":"mycelium-eso9","title":"Perf: Signature hints does full table scan with JSON parsing","description":"get_signature_hints() fetches all children per level with full JSON parsing.\n\nLocation: db.py:1814-1922\n\nImpact: MEDIUM - 5-15ms per solve\n\nPlanner only needs step_type, description, param_names - not full JSON.\n\nFix: Use _row_to_signature_fast() or batch fetch with GROUP_CONCAT.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:02:50.289239-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.147251-08:00","closed_at":"2026-01-20T18:00:01.147251-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-f3ub","title":"MCTS Phase 1: Add confidence scoring to routing","description":"Part of mycelium-5vp4 (Adaptive compute budget)\n\nAdd confidence signals to routing without changing behavior:\n- Return confidence score from route_through_hierarchy()\n- Track UCB1 gap between top-2 children\n- Add routing_confidence field to result\n\nThis is foundation for multi-path exploration.\n\nFiles: db.py (route_through_hierarchy)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:01:27.147621-08:00","created_by":"Bryce Roche","updated_at":"2026-01-16T04:54:02.402345-08:00","closed_at":"2026-01-16T04:54:02.402345-08:00","close_reason":"Implemented RoutingResult with confidence scoring and route_with_confidence() method"}
{"id":"mycelium-f9g","title":"Split mcts.py into mcts/ package","description":"mcts.py is 1016 lines with 3 classes + prompts.\n\nSplit into mcts/ package:\n- core.py: MCTSNode, MCTS tree logic\n- decomposer.py: MCTSDecomposer\n- cache.py: LRUCache (could also move to shared/)\n- prompts.py: DIRECT_SOLVE prompt constant\n\nLower priority than step_signatures split.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:35:15.563709-08:00","updated_at":"2026-01-20T17:50:06.2583-08:00","closed_at":"2026-01-20T17:50:06.2583-08:00","close_reason":"Stale - older than Jan 15, deprioritizing","dependencies":[{"issue_id":"mycelium-f9g","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.512385-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-fb2","title":"Lift-gated injection with exploration bootstrapping","description":"## Summary\nAdded exploration rate to `should_inject()` to solve the cold-start problem for lift-gated injection.\n\n## Problem\nThe lift-gated injection system had a chicken-and-egg problem:\n- Signatures couldn't accumulate injection data because `should_inject()` required `min_samples_per_arm=3` in BOTH the injected AND non-injected arms\n- Since injections never happened, `injected_uses` stayed at 0, and the lift gate never triggered\n- Result: 0% injection rate, no lift data collected\n\n## Solution\nAdded `exploration_rate` parameter (default 0.3) to `StepSignature.should_inject()`:\n- During cold-start (insufficient data in both arms), randomly inject with probability `exploration_rate`\n- This allows the system to gather data on both arms to make informed lift decisions\n- Once enough data is collected (3+ samples per arm), the lift gate takes over\n\n## Results\nBefore fix:\n- Injection rate: 0%\n- No lift data collected\n\nAfter fix:\n- Training injection rate: 44.4%\n- Eval injection rate: 25%\n- **Overall lift: +45.7%** (injected: 100% success, non-injected: 54.3% success)\n- Wave propagation effectiveness: +21.2%\n\n## Files Changed\n- `src/mycelium/step_signatures.py`: Added `exploration_rate` parameter to `should_inject()`\n\n## Commit\n0a59088 feat: Add exploration rate to lift-gated injection for cold-start","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T13:22:10.794625-08:00","updated_at":"2026-01-08T13:22:15.881966-08:00","closed_at":"2026-01-08T13:22:15.881966-08:00"}
{"id":"mycelium-fg0r","title":"High: JSON result extraction too lenient (nested objects break regex)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:40.520813-08:00","updated_at":"2026-01-13T11:45:00.525515-08:00","closed_at":"2026-01-13T11:45:00.525515-08:00"}
{"id":"mycelium-fk30","title":"Move hardcoded thresholds to config.py","description":"Several hardcoded values should be moved to config.py for tunability:\n- semantic_validation.py line 138: similarity threshold 0.3\n- semantic_validation.py line 96: coherence threshold 0.5  \n- solver.py line 168: max_retries = 2\n\nThese affect validation behavior and should be configurable without code changes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:06:37.206925-08:00","updated_at":"2026-01-15T14:15:37.100796-08:00","closed_at":"2026-01-15T14:15:37.100796-08:00","close_reason":"Moved hardcoded thresholds to config.py: UMBRELLA_* (umbrella promotion), BIG_BANG_* (cold start), DSL_EXOTIC_* (exotic ops), DB_* (retry settings). Original issue was stale (referenced deleted files) but the spirit was correct. All 302 tests pass."}
{"id":"mycelium-fk98","title":"Perf: N+1 queries in centroid propagation","description":"propagate_centroid_to_parents() recursively queries DB for each level up the tree.\n\nLocation: db.py:153-243\n\nWith 10-level deep tree, generates 10+ queries per embedding update.\n\nOptions:\n1. Batch ancestor updates with CTE\n2. Limit propagation depth\n3. Async background propagation\n\nLatency impact: HIGH - called on every signature match","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:27:34.205556-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T13:36:46.810373-08:00","closed_at":"2026-01-15T13:36:46.810373-08:00","close_reason":"Refactored propagate_centroid_to_parents to use batch CTE approach: 2 queries (fetch ancestors + fetch children) + N updates instead of 3N queries. Bounded to CENTROID_PROPAGATION_MAX_DEPTH=3 levels."}
{"id":"mycelium-flbq","title":"Post-mortem: DSL regeneration on high failure rate","description":"When post-mortem detects high failure rate at a specific (dag_step_id, node_id) pair, trigger DSL regeneration. The DSL may be incorrectly parameterized or using wrong operations. Post-mortem has the evidence to know when rewriting is needed vs when the signature itself needs splitting.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:00.802615-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:50:21.351776-08:00","closed_at":"2026-01-21T08:50:21.351776-08:00","close_reason":"Already implemented. Full pipeline exists: accumulate_high_conf_wrong_nodes → should_trigger_dsl_regen → trigger_dsl_regeneration_for_nodes. Config: POSTMORTEM_DSL_REGEN_ENABLED, POSTMORTEM_DSL_REGEN_BATCH_SIZE."}
{"id":"mycelium-flui","title":"Brainstorm: Success-weighted routing \u0026 parent credit propagation","description":"## Ideas to explore\n\n### 1. Success-weighted routing\nCurrently `find_or_create` matches purely by cosine similarity. Should we blend in success rate?\n\n```python\n# Example formula with cold-start prior\nprior = 2\neffective_rate = (successes + prior) / (uses + prior * 2)\nscore = cosine_sim * (0.7 + 0.3 * effective_rate)\n```\n\n**Tradeoffs:**\n- Pro: Routes to proven patterns\n- Con: Cold start problem for new signatures\n- Con: Current success rate is problem-level, not step-level\n\n### 2. Parent credit propagation\nWhen a child signature succeeds, should we propagate success up the umbrella routing chain?\n\nExample: `probability_umbrella → counting_outcomes → result`\n- If problem correct, currently only `counting_outcomes` gets success credit\n- Should `probability_umbrella` also get credit for good routing?\n\nThis would reward umbrella signatures that route well, not just leaf executors.\n\n**Questions:**\n- Full credit to all ancestors, or decay (0.5^depth)?\n- Only for is_semantic_umbrella=True signatures?\n- Does this create perverse incentives?\n\n### Current state\n- `update_problem_outcome(signature_ids, correct)` updates leaf signatures\n- Success rate data collected but not used in routing\n- Centroid averaging improves matching based on usage, not success","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-13T04:36:32.331109-08:00","updated_at":"2026-01-13T04:39:58.986403-08:00","closed_at":"2026-01-13T04:39:58.986403-08:00"}
{"id":"mycelium-fnr2","title":"Bug: Unique constraint on centroid TEXT causes flaky sig creation (schema.py:65)","description":"schema.py:65 has UNIQUE INDEX on centroid column which stores JSON-serialized floats as TEXT. Floating point serialization is not numerically stable - two mathematically identical centroids can have different string representations. This causes 'UNIQUE constraint failed' errors on signature creation.\n\n## Implementation (COMPLETED)\n\n**Two-layer bounded uniqueness:**\n\n1. **DB Layer**: centroid_bucket (quantized hash, UNIQUE index)\n   - Normalizes embedding, rounds to 1 decimal, hashes first 64 dims\n   - Prevents gross duplicates at creation time\n\n2. **App Layer**: Adaptive drift monitoring\n   - threshold = MAX_DRIFT * DECAY^log2(count)\n   - count=1: 0.150 (loose), count=64: 0.080 (tight)\n   - Logs warning on excessive drift (monitoring only)\n\n**Files changed:**\n- schema.py: Added centroid_bucket column, UNIQUE index\n- utils.py: Added compute_centroid_bucket()\n- config.py: Added CENTROID_MAX_DRIFT=0.15, CENTROID_DRIFT_DECAY=0.9\n- db.py: Integrated bucket in create/update, added drift monitoring\n\n**Known edge case:** If centroid drifts into another signature's bucket, UPDATE may fail UNIQUE constraint. Rare in practice - could add try/except in future.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:31:06.381856-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:17:48.189189-08:00","closed_at":"2026-01-15T14:03:23.673759-08:00","close_reason":"Implemented two-layer bounded uniqueness: (1) DB-level coarse uniqueness via quantized centroid_bucket hash (UNIQUE index), (2) App-level adaptive drift monitoring with tighter bounds as embedding_count increases. Removes broken TEXT unique constraint."}
{"id":"mycelium-ft60","title":"Audit: Address test coverage gaps","description":"Meta-issue tracking test coverage improvements from Jan 14 audit.\n\nCurrent state: 124 tests passing\nGap: No tests for newer modules\n\nSub-tasks:\n- mycelium-p6qu: Test semantic_validation.py\n- mycelium-a6pe: Test umbrella_learner.py  \n- mycelium-topu: Test dsl_templates.py\n- mycelium-cwbb: Test refinement.py\n\nTarget: Increase coverage to include all core modules.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:20:18.204971-08:00","updated_at":"2026-01-14T06:37:12.597523-08:00","closed_at":"2026-01-14T06:37:12.597523-08:00","dependencies":[{"issue_id":"mycelium-ft60","depends_on_id":"mycelium-p6qu","type":"blocks","created_at":"2026-01-14T06:20:24.23061-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ft60","depends_on_id":"mycelium-a6pe","type":"blocks","created_at":"2026-01-14T06:20:24.27762-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ft60","depends_on_id":"mycelium-topu","type":"blocks","created_at":"2026-01-14T06:20:24.32413-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ft60","depends_on_id":"mycelium-cwbb","type":"blocks","created_at":"2026-01-14T06:20:24.369707-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-fx8","title":"Measure lift-gated injection effectiveness","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-08T12:24:09.269174-08:00","updated_at":"2026-01-08T12:31:00.475563-08:00","closed_at":"2026-01-08T12:31:00.475563-08:00"}
{"id":"mycelium-fxg8","title":"Extract computation graph from DSL after successful execution","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T07:03:37.99261-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:24:39.53312-08:00","closed_at":"2026-01-21T08:24:39.53312-08:00","close_reason":"Implemented graph_extractor.py with AST-based extraction and wired into signature creation","dependencies":[{"issue_id":"mycelium-fxg8","depends_on_id":"mycelium-k509","type":"blocks","created_at":"2026-01-21T07:03:48.907848-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-fyc1","title":"Audit: Is plans/ directory still used?","status":"closed","priority":4,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T11:05:59.642565-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T17:50:06.825847-08:00","closed_at":"2026-01-20T17:50:06.825847-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-fzxg","title":"Consolidate signature field updates","description":"## Problem\nScattered inline UPDATEs throughout src/mycelium/step_signatures/db.py instead of using dedicated update functions:\n\nDedicated functions exist:\n- `update_nl_interface()` (line ~3994) - Dynamic UPDATE with optional fields\n- `update_dsl_script()` (line ~4045) - Single field UPDATE\n- `update_graph_embedding()` (line ~5169) - Single field UPDATE + propagation\n\nBut inline UPDATEs also scattered:\n- Line ~3573 in `record_usage()` - updates last_used_at\n- Line ~3850 in `add_child()` - marks as umbrella\n- Line ~3633-3637 in `record_usage()` - auto-demotion logic\n- Various other places with direct SQL UPDATEs\n\n## Pattern to Follow\nSee `update_graph_embedding()` - it updates the field AND handles side effects (propagation, cache invalidation).\n\n## Proposed Solution\nCreate unified internal function:\n```python\ndef _update_signature_fields(\n    self,\n    conn,\n    signature_id: int,\n    **field_updates  # kwargs like dsl_script='...', is_semantic_umbrella=True\n) -\u003e bool:\n    '''Update signature fields atomically with proper cache invalidation.\n    \n    Handles:\n    - Field updates\n    - Cache invalidation based on which fields changed\n    - Logging\n    '''\n```\n\nReplace scattered inline UPDATEs with calls to this function.\n\n## Acceptance Criteria\n- [ ] Single internal function for signature field updates\n- [ ] Function determines which caches to invalidate based on fields changed\n- [ ] All inline UPDATEs migrated to use the helper\n- [ ] Existing dedicated functions (update_dsl_script, etc.) become wrappers\n- [ ] Audit trail/logging in one place","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:08:43.846772-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:43:43.841122-08:00","closed_at":"2026-01-25T08:43:43.841122-08:00","close_reason":"Consolidated ~13 inline UPDATEs to use _update_signature_fields helper. Remaining ~17 are complex cases (blobs, batches) that don't fit the pattern."}
{"id":"mycelium-g1hh","title":"Targeted MCTS re-runs for failure diagnosis","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-22T12:03:06.019271-08:00","created_by":"Bryce Roche","updated_at":"2026-01-22T12:47:29.052866-08:00","closed_at":"2026-01-22T12:47:29.052866-08:00","close_reason":"Implemented diagnostic exploration functions. During testing found root cause: planner prompt was ambiguous causing LLM to output variable names instead of numbers. Fixed in commit eafbf4e."}
{"id":"mycelium-g4mt","title":"Refactor: Split dsl_executor.py (2167 lines) into focused modules","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-13T14:55:23.996677-08:00","updated_at":"2026-01-14T06:44:22.254388-08:00","closed_at":"2026-01-14T06:44:22.254388-08:00","close_reason":"Split dsl_executor.py into 5 focused modules: dsl_types.py, dsl_validation.py, math_layer.py, sympy_layer.py, custom_layer.py. Main file is now a facade with re-exports for backward compatibility. All 268 tests pass."}
{"id":"mycelium-g9o","title":"Add error aggregation to asyncio.gather in council_v2.py","description":"Current asyncio.gather calls crash on first error. Add return_exceptions=True and aggregate errors for better debugging. Affects _execute_level() and parallel step execution.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:32.051607-08:00","updated_at":"2026-01-09T07:46:05.805266-08:00","closed_at":"2026-01-09T07:46:05.805266-08:00"}
{"id":"mycelium-g9rc","title":"Bug: Signature proliferation - 36 compute_sum signatures instead of consolidating","description":"**Finding:** DB has 36 signatures with step_type='compute_sum' and 14 with 'compute_product'. Most should be consolidated into one.\n\n**Evidence:**\n```\nsqlite3 mycelium.db 'SELECT step_type, COUNT(*) FROM step_signatures GROUP BY step_type ORDER BY COUNT(*) DESC LIMIT 10'\n```\n\n**Impact:**\n- Each signature gets attempted for decomposition before being marked atomic\n- Wastes LLM calls (36 attempts instead of 1)\n- Bloats the signature tree\n- Routing becomes less efficient\n\n**Root Cause (hypothesis):**\n- find_or_create() may not be consolidating similar signatures properly\n- Or signatures are being created with slightly different embeddings that don't match\n\n**Investigation needed:**\n1. Check find_or_create() similarity threshold\n2. Check if embeddings for same step_type are actually similar\n3. Consider merging signatures with same step_type and high centroid similarity\n\n**Related:** mycelium-ag3l fixed repeated decomposition per-signature, but proliferation is the upstream issue.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T14:04:24.543464-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T14:25:34.049994-08:00","closed_at":"2026-01-25T14:25:34.049994-08:00","close_reason":"Implemented compute_match_score() with graph_embedding + leaf stats. Results: 4 leaf signatures vs 75+ before (14 total with routers)."}
{"id":"mycelium-gelu","title":"Brainstorm: Embedding Limitation - Vocabulary vs Semantics","description":"## Status: Uncertain / Observation\n\n## The Problem\nThe embedding model clusters tasks based on vocabulary similarity rather than operational semantics.\n\n### Core Insight\nEmbeddings are fundamentally a measure of what words appear together, not what mathematical operation is intended.\n\n**Example:** \"multiply both sides of the equation\" and \"multiply two numbers\" appear similar to the model (shared vocabulary: \"multiply\"), but represent very different operations:\n- First: algebraic manipulation (transform equation)\n- Second: arithmetic computation (calculate product)\n\n### Implications\n- No single similarity threshold can perfectly separate all operational categories\n- Current mitigations (algebraic anchor blocking at 0.34 threshold) are heuristics, not solutions\n- False positives (blocking valid arithmetic) vs false negatives (allowing algebraic manipulation into arithmetic DSL) trade-off\n\n### Possible Directions\n1. **Fine-tune embeddings** on (task, operation_type) pairs - expensive, needs labeled data\n2. **Multi-stage classification** - embedding for candidate retrieval, then LLM for semantic verification\n3. **Negative example mining** - learn what NOT to match (current approach in dsl_negative_examples.py)\n4. **Operational signatures** - embed the DSL script structure, not just task text\n5. **Accept the limitation** - rely on DSL execution failure + LLM fallback as the correction mechanism\n\n### Current Mitigations\n- `_ALGEBRAIC_ANCHOR_TEXT` blocking in dsl_executor.py\n- `is_algebraic_manipulation()` check before arithmetic DSL\n- Negative param cache for failed mappings\n\n## Open Questions\n- Is this a fundamental limit or a model choice issue (MathBERT vs other models)?\n- How much accuracy is lost to vocabulary confusion?\n- Would operation-aware embeddings be worth the complexity?","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-13T07:04:50.821656-08:00","updated_at":"2026-01-20T17:50:06.71175-08:00","closed_at":"2026-01-20T17:50:06.71175-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-gp9n","title":"Consolidation: Extract graph embedding pattern to helper method","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": \"We want to consolidate methods.\"\n\nThe pattern `_dsl_hint_to_graph()` + `embed_computation_graph_sync()` is duplicated 7+ times in db.py with inline implementations.\n\n## Current Behavior\n\nSame pattern repeated at:\n- db.py:1441-1445 (create_signature)\n- db.py:1566-1572 (propose_signature - multi-part check)\n- db.py:1621 (propose_signature - known op check)\n- db.py:1688-1695 (propose_signature - atomic check)\n- db.py:1708-1715 (propose_signature - final check)\n- db.py:1905-1911 (route method)\n- db.py:2265-2275 (_create_signature_atomic)\n- db.py:8557-8559 (batch operations)\n\n```python\n# Repeated pattern (with variations):\nif dsl_hint:\n    graph = _dsl_hint_to_graph(dsl_hint)\n    if graph:\n        graph_embedding = embed_computation_graph_sync(graph, embedder)\n```\n\n## Expected Behavior\n\nSingle helper method:\n\n```python\ndef _compute_graph_embedding_from_dsl_hint(\n    self,\n    dsl_hint: Optional[str],\n    embedder: Optional[Embedder] = None,\n) -\u003e Optional[np.ndarray]:\n    \"\"\"Convert DSL hint to graph embedding.\n    \n    Per CLAUDE.md \"New Favorite Pattern\": Consolidates repeated pattern.\n    \n    Args:\n        dsl_hint: DSL expression like \"MUL(param_0, param_1)\"\n        embedder: Embedder instance (uses default if None)\n    \n    Returns:\n        Graph embedding array, or None if conversion fails\n    \"\"\"\n    if not dsl_hint:\n        return None\n    \n    graph = _dsl_hint_to_graph(dsl_hint)\n    if not graph:\n        return None\n    \n    return embed_computation_graph_sync(graph, embedder or self._get_default_embedder())\n```\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/db.py` - Add helper method, replace 7+ inline usages\n\n## Implementation Notes\n\n1. Some call sites have additional logic (e.g., fallback to text embedding)\n2. Keep helper focused on core pattern\n3. Call sites can add their own fallback logic after calling helper\n\n## Testing\n\n1. Add helper method\n2. Replace one usage at a time\n3. Run tests after each replacement\n4. Verify no behavior changes\n\n## Context\n\nPart of Consolidation code review. Medium priority.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:38:51.548966-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:19:30.712978-08:00","closed_at":"2026-01-28T12:19:30.712978-08:00","close_reason":"Added _get_graph_embedding_from_hint() helper. Updated 4 call sites in db.py (lines 1403, 1531, 1641, 1838) to use the consolidated helper per New Favorite Pattern."}
{"id":"mycelium-h0ne","title":"Post-mortem credit propagation from mcts_thread_steps","description":"Post-mortem analysis of MCTS rollouts after grading.\n\nStep 1: Compute amplitude_post for each thread_step\n- Thread won + high confidence → boost (reinforce good routing)\n- Thread won + low confidence → bigger boost (discovered something)\n- Thread lost + low confidence → mild penalty (expected uncertainty)\n- Thread lost + high confidence → strong penalty (confident and wrong)\n\nStep 2: Analyze (dag_step_id, node_id) combinations\n- Identify nodes that consistently win/lose at specific steps\n- Flag high-variance nodes for potential decomposition\n\nStep 3: Update system\n- Adjust node statistics based on amplitude_post\n- Consider centroid updates for consistently wrong nodes\n- Feed insights back into routing decisions\n\nMerged from mycelium-m76g (wave function collapse).","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:26.246185-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T16:50:06.291061-08:00","closed_at":"2026-01-20T16:50:06.291061-08:00","close_reason":"Implemented run_postmortem() which computes amplitude_post for all thread_steps after grading. Formula penalizes high-confidence wrong decisions (0.5x) and boosts low-confidence discoveries (1.4x). Auto-runs after grade_dag() in solver.","dependencies":[{"issue_id":"mycelium-h0ne","depends_on_id":"mycelium-m76g","type":"blocks","created_at":"2026-01-20T14:07:37.247193-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-h25","title":"Implement signature decay (decoherence)","description":"Old signatures that haven't been used should decay in confidence. This prevents stale patterns from being injected.\n\nFrom wave function analysis: 'Decoherence' - interaction with environment causes loss of quantum coherence over time.\n\nImplementation:\n1. Add decay_unused_signatures() method\n2. Use exponential decay based on time since last_used_at\n3. Consider using EMA for centroid updates (alpha=0.1)\n4. Run decay as background task or on each solve","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:34:09.319935-08:00","updated_at":"2026-01-08T12:10:18.069861-08:00","closed_at":"2026-01-08T12:10:18.069861-08:00"}
{"id":"mycelium-h4wy","title":"Cleanup: Remove vestigial db_path parameters in scoring.py","description":"## Problem\n\nscoring.py has `db_path: str = DB_PATH` parameters that are documented as \"kept for API compatibility but ignored (uses StateManager)\".\n\n```python\ndef get_total_problems_solved(db_path: str = DB_PATH) -\u003e int:\n    '''Note: db_path param kept for API compatibility but ignored (uses StateManager).'''\n    ...\n\ndef increment_total_problems(db_path: str = DB_PATH) -\u003e int:\n    '''Note: db_path param kept for API compatibility but ignored (uses StateManager).'''\n    ...\n```\n\nThis is dead code that adds confusion.\n\n## Solution\n\n1. Search for callers passing explicit db_path to these functions\n2. If none found, remove the parameters entirely\n3. If found, migrate callers to not pass db_path\n\n## Files to Modify\n\n- src/mycelium/step_signatures/scoring.py\n- Any callers (need to search)","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:39:49.356165-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:43:12.059501-08:00","closed_at":"2026-01-28T12:43:12.059501-08:00","close_reason":"Removed vestigial db_path parameters - functions now use StateManager singleton directly"}
{"id":"mycelium-h78c","title":"Post-mortem: Exploration rate tuning based on overall performance","description":"Post-mortem can assess overall system performance and adjust branching aggressiveness. Low accuracy → branch more (explore). High accuracy → branch less (exploit). This is meta-learning: the system learns how much to explore based on its own performance trajectory.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:03.124076-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:51:24.749858-08:00","closed_at":"2026-01-21T08:51:24.749858-08:00","close_reason":"Duplicate of mycelium-nirq. UCB1 adjustment IS exploration rate tuning - adjusts exploration constant C based on post-mortem hit/miss patterns. Already implemented in AdaptiveExploration._update_ucb1_adjustment()."}
{"id":"mycelium-h8m","title":"Bug: Orphan child signature references not validated","description":"In solver.py:1576-1580, if a child signature ID in child_signatures JSON doesn't exist in DB, routing silently fails with no audit trail. No validation on umbrella creation that all child IDs are valid. Fix: Validate child IDs exist when marking umbrella, track orphaned references for debugging.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T06:42:12.193806-08:00","updated_at":"2026-01-12T06:47:05.440729-08:00","closed_at":"2026-01-12T06:47:05.440729-08:00"}
{"id":"mycelium-hch0","title":"Fix test_centroid_averaging tests for graph-only routing","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:48:15.776589-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:50:46.824572-08:00","closed_at":"2026-01-25T08:50:46.824572-08:00","close_reason":"Tests updated for graph-based routing architecture"}
{"id":"mycelium-heh3","title":"Feature: Auto-restructure process (runs every N problems)","description":"## Summary\nImplement automatic restructuring process that runs every N problems, using Welford stats to reorganize the tree structure.\n\n## Config\n```python\n# config.py\nRESTRUCTURE_INTERVAL = 10  # run restructure every N problems\n```\n\n## Restructure Operations\n1. **Cluster Detection**: Find siblings with high mutual similarity (Welford child_mean)\n2. **Umbrella Creation**: Group similar siblings under new umbrella\n3. **Umbrella Demotion**: Demote umbrellas with low child variance (over-split)\n4. **Orphan Cleanup**: Remove umbrellas with no children\n5. **Merge Duplicates**: Merge signatures with very high similarity\n\n## Triggering\n```python\nasync def maybe_restructure(self, problem_count: int):\n    if problem_count \u003c COLD_START_THRESHOLD:\n        return  # no restructuring during cold start\n    if problem_count % RESTRUCTURE_INTERVAL != 0:\n        return\n    await self._run_restructure_pass()\n```\n\n## Restructure Algorithm\n```python\nasync def _run_restructure_pass(self):\n    # 1. Get all leaf nodes with Welford stats\n    leaves = self.get_leaf_nodes_with_stats()\n    \n    # 2. Compute pairwise similarities\n    sim_matrix = compute_similarity_matrix(leaves)\n    \n    # 3. Cluster detection (agglomerative, Welford-guided threshold)\n    clusters = detect_clusters(sim_matrix, threshold=2*avg_std)\n    \n    # 4. For each cluster with \u003e1 member: create umbrella\n    for cluster in clusters:\n        if len(cluster) \u003e 1:\n            self._create_umbrella_for_cluster(cluster)\n    \n    # 5. Cleanup orphan umbrellas\n    self._cleanup_orphan_umbrellas()\n```\n\n## Integration\n- Call `maybe_restructure()` at end of `solve_problem()` in solver.py\n- Log all restructure operations for debugging\n- Per CLAUDE.md \"System Independence\": fully automated, no manual intervention","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-27T06:38:01.837437-08:00","created_by":"Bryce Roche","updated_at":"2026-01-27T08:17:39.935239-08:00","closed_at":"2026-01-27T08:17:39.935239-08:00","close_reason":"Implemented in commit 06583d2: auto-restructure every N problems with Welford-guided clustering","dependencies":[{"issue_id":"mycelium-heh3","depends_on_id":"mycelium-5cn0","type":"blocks","created_at":"2026-01-27T06:38:08.842105-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-hhfy","title":"Audit: Confirm every problem routes through single root (no level skipping)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:01:00.422311-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:06:38.336471-08:00","closed_at":"2026-01-15T09:06:38.336471-08:00","close_reason":"Audit complete: Confirmed every problem routes through single root with no level skipping.\n\n## Findings\n\n### 1. Single Root Entry Point: CONFIRMED\n- db.py:119-134: get_root() queries for is_root=1\n- db.py:447-462: First signature becomes root (is_root=1, is_semantic_umbrella=1)\n- db.py:554-561: _route_hierarchical() always starts from root\n\n### 2. No Level Skipping: CONFIRMED\n- db.py:531-656: _route_hierarchical() traverses level-by-level via UCB1 selection\n- Each iteration: get children → pick best → move to child (depth += 1)\n- UMBRELLA_MAX_DEPTH=10 hard limit in config.py\n\n### 3. No Bypass Paths: CONFIRMED\n- solver.py:455: Only routing entry is find_or_create() which goes through hierarchy\n- find_similar() is NOT used for routing (only DSL inference)\n- All other get_signature() calls are for already-routed signatures\n\nImplementation correctly follows CLAUDE.md guidelines."}
{"id":"mycelium-hhyl","title":"Perf: Skip DAG validation for single-step plans","description":"Every plan validates entire DAG via plan.validate() even for single steps.\n\nLocation: solver.py:462-475\n\nImpact: LOW - \u003c1ms but unnecessary work\n\nSingle-step plans cannot have cycles.\n\nFix: Skip validation when len(plan.steps) == 1","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:03:02.68711-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.311909-08:00","closed_at":"2026-01-20T18:00:01.311909-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-hl01","title":"MCTS Phase 2: Add budget parameter to solver","description":"Part of mycelium-5vp4 (Adaptive compute budget)\n\nAdd compute_budget parameter to Solver.solve():\n- Default 1.0 (backward compatible, single-pass)\n- Pass through to internal methods\n- No behavior change yet, just plumbing\n\nFiles: solver.py, config.py (COMPUTE_BUDGET_DEFAULT)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:01:33.390182-08:00","created_by":"Bryce Roche","updated_at":"2026-01-16T04:56:58.672399-08:00","closed_at":"2026-01-16T04:56:58.672399-08:00","close_reason":"Added compute_budget parameter to solve(), _execute_step(), _execute_composite_step() with full plumbing","dependencies":[{"issue_id":"mycelium-hl01","depends_on_id":"mycelium-f3ub","type":"blocks","created_at":"2026-01-15T20:01:58.319204-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-hn50","title":"Bug: No null check on dsl_script before JSON decode in db.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:55.229761-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:21:34.682924-08:00","closed_at":"2026-01-15T05:21:34.682924-08:00","close_reason":"Added null check on dsl_script before json.loads in dsl_templates.py:625-629. Also added TypeError to except clause."}
{"id":"mycelium-i2a9","title":"Bug: Orphan umbrella in create_umbrella_above_signature","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T20:09:07.802294-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T20:09:12.406748-08:00","closed_at":"2026-01-26T20:09:12.406748-08:00","close_reason":"Fixed in 48c7bb8 - Create as leaf first, promote after child added"}
{"id":"mycelium-i3l4","title":"Refactor: Replace inline cosine similarity with utils.cosine_similarity()","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T14:55:30.397669-08:00","updated_at":"2026-01-20T17:50:06.508101-08:00","closed_at":"2026-01-20T17:50:06.508101-08:00","close_reason":"Stale - older than Jan 15, deprioritizing","dependencies":[{"issue_id":"mycelium-i3l4","depends_on_id":"mycelium-g4mt","type":"blocks","created_at":"2026-01-13T14:55:53.986321-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-i601","title":"Feature: Adaptive leaf node rejection during MCTS exploration","description":"## Problem\n\nCurrently leaf nodes accept any dag_step routed to them, regardless of similarity confidence. This leads to:\n1. Wasted LLM calls on executions likely to fail\n2. Delayed learning (only learn after execution failure)\n3. Post-mortem has to clean up bad matches reactively\n\n## Proposed Solution: Adaptive Rejection Threshold\n\nLeaf nodes should reject dag_steps when similarity is below their **historical success distribution**.\n\n### The Mechanism\n\nEach leaf tracks the similarity scores of dag_steps it has successfully executed:\n\n```python\n# On successful execution, record the similarity score\nleaf.success_similarities = [0.85, 0.82, 0.91, 0.78, ...]\n\n# Compute acceptance threshold (e.g., mean - 1.5*std)\nthreshold = mean(success_similarities) - 1.5 * std(success_similarities)\n```\n\nWhen a new dag_step routes to this leaf:\n- If `similarity \u003e= threshold` → accept, attempt execution\n- If `similarity \u003c threshold` → reject, signal \"decompose this step\"\n\n### Why Adaptive?\n\nStatic thresholds don't account for leaf specialization:\n- A highly specialized leaf (narrow cluster) might have success_similarities of [0.92, 0.95, 0.91]\n- A broader leaf might have [0.75, 0.82, 0.71, 0.78]\n\nThe adaptive threshold respects each leaf's learned domain.\n\n### Cold Start Handling\n\nNew leaves (few successes) should be permissive:\n- `if len(success_similarities) \u003c MIN_SAMPLES: accept_all = True`\n- Mirrors the \"big bang\" cold start philosophy\n\n### Integration with MCTS\n\nDuring MCTS exploration (spawning threads on failed problems):\n1. Route dag_step to candidate leaf\n2. Leaf checks similarity against its success distribution\n3. If rejected → that thread triggers decomposition path\n4. If accepted → attempt execution, record outcome\n\nRejection becomes another signal for the post-mortem analysis.\n\n### Data to Track\n\nNew columns on `step_signatures` or separate table:\n- `success_similarity_sum` (running sum for mean calculation)\n- `success_similarity_sq_sum` (running sum of squares for std calculation)\n- `success_count` (already exists)\n\nOr store recent N similarities in a JSON array for windowed statistics.\n\n## Connections to CLAUDE.md\n\n- \"Failures are valuable data points\" → rejections are soft failures that provide signal\n- \"Post-mortem is the crown jewel\" → rejection events feed into post-mortem\n- \"Let signatures fail\" → but catch obvious mismatches early\n- \"Selective branching on uncertainty\" → rejection is a form of uncertainty signal","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T12:36:18.265562-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T12:47:33.858232-08:00","closed_at":"2026-01-25T12:47:33.858232-08:00","close_reason":"Implemented adaptive leaf node rejection. Each leaf now computes its own acceptance threshold based on historical success similarities using Welford's algorithm: threshold = mean - k*std. Cold-start leaves use default threshold. Post-mortem propagates similarity scores from winning threads."}
{"id":"mycelium-i74m","title":"Bug: Cold start failure - no LLM fallback causes cascading failures","description":"Fresh DB leads to 0% accuracy because: 1) New signatures get 'decompose' DSL type 2) 'decompose' returns None,False in dsl_executor 3) Solver has no LLM fallback (line 417) 4) Step fails -\u003e DAG aborts. Need to add LLM fallback for cold start or improve DSL inference.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T07:08:10.978157-08:00","created_by":"Bryce Roche","updated_at":"2026-01-14T08:12:36.079257-08:00","closed_at":"2026-01-14T08:12:36.079257-08:00","close_reason":"Not a bug - this is intentional design. High threshold (0.6) rejects bad matches → decompose → fail cleanly. System learns from failures. See updated CLAUDE.md section on Signature-Guided Learning."}
{"id":"mycelium-ib7","title":"Extract shared/similarity.py - deduplicate cosine functions","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:53:54.825428-08:00","updated_at":"2026-01-09T06:05:02.586792-08:00","closed_at":"2026-01-09T06:05:02.586792-08:00"}
{"id":"mycelium-icv4","title":"Create function_registry.py with curated Python math functions","description":"## Goal\nCreate a new file `src/mycelium/function_registry.py` containing curated Python function pointers organized by tier.\n\n## Tiers\n1. **Arithmetic**: operator.add, sub, mul, truediv, floordiv, mod, pow, neg, abs + math.sqrt, cbrt, floor, ceil\n2. **Comparison**: operator.eq, ne, lt, le, gt, ge + builtins max, min\n3. **Trigonometry**: math.sin, cos, tan, asin, acos, atan, atan2, degrees, radians, hypot\n4. **Logarithms/Exponentials**: math.log, log10, log2, exp, exp2\n5. **Number Theory**: math.gcd, lcm, factorial, comb, perm, isqrt\n6. **Statistics**: statistics.mean, median, mode, stdev, variance, fsum\n7. **Symbolic**: sympy.solve, simplify, expand, factor, diff, integrate, limit\n\n## Schema\n```python\nFUNCTION_REGISTRY = {\n    \"add\": {\"func\": operator.add, \"arity\": 2, \"tier\": 1, \"module\": \"operator\"},\n    \"sqrt\": {\"func\": math.sqrt, \"arity\": 1, \"tier\": 1, \"module\": \"math\"},\n    ...\n}\n\ndef get_function(name: str) -\u003e Callable\ndef list_functions(tier: int = None) -\u003e List[str]\ndef call_function(name: str, *args) -\u003e Any\n```\n\n## Acceptance Criteria\n- [ ] All tiers implemented\n- [ ] Each function has: func pointer, arity, tier, module source\n- [ ] Helper functions for lookup and execution\n- [ ] Unit tests for each tier","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:53:18.608912-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T05:57:24.216116-08:00","closed_at":"2026-01-31T05:57:24.216116-08:00","close_reason":"Created function_registry.py with 57 functions across 7 tiers. All tests passing."}
{"id":"mycelium-ieq4","title":"Feature: Welford-guided embedding drift for leaf nodes and router centroids","description":"## Summary\n\nAllow leaf node graph embeddings to drift toward successful dag_step embeddings over time, making nodes \"semantic attractors\" that stabilize around operational meaning rather than initial vocabulary-based embeddings.\n\n## Motivation\n\nPer CLAUDE.md: \"High-traffic signatures become semantic attractors: their centroids stabilize around operational meaning rather than vocabulary.\"\n\nCurrently, node embeddings are fixed at creation time. This feature lets them adapt based on successful matches, self-correcting toward what they're actually good at.\n\n## Design Decisions (Finalized)\n\n### 1. Learning Rate: Welford-Adaptive\nHigh variance nodes drift faster (still exploring), low variance nodes stay stable (converged):\n\n```python\n# Welford-adaptive α: high variance = lower α = faster drift\nvariance = node.embedding_variance  # from Welford stats\nα = 1 - (k / (k + variance))  # k is tunable sensitivity\n# High variance → α closer to 0 → more weight on new embedding\n# Low variance → α closer to 1 → sticky to current embedding\n```\n\n### 2. No Bounding Drift\nLet nodes drift freely. Trust Welford variance to signal if something goes wrong. No artificial constraints.\n\n### 3. Batch Updates with NumPy Vectorization\nTrigger every ~50 problems during periodic tree review:\n\n```python\n# Vectorized batch update (pseudocode)\nleaf_embeddings = np.array([...])  # shape: (N, embedding_dim)\nsuccess_embeddings = np.array([...])  # accumulated since last update\nalphas = compute_welford_alphas(leaf_ids)  # shape: (N,)\n\n# Single vectorized operation\nnew_embeddings = alphas[:, None] * leaf_embeddings + (1 - alphas[:, None]) * success_embeddings\n```\n\n### 4. Router Centroids = Average of Children Graph Embeddings\nSimple and consistent:\n\n```python\nrouter.graph_embedding = np.mean([child.graph_embedding for child in children], axis=0)\n```\n\nRecompute after leaf updates propagate.\n\n## Implementation Steps\n\n1. Add config constants:\n   - `EMBEDDING_DRIFT_ENABLED = True`\n   - `EMBEDDING_DRIFT_INTERVAL = 50`  # problems between drift updates\n   - `EMBEDDING_DRIFT_VARIANCE_K = 1.0`  # Welford α sensitivity\n\n2. Add accumulator table for pending drift data:\n   - `pending_embedding_drifts(leaf_id, success_embedding_sum, success_count)`\n   - Accumulate during normal operation, flush during batch update\n\n3. Implement vectorized drift update in tree review:\n   - Fetch all pending drifts\n   - Compute Welford-adaptive alphas\n   - NumPy batch update\n   - Update router centroids bottom-up\n   - Clear accumulators\n\n4. Hook into periodic tree review cycle (every N problems)\n\n## Success Metrics\n\n- Routing accuracy improves over time\n- Embedding variance decreases for mature nodes (stabilization)\n- No latency regression (batch-only updates)\n- Nodes naturally cluster around operational semantics\n\n## Related\n\n- Ties into existing Welford stats infrastructure\n- Similar to credit propagation but for embeddings  \n- Supports \"System Independence\" - tree self-adjusts","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T13:01:38.797878-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:15:14.861675-08:00","closed_at":"2026-01-28T13:15:14.861675-08:00","close_reason":"Implemented Welford-guided embedding drift: leaf nodes drift toward successful dag_step embeddings with adaptive learning rate (high variance = faster drift). Batch updates every ~50 problems during tree review using NumPy vectorization. Router centroids recomputed as mean of children. 369 tests pass."}
{"id":"mycelium-ieq8","title":"Feature: Adaptive MCTS exploration weight tied to training accuracy","description":"## Problem\nFixed exploration constant doesn't adapt to learning progress. Early training needs aggressive exploration, mature system needs exploitation.\n\n## Solution\nTie UCB1 exploration weight (C) and cluster split threshold to global accuracy:\n\n### Adaptive Exploration Weight\n- accuracy=0% → C=2.0 (maximum exploration)\n- accuracy=50% → C=1.25\n- accuracy=90% → C=0.5 (mostly exploit)\n\n### Adaptive Split Threshold  \n- accuracy=0% → threshold=0.7 (tolerate 70% failure before split)\n- accuracy=50% → threshold=0.55\n- accuracy=90% → threshold=0.4 (split at 40% failure)\n\n## Implementation\nNew module: src/mycelium/mcts/adaptive.py\n- AdaptiveExploration class with rolling window accuracy tracking\n- get_adaptive_exploration_weight(global_accuracy)\n- get_adaptive_split_threshold(global_accuracy)\n- Integration with scoring.py and umbrella_learner.py\n\nAligns with CLAUDE.md: 'cold-start aware thresholds (adaptive branching more aggressive during cold start)'","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-16T04:42:07.140208-08:00","created_by":"Bryce Roche","updated_at":"2026-01-16T04:45:55.800352-08:00","closed_at":"2026-01-16T04:45:55.800352-08:00","close_reason":"Implemented adaptive MCTS exploration: UCB1 C parameter and split threshold now adapt to rolling accuracy"}
{"id":"mycelium-if16","title":"Perf: Cache child embeddings in routing","description":"In _route_to_child_signature (solver.py:1583-1593), child condition embeddings are computed on every routing call. Consider caching these embeddings since child_signatures JSON is relatively static. Profile first to confirm this is a bottleneck before optimizing.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-12T10:44:03.811357-08:00","updated_at":"2026-01-12T10:55:45.978503-08:00","closed_at":"2026-01-12T10:55:45.978503-08:00"}
{"id":"mycelium-ih6z","title":"New Favorite Pattern: Route all signature creation through propose_signature()","description":"Direct _create_signature_atomic() calls at db.py:884,1507,5684 bypass propose_signature() which is supposed to be SINGLE ENTRY POINT for signature creation. All creation should route through propose_signature() for Welford-based placement.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:00:43.499817-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:10:38.467612-08:00","closed_at":"2026-01-28T12:10:38.467612-08:00","close_reason":"Not a violation - the direct _create_signature_atomic() calls are for special cases where placement is predetermined: (1) root creation (no tree yet), (2) dynamic branch at specific depth, (3) umbrella promotion above existing sig. User-facing signature creation already goes through propose_signature(). These internal tree operations don't need Welford-based placement."}
{"id":"mycelium-iiw","title":"Add pluggable wave normalization to pipeline_runner","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:29:58.220623-08:00","updated_at":"2026-01-08T13:03:38.661395-08:00","closed_at":"2026-01-08T13:03:38.661395-08:00"}
{"id":"mycelium-ik9n","title":"Big 3: Consolidate umbrella promotion/demotion pathways","description":"Per CLAUDE.md 'New Favorite Pattern': Multiple promotion/demotion functions without unified entry point.\n\n**Functions**:\n- demote_umbrella_to_leaf() (line 3618)\n- promote_to_umbrella() (line 5779)\n- _promote_to_umbrella_internal() (line 5719)\n- create_upward_umbrella() (line 5877)\n- demote_orphan_umbrellas() (line 5999)\n\n**Fix**: Create unified `modify_signature_type(sig_id, action: UmbrellaAction)` that all call paths route through, similar to `_route_core()` pattern.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:28.344984-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T05:59:46.893886-08:00","closed_at":"2026-01-29T05:59:46.893886-08:00","close_reason":"Completed: All umbrella demotion now routes through demote_umbrella_to_leaf(). Added dsl_type parameter to support 'decompose' (default) vs 'math' (for orphans). Updated demote_orphan_umbrellas(), _demote_if_orphan(), and remove_child() to use consolidated pathway. Promotion was already consolidated via _promote_to_umbrella_internal()."}
{"id":"mycelium-imh6","title":"Bug: Leaf nodes without DSL should not exist","description":"Leaf nodes (is_semantic_umbrella=0) should always have a DSL script.\n\nA leaf without DSL can't execute anything - it would fall back to LLM, which violates the \"no LLM fallback\" principle from CLAUDE.md.\n\n**To investigate:**\n- Query: `SELECT COUNT(*) FROM step_signatures WHERE is_semantic_umbrella=0 AND (dsl_script IS NULL OR dsl_script = '')`\n- If any exist, either:\n  1. Generate DSL for them\n  2. Convert them to routers\n  3. Archive them\n\n**Root cause:** Likely signatures created before DSL generation was mandatory.\n\n**Fix:** Enforce DSL requirement on leaf creation, backfill existing.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T10:23:25.63768-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T10:46:43.111553-08:00","closed_at":"2026-01-23T10:46:43.111553-08:00","close_reason":"Issue resolved by design: infer_dsl_for_signature() always returns either 'math' or 'decompose' DSL, making leaves without DSL impossible. DB verification confirms 0 leaves without DSL."}
{"id":"mycelium-imve","title":"Medium: Dual meaning of success field (step result vs problem correctness)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:34:47.908485-08:00","updated_at":"2026-01-13T11:51:45.907543-08:00","closed_at":"2026-01-13T11:51:45.907543-08:00"}
{"id":"mycelium-itkn","title":"Per-step credit propagation from amplitude_post to signature stats","description":"Currently amplitude_post is computed but never used to update signature stats.\n\nGap: We compute fine-grained credit/blame (amplitude_post) but signature.successes/operational_failures don't reflect it.\n\nImplementation:\n1. After run_postmortem() computes amplitude_post for each step\n2. Group by node_id\n3. For each node: aggregate the amplitude_post signals\n4. Update signature stats:\n   - High amplitude_post average → increment successes\n   - Low amplitude_post average → increment operational_failures\n\nThis closes the loop: post-mortem analysis → signature learning","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T06:24:59.906916-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T06:34:45.083968-08:00","closed_at":"2026-01-21T06:34:45.083968-08:00","close_reason":"Implemented propagate_amplitude_to_signature_stats() - groups by node_id, updates signature successes/failures based on avg amplitude_post thresholds"}
{"id":"mycelium-ivm","title":"Extract clustering/ module for DBSCAN utilities","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:06.058589-08:00","updated_at":"2026-01-09T06:25:42.352808-08:00","closed_at":"2026-01-09T06:25:42.352808-08:00","dependencies":[{"issue_id":"mycelium-ivm","depends_on_id":"mycelium-ib7","type":"blocks","created_at":"2026-01-09T05:54:45.553178-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-ixfb","title":"Arch: Replace text embeddings with computation graph embeddings","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T07:03:35.371569-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:59:27.088313-08:00","closed_at":"2026-01-21T08:59:27.088313-08:00","close_reason":"Architecture complete: computation_graph extracted on signature creation, graph_embedding stored, route_by_graph_embedding in db.py, wired into solver.py routing with boost factor."}
{"id":"mycelium-ixjm","title":"Infra: Add unit tests for critical paths (56 LOC tests for 11k LOC codebase)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T11:34:57.478243-08:00","updated_at":"2026-01-13T12:05:09.553118-08:00","closed_at":"2026-01-13T12:05:09.553118-08:00"}
{"id":"mycelium-iz2","title":"Add parallel worker support to pipeline_runner.py","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T14:03:21.789848-08:00","updated_at":"2026-01-08T14:08:26.917274-08:00","closed_at":"2026-01-08T14:08:26.917274-08:00"}
{"id":"mycelium-j3x","title":"SQL injection vulnerability in connection.py","description":"Line 238: DB_SCHEMA env var directly interpolated into SQL without validation","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T11:20:15.93194-08:00","updated_at":"2026-01-09T11:21:45.875075-08:00","closed_at":"2026-01-09T11:21:45.875075-08:00"}
{"id":"mycelium-j563","title":"Bug: Division by zero in scoring.py if priors set to 0","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:24.863685-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:06:43.098096-08:00","closed_at":"2026-01-15T05:06:43.098096-08:00","close_reason":"Fixed division by zero in scoring.py: Added guards for ROUTING_PRIOR_USES=0 in compute_routing_score and compute_ucb1_score (default to 0.5 effective_rate), and TRAFFIC_MIN_SHARE=0 in compute_traffic_penalty (return 0 penalty)"}
{"id":"mycelium-j6gy","title":"Critical: Silent step failures return empty string instead of aborting","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:28.229064-08:00","updated_at":"2026-01-13T11:37:10.694093-08:00","closed_at":"2026-01-13T11:37:10.694093-08:00"}
{"id":"mycelium-j9cq","title":"Update routing to compare operation embedding vs graph embedding","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T07:03:40.414791-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:59:26.974163-08:00","closed_at":"2026-01-21T08:59:26.974163-08:00","close_reason":"Verified wiring is complete: operation extraction → embedding → route_by_graph_embedding → boost application in solver.py lines 1848-1947. Graph routing boosts centroid candidates.","dependencies":[{"issue_id":"mycelium-j9cq","depends_on_id":"mycelium-fxg8","type":"blocks","created_at":"2026-01-21T07:03:49.113028-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-j9cq","depends_on_id":"mycelium-jeil","type":"blocks","created_at":"2026-01-21T07:03:49.213204-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-jacu","title":"Refactor: Route all signature updates through db.py","description":"## Context (CLAUDE.md New Favorite Pattern)\nPer CLAUDE.md: \"consolidate methods - for example all database connections should go through a data layer instead of having multiple database connections. Same with Signature creation\"\n\n## Problem\n`UPDATE step_signatures SET` appears in multiple files instead of going through consolidated methods in `db.py`:\n\n| File | What it updates | Lines |\n|------|-----------------|-------|\n| `data_layer/mcts.py` | `rejection_count` | 764 |\n| `data_layer/mcts.py` | `depth` | 4466, 4541, 4561 |\n| `data_layer/mcts.py` | `is_archived` | 4476 |\n| `step_signatures/decay.py` | `is_archived` | 528, 735 |\n\n## Solution\nAdd consolidated methods to `db.py`:\n\n```python\ndef increment_rejection_count(self, signature_id: int) -\u003e int:\n    \"\"\"Increment rejection count and return new value.\"\"\"\n    \ndef update_signature_depth(self, signature_id: int, depth: int) -\u003e bool:\n    \"\"\"Update signature depth.\"\"\"\n    \ndef archive_signature(self, signature_id: int, reason: str = None) -\u003e bool:\n    \"\"\"Archive (soft-delete) a signature.\"\"\"\n    \ndef unarchive_signature(self, signature_id: int) -\u003e bool:\n    \"\"\"Restore an archived signature.\"\"\"\n```\n\nThen update `mcts.py` and `decay.py` to call these methods instead of direct SQL.\n\n## Files to Modify\n1. `src/mycelium/step_signatures/db.py` - Add new methods\n2. `src/mycelium/data_layer/mcts.py` - Replace direct SQL with db method calls\n3. `src/mycelium/step_signatures/decay.py` - Replace direct SQL with db method calls\n\n## Acceptance Criteria\n- [ ] New methods added to `db.py` with proper logging\n- [ ] `mcts.py` uses db methods instead of direct SQL for signature updates\n- [ ] `decay.py` uses db methods instead of direct SQL for signature updates\n- [ ] No direct `UPDATE step_signatures` outside of `db.py`\n- [ ] Tests pass\n- [ ] Cache invalidation handled properly in consolidated methods\n\n## Notes\n- The `_update_signature_fields()` method in db.py already exists as a generic updater - consider using it\n- Ensure proper cache invalidation (centroid cache, children cache) in the new methods\n- `mcts.py` currently passes `conn` parameter - new methods should support optional conn param for transaction support","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T17:58:02.619949-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T18:10:13.018018-08:00","closed_at":"2026-01-26T18:10:13.018018-08:00","close_reason":"Implemented in commit 380662d: Added consolidated methods to db.py and updated mcts.py and decay.py to use them"}
{"id":"mycelium-jaq9","title":"Implement sigmoid maturity transition for decompose vs create-new","description":"When routing fails (no matching signature), the system must decide:\n- Create a new atomic signature, OR\n- Decompose into sub-steps that match existing signatures\n\nThis decision should follow a sigmoid based on system maturity:\n\n```\nP(decompose) = sigmoid(maturity_score)\nwhere maturity_score = f(num_signatures, recent_accuracy)\n```\n\n## Implementation\n\n1. **Maturity score function**\n   - Input: num_signatures, recent_accuracy (last N problems)\n   - Output: score that feeds into sigmoid\n   - Tunable parameters: midpoint, steepness\n\n2. **Integration point**: When route fails in solver.py\n   - Compute maturity score\n   - Sample from P(decompose) or use as threshold\n   - If decomposing: call planner to break into sub-steps\n   - Route each sub-step\n\n3. **Escape hatch**: If decomposed sub-steps ALSO don't match\n   - Recognize as genuinely novel operation\n   - Create new atomic signature (bypass sigmoid)\n\n4. **Config values**\n   - MATURITY_SIGMOID_MIDPOINT (num_signatures where P=0.5)\n   - MATURITY_SIGMOID_STEEPNESS\n   - MATURITY_ACCURACY_WEIGHT (how much accuracy factors in)\n\n## Acceptance Criteria\n- [ ] Maturity score computed from signature count + accuracy\n- [ ] Sigmoid probability guides decompose vs create decision\n- [ ] Escape hatch creates new atomic when sub-steps don't match\n- [ ] Config values tunable\n- [ ] Logged for observability\n\nPer CLAUDE.md \"With Mature DB\" section.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T14:53:39.620628-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T16:08:10.735989-08:00","closed_at":"2026-01-21T16:08:10.735989-08:00","close_reason":"Implemented sigmoid maturity transition with escape hatch"}
{"id":"mycelium-jeil","title":"Implement operation-needed extraction from problem text","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T07:03:39.252457-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:43:13.625158-08:00","closed_at":"2026-01-21T08:43:13.625158-08:00","close_reason":"Implemented operation extraction from problem text with caching","dependencies":[{"issue_id":"mycelium-jeil","depends_on_id":"mycelium-k509","type":"blocks","created_at":"2026-01-21T07:03:49.010579-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-jit","title":"Migrate step_signatures helper modules to data_layer","description":"relationships.py (4 calls), sequences.py (1 call), _legacy.py (7 calls) - migrate to use data_layer.db.connection()","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:00:31.865025-08:00","updated_at":"2026-01-09T10:16:28.798171-08:00","closed_at":"2026-01-09T10:16:28.798171-08:00"}
{"id":"mycelium-jmi","title":"Add structured logging throughout codebase","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:28.437679-08:00","updated_at":"2026-01-09T06:36:37.023577-08:00","closed_at":"2026-01-09T06:36:37.023577-08:00"}
{"id":"mycelium-jp2","title":"Design final solver execution strategy","description":"Open question: Does the final synthesis solver run multiple times to merge each sub-problem, or once at the end?\n\nOptions:\n1. **Once at end** - Collect all step results, synthesize final answer in one pass\n2. **Incremental merges** - Merge pairs/groups of steps progressively up to final\n3. **Problem-dependent** - Most likely correct answer. Strategy depends on:\n   - DAG structure (sequential vs parallel steps)\n   - Step dependencies (some steps feed into others)\n   - Problem complexity (simple = one pass, complex = incremental)\n\nNeed to investigate what works best. Likely problem-dependent with heuristics to choose strategy.\n\nRelated: mycelium-ksi (Add final synthesis solver)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T06:59:50.093652-08:00","updated_at":"2026-01-08T11:46:19.950592-08:00","closed_at":"2026-01-08T11:46:19.950592-08:00"}
{"id":"mycelium-jsuk","title":"Epic: Refactor to Function Pointer Architecture","description":"## Overview\nMajor refactor from DSL-based execution to Python function pointer architecture.\n\n## The 3 Components\n1. **LLM** - Recursively decomposes problem into DAG of semantic steps\n2. **Tree** - Routes each step to function pointer via embeddings\n3. **Python Libs** - Executes function calls (deterministic)\n\n## Key Insight\n- Atomic = single Python function call\n- If a function exists (e.g., sympy.integrate), it's atomic\n- We only chain when a PROBLEM requires multiple operations\n\n## Child Issues\nTrack all related issues under this epic.\n\n## Success Metrics\n- GSM8K accuracy maintained or improved\n- Simpler codebase (fewer files)\n- Execution is trivial (just call functions)\n- Clear separation: LLM decomposes, Tree routes, Python executes","status":"closed","priority":0,"issue_type":"epic","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:54:09.753489-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:14:08.541435-08:00","closed_at":"2026-01-31T06:14:08.541435-08:00","close_reason":"All sub-tasks complete: function_registry created, schema updated, solver migrated, obsolete files removed"}
{"id":"mycelium-jvw","title":"Feature: Add param mapping logging for child DSL execution","description":"In solver.py:1603-1625, child DSLs receive rich context but param mapping happens inside execute_dsl_with_llm_matching() with no visibility into which params mapped to which inputs. Fix: Add logging showing param name -\u003e input value mappings for child DSL execution to aid debugging.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T06:42:13.563977-08:00","updated_at":"2026-01-12T07:00:02.219235-08:00","closed_at":"2026-01-12T07:00:02.219235-08:00"}
{"id":"mycelium-jzbf","title":"P3: Document and config-ify remaining magic numbers","description":"## Problem\n\nPer CLAUDE.md \"The Flow\": \"Thresholds come from config, not magic numbers.\"\n\nSeveral magic numbers in the codebase lack documentation and should be in config.py.\n\n## Magic Numbers Found\n\n### 1. Gap Scaling Factor (db.py:219)\n```python\ngap_factor = max(0.0, min(1.0, gap * 2.0))  # Scale to 0-1 range\n```\n- The `2.0` multiplier means gaps 0-0.5 scale to probabilities 0-1\n- Not documented why 2.0 specifically\n\n### 2. Maturity Tau Divisor (db.py:122)\n```python\ntau = BIG_BANG_TARGET_SIGNATURES / 3.0  # ~3tau to reach 95%\n```\n- The `3.0` divisor relates to exponential decay formula\n- Comment mentions \"95%\" but formula rationale not in config\n\n### 3. Welford Minimum Samples\nVarious places check `stats.n \u003e 5` or `stats.n \u003e 50` before using Welford:\n- Should be config: `WELFORD_MIN_SAMPLES_ROUTING = 50`\n\n### 4. Credit Decay Formula\n```python\ncredit = decay_factor ** depth\n```\n- `decay_factor` comes from config, but the formula itself has implicit assumptions\n\n## Solution\n\nAdd to config.py with documentation:\n\n```python\n# =============================================================================\n# FORMULA CONSTANTS (with rationale)\n# =============================================================================\n\n# Gap → Probability scaling\n# Gaps range 0.0-0.5 typically; multiply by 2.0 to get 0.0-1.0 probability range\nFORK_GAP_SCALING_FACTOR = 2.0\n\n# Maturity exponential decay\n# System reaches 95% maturity at 3*tau signatures (standard exponential property)\nBIG_BANG_MATURITY_TAU_DIVISOR = 3.0\n\n# Welford minimum samples before trusting statistics\nWELFORD_MIN_SAMPLES_COLD_START = 5   # Very basic operations\nWELFORD_MIN_SAMPLES_ROUTING = 50     # Routing decisions\nWELFORD_MIN_SAMPLES_STRUCTURE = 100  # Tree structure changes\n```\n\n## Implementation Steps\n\n1. Add constants to config.py with docstrings explaining rationale\n2. Replace hardcoded values with config references\n3. Add comments linking to config documentation\n4. Update CLAUDE.md if needed\n\n## Files to Modify\n\n- `src/mycelium/config.py` - Add documented constants\n- `src/mycelium/step_signatures/db.py` - Use config references\n\n## Testing\n\n- Verify no behavioral changes\n- Grep to ensure magic numbers replaced\n\n## Context\n\nP3 priority per Big 3 audit - cleanup/documentation task.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:51:45.135132-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T14:30:21.515063-08:00","closed_at":"2026-01-28T14:30:21.515063-08:00","close_reason":"Added WELFORD_MIN_SAMPLES_BASIC and WELFORD_MIN_SAMPLES_STRUCTURE constants to config. BIG_BANG_TAU_DIVISOR was already added and in use. The \u003e= 5 checks in db.py could be updated incrementally to use these constants."}
{"id":"mycelium-k509","title":"Add computation_graph column to step_signatures schema","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T07:03:36.789584-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:19:35.712656-08:00","closed_at":"2026-01-21T08:19:35.712656-08:00","close_reason":"Added computation_graph and graph_embedding columns to step_signatures schema with migration"}
{"id":"mycelium-k6g","title":"HIGH: Add docstrings to council_v2.py public methods","description":"Critical methods lack docstrings: _get_similarity() (line 601), _analyze_dag() (line 624), _select_synthesis_strategy() (line 650). Add comprehensive docstrings with Args, Returns, Raises.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:47.908198-08:00","updated_at":"2026-01-09T08:26:00.365795-08:00","closed_at":"2026-01-09T08:26:00.365795-08:00"}
{"id":"mycelium-khk","title":"DB method return types wrong for PostgreSQL","description":"_execute() and _executemany() return sqlite3.Cursor but actually return psycopg2 cursor for PostgreSQL. Should be Any or a Cursor protocol.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-09T08:33:00.287411-08:00","updated_at":"2026-01-09T10:16:40.538162-08:00","closed_at":"2026-01-09T10:16:40.538162-08:00"}
{"id":"mycelium-kj8t","title":"Bug: Investigate how orphan umbrellas are created","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T17:23:33.212444-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T17:30:33.812864-08:00","closed_at":"2026-01-26T17:30:33.812864-08:00","close_reason":"Fixed root cause: scaffold branches abandoned when global dedup redirects. Added _demote_if_orphan() to demote orphan umbrellas back to leaves."}
{"id":"mycelium-kkch","title":"Cleanup: Standardize error handling patterns","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-13T14:55:46.936322-08:00","updated_at":"2026-01-20T17:50:06.598231-08:00","closed_at":"2026-01-20T17:50:06.598231-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-kn8k","title":"Audit DSL execution pathways","description":"**Current State:** 4 DSL execution entry points:\n- dsl_executor.py: try_execute_dsl() - main dispatcher\n- math_layer.py: try_execute_dsl_math() - Python math fallback\n- sympy_layer.py: try_execute_dsl_sympy() - SymPy symbolic math\n- solver.py: maybe_run_dsl_regeneration() - regeneration logic\n\n**Question:** Is this intentional strategy pattern (math vs sympy backends) or code duplication?\n\n**Goal:** Audit and document. If redundant, consolidate. If intentional layering, document the architecture.\n\n**Files:** src/mycelium/step_signatures/dsl_executor.py, math_layer.py, sympy_layer.py","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T13:22:02.477653-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T13:45:36.648909-08:00","closed_at":"2026-01-25T13:45:36.648909-08:00","close_reason":"Audit complete: Intentional strategy pattern. try_execute_dsl() dispatches to math_layer (AST-based safe eval) or sympy_layer (SymPy algebra). maybe_run_dsl_regeneration() is a separate concern (rewriting, not execution). Added architecture docs to dsl_executor.py."}
{"id":"mycelium-koqy","title":"Bug: DSL failures logged at DEBUG level","description":"DSL execution failures are logged at DEBUG, not WARN. Misses important signals.\n\nLocation: dsl_executor.py:132-150\n\nPer CLAUDE.md: 'failures are valuable data points' - we need to SEE them.\n\nFix: Change logger.debug() to logger.warning() for DSL failures that affect problem solving.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:27:57.991273-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:08:22.957343-08:00","closed_at":"2026-01-15T14:08:22.957343-08:00","close_reason":"Elevated DSL failures from DEBUG to WARNING: sympy failures, huge results, null results, exceptions. Failures now visible per CLAUDE.md."}
{"id":"mycelium-ksi","title":"Add final synthesis solver","description":"Currently each step gets solved independently, but there's no explicit 'combine all the pieces' step at the end.\n\nNeed a final synthesis solver that:\n1. Takes all step results + injected methods\n2. Produces coherent final answer\n3. Handles cases where steps have dependencies\n4. Verifies the answer makes sense given the original problem\n\nThis is the missing piece between 'solve all steps' and 'return answer'.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-08T06:38:34.82638-08:00","updated_at":"2026-01-08T11:52:45.828687-08:00","closed_at":"2026-01-08T11:52:45.828687-08:00","dependencies":[{"issue_id":"mycelium-ksi","depends_on_id":"mycelium-jp2","type":"blocks","created_at":"2026-01-08T07:00:11.822804-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-kw0u","title":"Perf: Hierarchical routing pruning (early termination)","description":"Currently: Check all children at each level. Opportunity: If parent similarity \u003c threshold, skip entire subtree. Early termination for dissimilar branches.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:30:49.872718-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.265186-08:00","closed_at":"2026-01-20T18:00:01.265186-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-kx27","title":"Test: Add unit tests for orphan validation functions","description":"Add unit tests for the new orphan validation functions in db.py: validate_child_signatures(), find_orphan_child_references(), cleanup_orphan_child_references(). Test cases: empty list, valid children, orphan detection, mixed valid/orphan, cleanup behavior.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-12T10:44:04.768467-08:00","updated_at":"2026-01-20T17:50:06.37274-08:00","closed_at":"2026-01-20T17:50:06.37274-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-l703","title":"Reactive exploration: spawn high-temp threads on failure for cross-examination","description":"## Motivation\nWhen a problem fails, we currently just record the failure. But we have no way to know\nWHICH (dag_step, leaf_node) pair caused the failure.\n\n## Idea: Cross-Examination via Reactive Exploration\n\nWhen a problem fails:\n1. Spawn N additional threads with higher temperature (more exploration)\n2. Try alternative routes at each step\n3. If ANY thread wins, compare divergence points between winning and losing threads\n4. The step where winning/losing threads diverged = the culprit (dag_step, leaf_node) pair\n\n## Example\n```\nProblem: \"Calculate 15% of 200\"\n\nThread 1 (original, lost):\n  step1 → sig_A (convert percent)    ✓ same\n  step2 → sig_B (multiply)           ← DIVERGENCE POINT\n  step3 → sig_C (format)             \n  Result: WRONG\n\nThread 2 (exploration, won):\n  step1 → sig_A (convert percent)    ✓ same  \n  step2 → sig_D (divide then mult)   ← DIFFERENT CHOICE\n  step3 → sig_C (format)\n  Result: CORRECT\n\nConclusion: sig_B is wrong for this step type, sig_D is right\n→ Blame sig_B, credit sig_D\n→ Maybe sig_B needs decomposition or DSL rewrite\n```\n\n## Implementation\n1. After grading, if problem failed:\n   - Re-run with EXPLORATION_EPSILON=1.0 (pure exploration)\n   - Or use higher temperature in UCB1\n   - Cap at N attempts (e.g., 5)\n\n2. If a winning thread is found:\n   - Compare step-by-step with losing thread\n   - Find divergence points\n   - Attribute precise blame/credit\n\n3. Feed back to signatures:\n   - Blamed signature: increment operational_failures\n   - Credited signature: increment successes\n   - Flag blamed sig for potential decomposition\n\n## Config\n```python\nREACTIVE_EXPLORATION_ENABLED = True  # Already exists!\nREACTIVE_EXPLORATION_MAX_RETRIES = 5\nREACTIVE_EXPLORATION_TEMPERATURE = 1.5  # Higher than normal\n```\n\n## Relationship to Existing Code\nWe already have REACTIVE_EXPLORATION_* configs but need to verify the cross-examination\nlogic is implemented. The key insight is COMPARING winning vs losing threads to find\nthe exact divergence point.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T07:11:17.095248-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T07:18:53.852755-08:00","closed_at":"2026-01-25T07:18:53.852755-08:00","close_reason":"Implemented multi-thread reactive exploration with cross-examination: spawns N threads with higher temperature, collects all DAGs, and cross-examines divergence points across all exploration runs"}
{"id":"mycelium-l7xs","title":"Remove obsolete DSL and GTS files","description":"## Goal\nClean up files that are no longer needed in the new architecture.\n\n## Files to Remove\n- `src/mycelium/step_signatures/dsl_executor.py`\n- `src/mycelium/step_signatures/dsl_types.py`\n- `src/mycelium/step_signatures/math_layer.py`\n- `src/mycelium/step_signatures/sympy_layer.py`\n- `src/mycelium/gts_model.py`\n- `src/mycelium/gts_decomposer.py`\n- `src/mycelium/expression_tree.py`\n- `src/mycelium/local_decomposer.py`\n- `src/mycelium/chain_nodes.py`\n\n## Process\n1. Identify all imports of these files\n2. Update imports to use new alternatives\n3. Remove the files\n4. Run tests to ensure nothing breaks\n\n## Acceptance Criteria\n- [ ] All listed files removed\n- [ ] No broken imports\n- [ ] Tests still pass","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:53:42.716829-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:13:59.69063-08:00","closed_at":"2026-01-31T06:13:59.69063-08:00","close_reason":"Completed in commit 8627d70 - solver uses function_registry, obsolete files removed","dependencies":[{"issue_id":"mycelium-l7xs","depends_on_id":"mycelium-t3ao","type":"blocks","created_at":"2026-01-31T05:54:33.535614-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-l8j","title":"Unbounded MCTS cache growth causes memory leak","description":"mcts.py:569-572 - _plan_cache and _sim_cache grow unboundedly. Caches only cleared at start of find_best_decomposition(). Long-running processes accumulate unlimited entries. Implement bounded LRU cache with functools.lru_cache or cachetools.LRUCache.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:37.694441-08:00","updated_at":"2026-01-08T11:52:39.386468-08:00","closed_at":"2026-01-08T11:52:39.386468-08:00"}
{"id":"mycelium-laf","title":"Add end-to-end integration tests","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:24:54.241384-08:00","updated_at":"2026-01-09T06:48:20.62586-08:00","closed_at":"2026-01-09T06:48:20.62586-08:00"}
{"id":"mycelium-lmba","title":"Refactor: Break up _execute_step() complexity","description":"_execute_step() is 187 lines with 4 nest levels. Hard to maintain.\n\nLocation: solver.py:578-765\n\nHas 4 DSL execution attempts (#4, #4.6, #4.7, umbrella fallback) and 7 success/failure paths.\n\nBreak into focused methods:\n- _find_or_create_signature()\n- _execute_through_umbrella()\n- _execute_dsl_with_fallbacks()\n\nPer CLAUDE.md: 'Smooth refactoring - not all at once'","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:27:51.347892-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.217643-08:00","closed_at":"2026-01-20T18:00:01.217643-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-lp0","title":"Feature: Add routing confidence scoring for child selection","description":"In solver.py:1557-1573, LLM selects which child signature to use but there's no confidence score on the routing decision. If LLM returns unparseable output, routing silently fails. No fallback if child selection is ambiguous. Fix: Add confidence scoring, log selection rationale, implement fallback for low-confidence selections.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T06:42:10.367531-08:00","updated_at":"2026-01-12T07:01:46.934445-08:00","closed_at":"2026-01-12T07:01:46.934445-08:00"}
{"id":"mycelium-lp9p","title":"Critical: Null dereference in composite steps with empty sub_results","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:29.01353-08:00","updated_at":"2026-01-13T11:37:33.784751-08:00","closed_at":"2026-01-13T11:37:33.784751-08:00"}
{"id":"mycelium-lvio","title":"Bug: Silent JSON failure in umbrella_learner.py returns empty dict","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:43.407416-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:16:46.851846-08:00","closed_at":"2026-01-15T05:16:46.851846-08:00","close_reason":"Added logging to _extract_json() in umbrella_learner.py and dsl_generator.py - now logs response preview when JSON extraction fails instead of silently returning None"}
{"id":"mycelium-m76g","title":"Implement wave function collapse at final step","description":"Per ideas.md: Wave collapses at last DAG step where ground truth is available. Update amplitude_post based on thread success/failure. High confidence + failure = strong negative signal.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:22.387651-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T16:44:32.742736-08:00","closed_at":"2026-01-20T16:44:32.742736-08:00","close_reason":"Merged into mycelium-h0ne (post-mortem credit propagation). Wave function collapse is just the post-mortem step of computing amplitude_post after grading.","dependencies":[{"issue_id":"mycelium-m76g","depends_on_id":"mycelium-t9kh","type":"blocks","created_at":"2026-01-20T14:07:34.241833-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-mb7s","title":"Consolidate cache invalidation patterns","description":"## Problem\nCache invalidation in src/mycelium/step_signatures/db.py is inconsistent. Different operations call different combinations of cache invalidation functions:\n\nCurrent cache functions:\n- `invalidate_signature_cache(sig_id)` - clears signature from LRU cache\n- `invalidate_centroid_cache(sig_id)` - clears centroid data\n- `invalidate_children_cache(sig_id)` - clears children list\n- `self.invalidate_centroid_matrix()` - clears the routing matrix\n\nInconsistent patterns found:\n- Line ~571: centroid_cache + centroid_matrix (missing signature_cache?)\n- Lines ~810-811: centroid_cache + signature_cache (missing matrix?)\n- Lines ~2763-2765: All three individual + matrix\n- Lines ~4862-4866: Full quad invalidation for relationship changes\n- Lines ~4043, 4069: Just signature_cache for DSL updates\n\n## Pattern to Follow\nSee `propagate_graph_centroid_to_parents()` - it consolidates all graph_centroid updates. Apply same pattern to cache invalidation.\n\n## Proposed Solution\nCreate semantic helper functions that know which caches to invalidate:\n\n```python\ndef _invalidate_on_embedding_change(self, signature_id: int):\n    '''Invalidate when centroid/graph_embedding changes.'''\n    invalidate_centroid_cache(signature_id)\n    invalidate_signature_cache(signature_id)\n    self.invalidate_centroid_matrix()\n\ndef _invalidate_on_relationship_change(self, parent_id: int, child_id: int):\n    '''Invalidate when parent-child relationship added/removed.'''\n    invalidate_centroid_cache(parent_id)\n    invalidate_children_cache(parent_id)\n    invalidate_signature_cache(parent_id)\n    invalidate_signature_cache(child_id)\n    self.invalidate_centroid_matrix()\n\ndef _invalidate_on_dsl_change(self, signature_id: int):\n    '''Invalidate when DSL script changes.'''\n    invalidate_signature_cache(signature_id)\n```\n\nReplace all manual invalidation patterns with these helpers.\n\n## Acceptance Criteria\n- [ ] 3 semantic helper functions created\n- [ ] All manual cache invalidation patterns replaced with helpers\n- [ ] Each operation type uses consistent cache invalidation\n- [ ] No cache consistency bugs introduced\n- [ ] Document which helper to use for which operation type","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:08:41.92609-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:41:54.649281-08:00","closed_at":"2026-01-25T08:41:54.649281-08:00","close_reason":"Implemented 3 semantic cache invalidation helpers (_invalidate_on_embedding_change, _invalidate_on_relationship_change, _invalidate_on_dsl_change) and consolidated 8 manual invalidation patterns to use them. Tests pass."}
{"id":"mycelium-mf3","title":"Archive V1 code (council.py, signatures.py)","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T12:23:46.757811-08:00","updated_at":"2026-01-08T13:07:54.689376-08:00","closed_at":"2026-01-08T13:07:54.689376-08:00"}
{"id":"mycelium-mgbs","title":"Store dsl_hint in mcts_dag_steps for better step-node key normalization","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-22T10:52:34.737092-08:00","created_by":"Bryce Roche","updated_at":"2026-01-22T10:59:45.058285-08:00","closed_at":"2026-01-22T10:59:45.058285-08:00","close_reason":"Added dsl_hint column to mcts_dag_steps. Now dag_step_node_stats uses normalized operation hints (+, *, -) instead of NL descriptions for better stats aggregation."}
{"id":"mycelium-mjg","title":"LOW: Replace magic numbers with constants","description":"council_v2.py has hardcoded values like problem[:200]. Define as module constants: MAX_PARENT_PROBLEM_LENGTH = 200, etc.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:16.173618-08:00","updated_at":"2026-01-09T08:31:30.552368-08:00","closed_at":"2026-01-09T08:31:30.552368-08:00"}
{"id":"mycelium-mjls","title":"Perf: Async signature stat writes (fire-and-forget)","description":"Success/failure updates don't need to block step execution. Fire-and-forget updates, sync before next problem. Reduces blocking I/O on hot path.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:30:56.253407-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.241593-08:00","closed_at":"2026-01-20T18:00:01.241593-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-mm08","title":"Feature: Decomposition bucket leaf for complex dag_steps","description":"Create a special \"decompose\" leaf that catches complex/multi-step dag_steps and queues them for further decomposition.\n\n**Flow:**\n1. Planner generates DAG with steps\n2. Router routes each step\n3. If step is too complex (low similarity to atomic leaves, multiple operations detected), route to \"decompose\" bucket\n4. Bucket accumulates complex steps\n5. Periodically (or at threshold), batch send to LLM for decomposition\n6. LLM breaks each into atomic sub-steps\n7. Create new leaf signatures for the atomic pieces\n\n**Detection heuristics for \"too complex\":**\n- Multiple operators in step description (+, -, *, / together)\n- Low similarity to all existing atomic leaves (\u003c 0.7)\n- Step description length above threshold (long = complex)\n- Contains words like \"then\", \"and then\", \"after that\"\n\n**The \"decompose\" leaf:**\n- is_semantic_umbrella = 0 (it's a leaf)\n- step_type = \"decompose\" or \"complex_step\"\n- dsl_script = NULL (no direct execution)\n- Special handling in solver: queue instead of execute\n\n**Batch decomposition:**\n- Triggered every N problems or when bucket size \u003e threshold\n- Send batch to LLM with prompt: \"Break each step into atomic operations\"\n- Parse results, create new signatures\n- Clear bucket\n\n**Benefits:**\n- Self-healing system\n- Catches planner mistakes\n- Batches LLM calls (efficient)\n- Continuous learning of new atomic patterns\n\nPer CLAUDE.md: \"Failing signatures get decomposed\"","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T10:25:11.702995-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T10:31:28.445455-08:00","closed_at":"2026-01-23T10:31:28.445455-08:00","close_reason":"Implemented decomposition bucket: queue complex steps, batch process via LLM"}
{"id":"mycelium-mpg","title":"Create train/test evaluation script","description":"Need to measure if signatures actually help:\n\n1. Train on subset of problems (build signature library)\n2. Test on held-out problems\n3. Compare: accuracy with signatures vs without\n4. Track: how often method injection fires\n\nMetrics to capture:\n- Baseline accuracy (no signatures)  \n- With signatures accuracy\n- % of test problems that matched a signature\n- Success rate when signature was injected","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T05:32:49.383522-08:00","updated_at":"2026-01-08T07:36:57.192507-08:00","closed_at":"2026-01-08T07:36:57.192507-08:00","dependencies":[{"issue_id":"mycelium-mpg","depends_on_id":"mycelium-ulk","type":"blocks","created_at":"2026-01-08T05:33:18.390854-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-n94b","title":"Task: Enforce 'Only call LLM on leaf nodes' rule (per CLAUDE.md)","description":"Per CLAUDE.md:11-12 'Only call LLM on leaf nodes'. Currently: planner is called on every problem (not just leaves), umbrella routing has LLM fallback (solver.py:968-1001). Per signature types: Root=router, Umbrella=router, Leaf=executor. Only leaves should invoke LLM. Fix: Remove LLM fallback in umbrella routing, ensure planner only called for leaf execution.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:31:24.776154-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T13:57:56.643983-08:00","closed_at":"2026-01-15T13:57:56.643983-08:00","close_reason":"Removed LLM fallback in umbrella routing (solver.py). Umbrellas are routers - per CLAUDE.md only leaves (executors) should call LLM. When no embedding is available, routing now returns None to trigger decomposition/failure."}
{"id":"mycelium-n9v","title":"Add unit tests for wave_physics module","description":"Write pytest tests for compute_interference_score, compute_resonance, frequency functions. Test edge cases: zero centroids, empty signatures, extreme amplitudes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:40.882549-08:00","updated_at":"2026-01-09T07:55:40.36301-08:00","closed_at":"2026-01-09T07:55:40.36301-08:00"}
{"id":"mycelium-nd5f","title":"System Independence: Remove manual tree restructuring in collapse_single_child_routers()","description":"mcts.py:4528-4633 collapse_single_child_routers() manually restructures tree by deleting/updating signature_relationships. This violates System Independence - tree structure should emerge from Welford stats, not manual intervention. Consider: let single-child routers exist naturally, or make collapse data-driven.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:00:40.287778-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:06:25.128707-08:00","closed_at":"2026-01-28T12:06:25.128707-08:00","close_reason":"Not a violation - collapse_single_child_routers() is automated system behavior, which is what we want. System Independence means WE don't manually intervene, not that the system can't restructure itself."}
{"id":"mycelium-ngs8","title":"Update LLM decomposer prompts for new schema","description":"## Goal\nUpdate `src/mycelium/mathdecomp/llm_api.py` to generate decompositions using function registry keys.\n\n## Changes to DECOMPOSE_PROMPT\n\n### Before\n```\n\"op\": \"+|-|*|/\"\n```\n\n### After\n```\n\"func\": \"add|sub|mul|div|sqrt|...\"  # Keys from function registry\n\"inputs\": [{\"type\": \"extraction\", \"id\": \"...\"}, ...]  # Flexible arity\n```\n\n## Also Consider\n- Include list of available functions in prompt\n- Few-shot examples with new schema\n- Handle variable arity in examples (show sqrt with 1 input)\n\n## Acceptance Criteria\n- [ ] Prompt uses func: str instead of op: enum\n- [ ] Prompt shows available function names\n- [ ] Examples demonstrate variable arity\n- [ ] LLM output parses correctly into new schema","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:54:08.47501-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:07:28.265557-08:00","closed_at":"2026-01-31T06:07:28.265557-08:00","close_reason":"Completed in commit bdca455 - executor uses function_registry, prompts updated with new schema","dependencies":[{"issue_id":"mycelium-ngs8","depends_on_id":"mycelium-rqys","type":"blocks","created_at":"2026-01-31T05:54:33.126966-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-nirq","title":"Post-mortem: UCB1 parameter adjustment from hit/miss patterns","description":"UCB1 has an exploration constant that balances exploitation vs exploration. Post-mortem hit/miss patterns can inform whether we're over-exploring (wasting compute on bad paths) or under-exploring (missing good paths). Adjust the constant based on evidence.","status":"closed","priority":3,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:04.340678-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:50:36.957978-08:00","closed_at":"2026-01-21T08:50:36.957978-08:00","close_reason":"Already implemented. UCB1_ADJUSTMENT_ENABLED config, AdaptiveExploration.record_postmortem_stats(), _update_ucb1_adjustment(). Adjusts exploration constant from hit/miss patterns."}
{"id":"mycelium-nke","title":"Remove deprecated get_method_superposition_legacy()","description":"step_signatures.py:1386-1400 - Deprecated method still present. Either remove completely or add warnings.warn() deprecation warning.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:10:49.606643-08:00","updated_at":"2026-01-08T12:11:55.371717-08:00","closed_at":"2026-01-08T12:11:55.371717-08:00"}
{"id":"mycelium-nnb","title":"Split step_signatures.py into smaller modules","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:23:40.825031-08:00","updated_at":"2026-01-09T10:19:53.03221-08:00","closed_at":"2026-01-09T10:19:53.03221-08:00"}
{"id":"mycelium-nolr","title":"P2: Move all hardcoded similarity thresholds to config.py","description":"## Problem\n\nPer CLAUDE.md \"The Flow\": \"Thresholds come from config, not magic numbers.\"\n\nSimilarity thresholds are hardcoded across multiple files instead of being centralized in config.py.\n\n## Current Violations\n\n### db.py\n- Line 32: `ATOMIC_SIMILARITY_THRESHOLD = 0.70`\n- Line 991, 1152, 1184, 1233, 1298, 3004: `min_similarity: float = 0.85` (default params)\n- Line 219: `gap * 2.0` (magic multiplier for fork probability)\n\n### umbrella_learner.py\n- Line 609: `min_similarity=0.75` in find_deeper_signature call\n- Line 629: `min_similarity=0.85` in find_or_create call\n\n### solver.py\n- Line 5208: `0.85` hardcoded in routing logic\n\n### dsl_templates.py\n- Line 436: `min_similarity: float = 0.5`\n- Lines 507-509: `param_weight = 0.7 if semantic_params else 0.3`\n- Line 578: `min_success_rate: float = 0.6`\n- Line 634: `if best_similarity \u003e= 0.7`\n\n## Solution\n\nAdd all thresholds to config.py with clear documentation:\n\n```python\n# config.py - Similarity Thresholds\n# Per CLAUDE.md \"The Flow\": Centralized threshold configuration\n\n# Atomic operation detection\nATOMIC_SIMILARITY_THRESHOLD = 0.70  # Below this = unknown/complex operation\n\n# Signature routing\nROUTING_MIN_SIMILARITY = 0.85  # Default min similarity for find_or_create\nROUTING_HIGH_CONFIDENCE = 0.90  # Skip planner at this similarity\n\n# Umbrella learner\nUMBRELLA_REPOINT_SIMILARITY = 0.75  # Threshold for repointing to deeper sig\nUMBRELLA_CREATE_SIMILARITY = 0.85  # Threshold for creating under umbrella\n\n# DSL template matching\nDSL_MIN_SIMILARITY = 0.50  # Minimum for DSL template consideration\nDSL_PARAM_WEIGHT_SEMANTIC = 0.70  # Weight when semantic params available\nDSL_PARAM_WEIGHT_DEFAULT = 0.30  # Weight otherwise\nDSL_MIN_SUCCESS_RATE = 0.60  # Minimum success rate for DSL selection\n\n# Fork probability\nFORK_GAP_SCALING_FACTOR = 2.0  # Multiplier for gap → probability conversion\n```\n\n## Implementation Steps\n\n1. Add all threshold constants to config.py with documentation\n2. Update each file to import from config:\n   - `from mycelium.config import ROUTING_MIN_SIMILARITY, ...`\n3. Replace hardcoded values with config references\n4. Run tests to verify no behavioral changes\n5. Document in CLAUDE.md that thresholds are now centralized\n\n## Files to Modify\n\n- `src/mycelium/config.py` - Add all threshold constants\n- `src/mycelium/step_signatures/db.py`\n- `src/mycelium/step_signatures/umbrella_learner.py`\n- `src/mycelium/step_signatures/dsl_templates.py`\n- `src/mycelium/solver.py`\n\n## Testing\n\n- All tests must pass (behavioral equivalence)\n- Verify constants are used correctly via grep\n\n## Future Enhancement\n\nAfter centralizing, these thresholds can be made Welford-adaptive:\n```python\ndef get_routing_threshold() -\u003e float:\n    \"\"\"Get Welford-adaptive routing threshold.\"\"\"\n    stats = get_state_manager().get_welford_stats(\"routing\")\n    if stats and stats.n \u003e 100:\n        return max(0.80, 1.0 - 2 * stats.std)\n    return ROUTING_MIN_SIMILARITY  # Cold start fallback\n```\n\n## Context\n\nP2 priority per Big 3 audit - The Flow violations.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:50:54.424921-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:20:42.152668-08:00","closed_at":"2026-01-28T13:20:42.152668-08:00","close_reason":"Completed: All hardcoded similarity thresholds moved to config.py per CLAUDE.md 'The Flow'. Added FORK_GAP_SCALING_FACTOR, ROUTING_MIN_SIMILARITY, ROUTING_MIN_SIMILARITY_PERMISSIVE, ROUTING_BEST_MATCH_MIN_SIMILARITY, PLACEMENT_MIN_SIMILARITY, HINT_ALTERNATIVES_MIN_SIMILARITY to config.py and updated db.py, mcts.py to use them. Many other thresholds (MIN_MATCH_THRESHOLD, DSL_*, UMBRELLA_REPOINT_SIMILARITY) were already in config from earlier work."}
{"id":"mycelium-nqv7","title":"Implement custom GTS model loader (no MWPToolkit dependency)","description":"## Context\nMWPToolkit has dependency conflicts (old tokenizers requires Rust compiler). We need to load the trained GTS model directly with PyTorch.\n\n## Goal\nLoad and run inference on the GTS model without requiring MWPToolkit as a dependency.\n\n## Model Files\n`trained_model/GTS-mawps/`:\n- `model.pth` - PyTorch state dict (53MB)\n- `config.json` - Model hyperparameters\n- `input_vocab.json` - Word to index mapping\n- `output_vocab.json` - Output symbols (operators, NUM_X tokens)\n\n## Key Config Values (from config.json)\n```json\n{\n  'embedding_size': 128,\n  'hidden_size': 512,\n  'rnn_cell_type': 'gru',\n  'num_layers': 2,\n  'beam_size': 5,\n  'equation_fix': 'prefix'\n}\n```\n\n## Implementation\n\nCreate `src/mycelium/gts_model.py`:\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass GTSEncoder(nn.Module):\n    '''Bidirectional GRU encoder.'''\n    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers):\n        ...\n\nclass GTSDecoder(nn.Module):\n    '''Tree-structured decoder for prefix expression generation.'''\n    def __init__(self, hidden_size, output_vocab_size, num_layers):\n        ...\n\nclass GTSModel(nn.Module):\n    '''Full GTS model for inference.'''\n    \n    def __init__(self, config: dict, input_vocab: dict, output_vocab: dict):\n        ...\n    \n    @classmethod\n    def from_pretrained(cls, model_path: str) -\u003e 'GTSModel':\n        '''Load trained model from directory.'''\n        config = json.load(open(f'{model_path}/config.json'))\n        input_vocab = json.load(open(f'{model_path}/input_vocab.json'))\n        output_vocab = json.load(open(f'{model_path}/output_vocab.json'))\n        \n        model = cls(config, input_vocab, output_vocab)\n        model.load_state_dict(torch.load(f'{model_path}/model.pth'))\n        return model\n    \n    def generate(self, problem_tokens: list[int], beam_size: int = 5) -\u003e str:\n        '''Generate prefix expression using beam search.'''\n        ...\n```\n\n## Reference\nThe GTS architecture is documented in:\n- Paper: 'A Goal-Driven Tree-Structured Neural Model for Math Word Problems' (IJCAI 2019)\n- MWPToolkit source: https://github.com/LYH-YF/MWPToolkit/blob/master/mwptoolkit/model/Seq2Tree/gts.py\n\n## Alternative Approach\nIf reconstructing the model is too complex, consider:\n1. Running inference in a subprocess that has MWPToolkit installed\n2. Using ONNX export from Colab and loading ONNX model locally\n3. Keeping Colab as inference service (API endpoint)\n\n## Tests Required\n- test_model_loading\n- test_encoder_forward\n- test_decoder_forward\n- test_beam_search_generation\n- test_output_format_matches_mwptoolkit\n\n## Acceptance Criteria\n- [ ] GTSModel loads from trained_model/GTS-mawps/\n- [ ] generate() produces valid prefix expressions\n- [ ] No MWPToolkit import required\n- [ ] Output matches MWPToolkit inference (validate on test set)","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T12:28:31.255746-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T12:53:05.426778-08:00","closed_at":"2026-01-29T12:53:05.426778-08:00","close_reason":"All implemented with 208 tests passing. Committed in 2b96e5b."}
{"id":"mycelium-nrh4","title":"Perf: Batch embedding calls for plan steps","description":"Currently: 1 embed call per step. Opportunity: Batch all steps in a plan into single embed call. MathBERT supports batching, could 3-5x speedup on decomposition.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:30:24.561354-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.100006-08:00","closed_at":"2026-01-20T18:00:01.100006-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-nvc9","title":"Bug: DSL examples don't include actual expression/inputs","description":"## Problem\nWhen regenerating DSL for a signature, the examples passed to the LLM only include:\n- step_text (e.g., \"Calculate new house value\")\n- result (e.g., \"200000.0\")\n\nBut they DON'T include:\n- The actual expression used (e.g., \"hours * rate\")\n- The input values\n- The operation type beyond step_type name\n\n## Impact\nLLM generates garbage DSL scripts when there aren't enough examples to infer the pattern.\nFixed the symptom (MIN_EXAMPLES = 3), but root cause remains.\n\n## Suggested Fix\nInclude the actual expression/inputs in examples:\n```\n- Step: Calculate new house value\n  Expression: price * multiplier\n  Inputs: {price: 80000, multiplier: 2.5}\n  Result: 200000.0\n```\n\n## Files\n- src/mycelium/step_signatures/dsl_generator.py\n- Step examples table may need inputs column populated","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T18:34:39.117651-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T18:48:10.56092-08:00","closed_at":"2026-01-26T18:48:10.56092-08:00","close_reason":"Fixed in 7c9345b - DSL examples now include expression and inputs for better learning"}
{"id":"mycelium-o0m","title":"Low signature creation rate during validation runs","description":"100-problem run only created 4 new signatures despite 100 problems solved. Expected many more signatures to be created and stored. Need to investigate why signatures aren't being saved - possible DB concurrency issue or signature threshold too strict.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T14:03:35.353603-08:00","updated_at":"2026-01-15T05:48:52.483169-08:00","closed_at":"2026-01-15T05:48:52.483169-08:00","close_reason":"Added cold-start aware adaptive match threshold - starts at 0.92 during cold start (more signatures created), ramps down to 0.85 as DB matures (less fragmentation)"}
{"id":"mycelium-o0r1","title":"Post-mortem: Routing threshold adjustment from systematic misroutes","description":"If post-mortem detects systematic misroutes (high-similarity but wrong operation), thresholds may need adjustment. Too loose → false matches. Too tight → missed matches. Post-mortem has ground truth to calibrate.","status":"closed","priority":3,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:06.656401-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T14:29:59.441556-08:00","closed_at":"2026-01-25T14:29:59.441556-08:00","close_reason":"Superseded by graph_embedding + Welford match scoring. System is now self-correcting through match_score (similarity + traffic + success + variance)."}
{"id":"mycelium-o1a","title":"Create storage backend abstraction (ABC + SQLite impl)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:07.396472-08:00","updated_at":"2026-01-09T10:16:10.305632-08:00","closed_at":"2026-01-09T10:16:10.305632-08:00","dependencies":[{"issue_id":"mycelium-o1a","depends_on_id":"mycelium-p75","type":"blocks","created_at":"2026-01-09T05:54:52.212579-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-o3c7","title":"Medium: Missing bounds check on parameter extraction (extra numbers dropped)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:50.12924-08:00","updated_at":"2026-01-13T11:58:29.385601-08:00","closed_at":"2026-01-13T11:58:29.385601-08:00"}
{"id":"mycelium-o6wj","title":"Refactor: Extract numeric value extraction to shared utility","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-13T14:55:31.825308-08:00","updated_at":"2026-01-20T17:50:06.48571-08:00","closed_at":"2026-01-20T17:50:06.48571-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-o9db","title":"Refactor: Pass embedder instance instead of fetching singleton","description":"## Context (CLAUDE.md New Favorite Pattern)\nPer CLAUDE.md: \"consolidate method calls for features to simplify our codebase\"\n\n## Problem\n`Embedder.get_instance()` is called 15+ times across files instead of passing the instance:\n\n| File | Count | Pattern |\n|------|-------|---------|\n| `step_signatures/db.py` | 5 | Fetches inside methods |\n| `step_signatures/dsl_templates.py` | 4 | Fetches inside functions |\n| `step_signatures/dsl_types.py` | 2 | Fetches inside methods |\n| `step_signatures/umbrella_learner.py` | 1 | Stores in `self.embedder` ✓ |\n| `solver.py` | 1 | Stores in `self.embedder` ✓ |\n\n## Good Pattern (already in use)\n`solver.py` and `umbrella_learner.py` store the embedder instance:\n```python\nself.embedder = Embedder.get_instance()\n# Then pass to methods: cached_embed(text, self.embedder)\n```\n\n## Solution\n1. Classes that need embedder should accept it in `__init__` or store singleton once\n2. Functions should accept embedder as parameter with default `None` (fetch if not provided)\n3. Callers should pass their stored instance\n\nExample refactor for `dsl_templates.py`:\n```python\ndef get_dsl_hint_for_step(step_text: str, embedder: Embedder = None) -\u003e Optional[str]:\n    if embedder is None:\n        embedder = Embedder.get_instance()\n    # ... use embedder\n```\n\n## Files to Modify\n1. `src/mycelium/step_signatures/db.py` - Accept embedder in __init__, use stored instance\n2. `src/mycelium/step_signatures/dsl_templates.py` - Add embedder param to functions\n3. `src/mycelium/step_signatures/dsl_types.py` - Add embedder param to methods\n\n## Acceptance Criteria\n- [ ] Classes store embedder instance in __init__\n- [ ] Functions accept optional embedder parameter\n- [ ] Singleton fetch only happens once per component lifecycle\n- [ ] Tests pass\n- [ ] No performance regression (embedding calls should be same count)\n\n## Notes\n- This is optimization/cleanliness, not a bug fix\n- The singleton pattern works, this just reduces repeated lookups\n- Be careful with lazy initialization - some code may rely on late binding","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T17:58:03.591612-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T18:04:51.62911-08:00","closed_at":"2026-01-26T18:04:51.62911-08:00","close_reason":"Implemented: All functions/methods now accept optional embedder param, StepSignatureDB stores embedder with lazy init"}
{"id":"mycelium-obu2","title":"Bug: Orphaned umbrella routers from unprincipled branching","description":"## Summary\nOrphaned umbrella routers (umbrellas with no children) are a symptom of unprincipled branching decisions. This bug tracks the root cause fix.\n\n## Root Cause\nCurrent branching logic creates umbrella nodes reactively (on failure) without statistical evidence. This leads to:\n1. Premature umbrella creation before enough data is collected\n2. Orphan umbrellas when children are moved/deleted\n3. Inconsistent tree structure\n\n## Solution\nThe fix is NOT to patch orphan detection/cleanup, but to implement principled branching:\n\n1. **Welford stats table** (mycelium-bjrf): Collect running statistics\n2. **Proposed signatures staging** (mycelium-xv09): Stage before committing\n3. **Cold start mode** (mycelium-5cn0): Collect stats before restructuring\n4. **Auto-restructure** (mycelium-heh3): Restructure based on stats\n5. **Welford decision logic** (mycelium-br28): Principled sibling/child decisions\n\n## Verification\nAfter all dependencies are implemented:\n1. Run 50+ problems on fresh DB\n2. Verify no orphan umbrellas via: `SELECT * FROM step_signatures WHERE is_semantic_umbrella=1 AND id NOT IN (SELECT parent_id FROM signature_children)`\n3. Verify tree structure makes statistical sense (similar nodes clustered)\n\n## Blocked By\n- mycelium-heh3 (auto-restructure)\n- mycelium-br28 (decision logic)","status":"closed","priority":0,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-27T06:38:14.481473-08:00","created_by":"Bryce Roche","updated_at":"2026-01-27T08:21:16.383921-08:00","closed_at":"2026-01-27T08:21:16.383921-08:00","close_reason":"Root cause addressed through principled branching infrastructure:\n\n1. mycelium-bjrf: Welford stats table (856e3df)\n2. mycelium-xv09: Staging table infrastructure (11fb77d)\n3. mycelium-br28: Welford-based placement decisions (11fb77d)\n4. mycelium-5cn0: Cold start flat structure + blocked umbrella promotions (1f1ee9e)\n5. mycelium-heh3: Auto-restructure with orphan cleanup (06583d2)\n\nOrphan prevention mechanisms:\n- Cold start: No umbrella promotions during first 20 problems\n- Children check: _promote_to_umbrella_internal validates children exist\n- Auto-cleanup: _cleanup_orphan_umbrellas runs every restructure pass\n\nPer CLAUDE.md System Independence: fully automated, no manual tree intervention\nPer CLAUDE.md New Favorite Pattern: single entry points (maybe_restructure, propose_signature)","dependencies":[{"issue_id":"mycelium-obu2","depends_on_id":"mycelium-heh3","type":"blocks","created_at":"2026-01-27T06:38:20.545678-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-obu2","depends_on_id":"mycelium-br28","type":"blocks","created_at":"2026-01-27T06:38:20.647121-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-ocal","title":"Consolidation: Async embedding functions bypass centralized cache","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": All embedding calls should go through a single entry point.\n\nTwo async embedding functions bypass the centralized `embedding_cache.py`:\n\n1. **graph_extractor.py:440** - `embed_computation_graph()` uses `embedding_client.embed()` with its own `_graph_embedding_cache`\n2. **operation_extractor.py:175** - `embed_operation()` uses `embedding_client.embed()` with its own `_operation_embedding_cache`\n\nMeanwhile, sync versions use `cached_embed()` correctly (graph_extractor.py:500).\n\n## Impact\n\n- Duplicate caching logic in 3 places\n- Cache misses between async and sync paths\n- Harder to reason about cache behavior\n\n## Solution\n\nEither:\nA) Add async support to `embedding_cache.py` (`cached_embed_async()`)\nB) Deprecate async embedding paths if unused\n\n## Files to Modify\n\n- src/mycelium/step_signatures/graph_extractor.py\n- src/mycelium/step_signatures/operation_extractor.py\n- src/mycelium/embedding_cache.py (if option A)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:39:33.10857-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:46:33.39997-08:00","closed_at":"2026-01-28T12:46:33.39997-08:00","close_reason":"Removed unused async embedding functions that bypassed centralized cache: embed_computation_graph(), populate_graph_embeddings() from graph_extractor.py; all async functions from operation_extractor.py. All embedding now goes through cached_embed()/cached_embed_batch() per New Favorite Pattern. 369 tests pass."}
{"id":"mycelium-od85","title":"Perf: Execute independent DAG steps in parallel","description":"## Current\nSteps execute sequentially even when independent:\n```python\nfor step in execution_order:\n    result = await self._execute_step(...)  # One at a time\n```\n\n## Proposed\nExecute steps with no unmet dependencies in parallel:\n```python\nwhile remaining_steps:\n    ready = [s for s in remaining if all(d in completed for d in s.depends_on)]\n    results = await asyncio.gather(*[execute_step(s) for s in ready])\n    # ... update completed\n```\n\n## Impact\nFor DAG: A,B → C (A and B independent)\n- Current: A (500ms) → B (500ms) → C = 1000ms+ sequential\n- Parallel: A,B (500ms parallel) → C = 500ms+ total\n\n## Files\n- solver.py: Modify execution loop in solve()\n\n## Notes\nDAG structure already supports this (depends_on tracking).\nJust need to parallelize the execution loop.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T20:17:03.318611-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T20:21:16.191659-08:00","closed_at":"2026-01-15T20:21:16.191659-08:00","close_reason":"Implemented parallel DAG execution with asyncio.gather(). Independent steps now run concurrently. 302 tests pass."}
{"id":"mycelium-ogo6","title":"Track success rates of (DAG plan, Thread) pairs","description":"Track success rates of (DAG plan, Thread) pairs to understand which decomposition strategies work.\n\nCurrently we track:\n- (dag_step_type, node_id) pairs in dag_step_node_stats\n\nWe should also track:\n- (DAG plan structure, Thread outcome) pairs\n- This gives insight into which PLANS work, not just which steps\n- A plan that consistently fails suggests the decomposition strategy is wrong\n- A plan that consistently succeeds suggests good problem structure\n\nImplementation ideas:\n- Hash the DAG structure (step types + dependencies) as plan_signature\n- Track plan_signature → success_rate in new table\n- Use for routing: prefer plans that historically work for similar problems","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-22T20:29:14.934054-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T07:15:16.231392-08:00","closed_at":"2026-01-23T07:15:16.231392-08:00","close_reason":"Implemented plan signature tracking with dag_plan_stats table, compute_plan_signature(), evaluate_proposed_plan(), and integration with grade_dag()"}
{"id":"mycelium-onv4","title":"Big 3: Consolidate stat update functions (New Favorite Pattern)","description":"Per CLAUDE.md 'New Favorite Pattern': Consolidate methods.\n\n## Problem\nMultiple stat update functions in db.py:\n- increment_signature_stat() - generic\n- increment_signature_successes() - specific wrapper (deprecated)\n- increment_signature_failures() - specific wrapper (deprecated)\n- increment_signature_partial_success() - partial credit\n\nCallers must know which function to call.\n\n## Solution\nSingle `record_signature_outcome(signature_id, outcome: SignatureOutcome)` that:\n- Uses SignatureOutcome enum (SUCCESS, FAILURE, PARTIAL)\n- Records to DB\n- Updates Welford stats\n- Propagates credit up tree\n- Handles all side effects\n\nNote: increment_signature_stat() with SignatureStat enum is a step in this direction but wrapper functions still exist.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T14:16:39.182048-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T14:28:09.188264-08:00","closed_at":"2026-01-28T14:28:09.188264-08:00","close_reason":"Already consolidated. increment_signature_stat() with SignatureStat enum is the single entry point. All callers in mcts.py use it directly with SignatureStat.SUCCESS/FAILURE. Deprecated wrappers exist but have no callers. The naming (increment_signature_stat vs record_signature_outcome) is a cosmetic difference - functionality is identical."}
{"id":"mycelium-oy9","title":"[TEST] Missing test coverage for council_v2 synthesis code paths","description":"## Problem\nThe tests in `tests/test_integration.py` and `tests/test_synthesis_strategy.py` do not actually exercise the synthesis code paths (`_once_at_end_synthesize` and `_incremental_synthesize`). All tests mock the LLM responses at a higher level, so the actual synthesis prompt formatting is never tested.\n\n## Impact\nThe undefined variable bug (FINAL_SYNTHESIZER) has gone undetected because tests don't execute the actual synthesis code.\n\n## Suggested Fix\nAdd integration tests that:\n1. Actually exercise `_once_at_end_synthesize()` with step results\n2. Test `_incremental_synthesize()` with a complex DAG that triggers incremental mode (depth\u003e=4, width\u003e=3)\n3. Verify the synthesized answers are properly formatted\n\n## Files to Update\n- tests/test_integration.py - Add tests for synthesis paths\n- tests/test_synthesis_strategy.py - Add tests that go beyond DAGMetrics testing","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:20:36.624323-08:00","updated_at":"2026-01-09T08:34:39.100016-08:00","closed_at":"2026-01-09T08:34:39.100016-08:00"}
{"id":"mycelium-p1bk","title":"Big 3: Move cluster threshold magic numbers to config","description":"Per CLAUDE.md 'The Flow': Multiple hardcoded values in clustering logic.\n\n**Violations in db.py:10295-10310**:\n- `0.1` - CV threshold for method choice (line 10296)\n- `2.0` - Std multiplier for Welford (line 10298)\n- `0.03` - Percentile hardcoded (line 10304)\n- `0.85, 0.95` - Clamp bounds (line 10309)\n\n**Fix**: Add to config.py:\n```python\nADAPTIVE_CLUSTER_CV_THRESHOLD = 0.1\nADAPTIVE_CLUSTER_STD_MULTIPLIER = 2.0\nADAPTIVE_CLUSTER_PERCENTILE = 0.03\nADAPTIVE_CLUSTER_MIN = 0.85\nADAPTIVE_CLUSTER_MAX = 0.95\n```","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:31.390557-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T06:12:47.271327-08:00","closed_at":"2026-01-29T06:12:47.271327-08:00","close_reason":"Already resolved: compute_cluster_threshold() at db.py:463 uses config constants (CLUSTER_THRESHOLD_CV_CUTOFF, etc. from config.py:90-95). Both callers at lines 9054 and 10354 use this consolidated function. No hardcoded magic numbers remain."}
{"id":"mycelium-p6qu","title":"Test: Add unit tests for semantic_validation.py","description":"New module created today lacks test coverage. Need tests for:\n- validate_plan_coherence() with various plan structures\n- _validate_step_inputs() edge cases\n- _generate_planner_feedback() output formatting\n- create_failure_feedback() with/without signature\n- StepFailureFeedback.to_planner_hint() formatting\n\nReference: src/mycelium/step_signatures/semantic_validation.py (257 lines)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:19:44.365418-08:00","updated_at":"2026-01-14T06:23:05.523089-08:00","closed_at":"2026-01-14T06:23:05.523089-08:00"}
{"id":"mycelium-p75","title":"Consolidate configuration with pydantic validation","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:53:56.27705-08:00","updated_at":"2026-01-09T06:07:13.48607-08:00","closed_at":"2026-01-09T06:07:13.48607-08:00"}
{"id":"mycelium-p9c6","title":"Fix post-mortem 2x2 matrix: high conf + won should be biggest boost","description":"## Problem\nCurrent amplitude_post multipliers are backwards:\n- Won + high conf: ×1.1 (small boost)\n- Won + low conf: ×1.4 (bigger boost) ← THIS IS WRONG\n\nHigh confidence + won should be the biggest reinforcement signal - we were confident AND right.\nLow confidence + won is luck/exploration, should be smaller boost.\n\n## Current Config\n```python\nPOSTMORTEM_REINFORCE_MULT = 1.1  # Won + high confidence\nPOSTMORTEM_BOOST_MULT = 1.4      # Won + low confidence\n```\n\n## Proposed Fix\n```python\nPOSTMORTEM_REINFORCE_MULT = 1.4  # Won + high confidence (biggest boost)\nPOSTMORTEM_BOOST_MULT = 1.1      # Won + low confidence (smaller boost)\n```\n\n## Location\n- src/mycelium/config.py (lines 447-448)\n- src/mycelium/data_layer/mcts.py (run_postmortem function)","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T07:10:47.333708-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T07:12:56.17704-08:00","closed_at":"2026-01-25T07:12:56.17704-08:00","close_reason":"Fixed in commit 666ef17 - swapped REINFORCE_MULT and BOOST_MULT"}
{"id":"mycelium-pd3a","title":"Audit: Review cold-start threshold ramp vs 'same threshold at all levels'","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:01:06.441516-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:11:51.032523-08:00","closed_at":"2026-01-15T09:11:51.032523-08:00","close_reason":"Marked closed per user request"}
{"id":"mycelium-pgtd","title":"Feature: Add algebra/backwards-solving support","description":"## Problem\n\nCurrently the system only supports **forward computation** (given all inputs, compute output). Many math problems require **backwards solving** (given result, find unknown input).\n\n## Evidence\n\nFrom DSL failure investigation (2026-01-23):\n- Vacuum cleaners problem: \"She sold a third... If there are 5 left, how many did she start with?\"\n- Planner correctly identifies unknowns as `null`:\n  ```json\n  \"values\": {\n    \"initial_vacuums\": null,  // Unknown - needs solving\n    \"vacuums_left\": 5         // Known\n  }\n  ```\n- Our DSL can't handle `null` values or solve for unknowns\n\n## Impact\n\n- ~20% accuracy gap between our system (70%) and baseline LLM (90%) on GSM8K\n- MATH dataset problems are even more algebra-heavy\n\n## Potential Approaches\n\n1. **Symbolic algebra layer**: Use SymPy to solve equations with unknowns\n2. **Equation DSL**: New DSL type that represents equations, not just expressions\n3. **LLM fallback for algebra**: Detect algebra problems and route to LLM reasoning\n4. **Reverse operation inference**: If we know output and some inputs, infer the missing input\n\n## Acceptance Criteria\n\n- [ ] System can detect when a problem requires backwards solving\n- [ ] System can solve simple algebra (find x where x/3 + 2 + (x-x/3-2)/2 = 5)\n- [ ] Accuracy on GSM8K improves to \u003e85%","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T16:47:37.273836-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T17:10:59.218881-08:00","closed_at":"2026-01-23T17:10:59.218881-08:00","close_reason":"Implemented algebra/backwards-solving support: 1) Added SymPy layer (sympy_layer.py), 2) Added DSLLayer.SYMPY enum, 3) Integrated into executor, 4) Added requires_algebra flag to Step, 5) Added algebra routing in solver. GSM8K accuracy improved from 70% to 80%."}
{"id":"mycelium-ph4","title":"Lift tracking wrong for superposition runs","description":"Injected usage gets recorded as non-injected and skews lift gating/reliability over time.\n\nLocations:\n- council_v2.py (line 897)\n- step_signatures.py (line 1842)\n\nWhen superposition is used, the usage tracking may not correctly flag steps as 'injected', causing:\n1. Lift calculations to be incorrect (comparing injected vs non-injected)\n2. Reliability thresholds to be skewed over time\n3. Gating decisions based on faulty data","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:13:31.460108-08:00","updated_at":"2026-01-08T13:17:03.715943-08:00","closed_at":"2026-01-08T13:17:03.715943-08:00"}
{"id":"mycelium-pl5c","title":"Refactor: Make graph routing PRIMARY, text as fallback","description":"## Problem\n\nGraph routing finds operationally identical signatures but text routing ignores it and creates new signatures anyway.\n\n**Observed behavior:**\n- Graph routing: Found `SUB(p0,p1)` with 94.6% similarity\n- Text routing: Created NEW signature anyway (vocabulary mismatch)\n\n**Current architecture (backwards):**\n```\nText routing → candidates → graph boost (too late)\n```\n\nThe \"boost\" only applies AFTER text routing selects candidates. If text creates NEW, graph signal is wasted.\n\n## Proposed Solution\n\nMake graph routing PRIMARY:\n```\nGraph routing → match by operation → text as tiebreaker\n```\n\n### Options to Consider\n\n1. **Graph-first routing**: Route by computation graph first, use text only when graph doesn't match\n2. **Unified score**: Blend text + graph similarity into single score BEFORE match/create decision  \n3. **Adaptive threshold**: If graph finds 90%+ match, lower text similarity threshold to match\n\n## Why This Matters\n\nPer CLAUDE.md: \"embedding clusters by vocab not operational semantics\" is a known problem.\nGraph embeddings capture operational semantics (what operations DO), which is what we care about.\nCurrently this signal is being ignored for the critical match-vs-create decision.\n\n## Acceptance Criteria\n\n- [ ] Graph routing influences match/create decision (not just boost)\n- [ ] Operationally identical steps match even with different vocabulary\n- [ ] No regression in accuracy on GSM8K","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T10:00:55.687804-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T10:06:58.548801-08:00","closed_at":"2026-01-23T10:06:58.548801-08:00","close_reason":"Implemented graph-first routing. Graph routing now checks FIRST before text routing - high-confidence matches (≥90%) used directly. Verified: 6 GRAPH-FIRST matches in 5-problem test."}
{"id":"mycelium-plm8","title":"Credit/blame for single-path problems (no interference)","description":"Currently interference detection only triggers when multiple threads visit the same (dag_step, node). For single-path problems, no structured credit/blame is assigned.\n\nGap: Single-thread problems bypass the interference-based learning entirely.\n\nImplementation:\n1. After postmortem, even for single-thread DAGs:\n   - Identify high-conf-wrong steps → increment operational_failures\n   - Identify low-conf-right steps → increment successes\n2. Don't require multiple threads for credit assignment\n3. Use amplitude_post directly: amp_post \u003e 1.0 = credit, amp_post \u003c 0.7 = blame\n\nThis ensures every problem contributes to signature learning, not just multi-path ones.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T06:25:27.360001-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T06:33:44.072789-08:00","closed_at":"2026-01-21T06:33:44.072789-08:00","close_reason":"propagate_amplitude_to_signature_stats works for both single-path and multi-path problems - queries by node_id regardless of thread count","dependencies":[{"issue_id":"mycelium-plm8","depends_on_id":"mycelium-itkn","type":"blocks","created_at":"2026-01-21T06:25:32.965077-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-por","title":"[IMPROVE] Duplicate prompt templates in prompt_templates.py and council_v1.py","description":"## Issue\nThere is significant duplication of prompt templates:\n\n1. **prompt_templates.py** has templates registered as 'final_synthesizer' and 'incremental_synthesizer'\n2. **_archive/council_v1.py** has the same templates as module-level constants `FINAL_SYNTHESIZER` and `INCREMENTAL_SYNTHESIZER`\n\nThis creates maintenance burden - if templates need to be updated, they exist in multiple places.\n\n## Current State\n- council_v2.py uses the undefined constants (bug already filed)\n- The prompt_templates.py registry is the preferred approach\n\n## Suggested Fix\n1. Remove hardcoded templates from council_v1.py (if still needed, make it import from registry)\n2. Update council_v2.py to use the registry (already suggested in bug fix)\n3. Centralize all templates in prompt_templates.py\n\n## Files Affected\n- src/mycelium/prompt_templates.py (source of truth)\n- src/mycelium/_archive/council_v1.py (has duplicates)\n- src/mycelium/council_v2.py (needs to use registry)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:28.949573-08:00","updated_at":"2026-01-09T08:32:15.966635-08:00","closed_at":"2026-01-09T08:32:15.966635-08:00"}
{"id":"mycelium-pot","title":"Add cross-signature relationships","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-08T12:24:41.887833-08:00","updated_at":"2026-01-08T13:14:43.478541-08:00","closed_at":"2026-01-08T13:14:43.478541-08:00"}
{"id":"mycelium-ppb6","title":"Consolidate centroid propagation pathways","description":"## Problem\nTwo parallel centroid propagation systems in src/mycelium/step_signatures/db.py with ~200 lines of nearly identical logic:\n\n- `propagate_centroid_to_parents()` (line ~824) - text centroid propagation\n- `propagate_graph_centroid_to_parents()` (line ~989) - graph_embedding propagation\n\nBoth do:\n1. Recursive CTE to fetch all ancestors (same pattern)\n2. Fetch children's embeddings\n3. Compute weighted average\n4. Batch update all ancestors\n5. Invalidate caches per ancestor\n\n## Note\n**Lower priority** - text centroids are being phased out in favor of graph embeddings. This may become moot if text centroids are fully removed.\n\n## Pattern to Follow\nSee how we just consolidated graph_centroid updates to use single `propagate_graph_centroid_to_parents()` with `include_self` parameter.\n\n## Proposed Solution (if text centroids stay)\nCreate unified internal function:\n```python\ndef _propagate_embedding_to_parents(\n    self,\n    conn,\n    signature_id: int,\n    embedding_type: str,  # 'text' or 'graph'\n    include_self: bool = False,\n):\n    '''Single pathway for propagating any embedding type up the hierarchy.'''\n```\n\nThen both functions become thin wrappers.\n\n## Acceptance Criteria\n- [ ] Decide if text centroids are staying or being removed\n- [ ] If staying: Single internal function handles both embedding types\n- [ ] If removed: Delete text centroid propagation code entirely\n- [ ] Parent propagation logic exists in exactly one place\n- [ ] Routing behavior unchanged","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:08:42.732891-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:52:29.613197-08:00","closed_at":"2026-01-25T08:52:29.613197-08:00","close_reason":"Consolidated centroid propagation: text centroid propagation removed, routing now uses graph_embedding exclusively. Commit 856ebfc."}
{"id":"mycelium-pq5","title":"Ablation study: Essence-based matching evaluation","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T10:58:47.222043-08:00","updated_at":"2026-01-08T11:16:06.669525-08:00","closed_at":"2026-01-08T11:16:06.669525-08:00"}
{"id":"mycelium-pwa","title":"HIGH: Add type hints to step_signatures.py DB methods","description":"Functions returning Any or missing return type hints: _get_connection(), _execute(), several callback functions. Add explicit types: sqlite3.Connection, sqlite3.Cursor, proper return types.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:21:47.166681-08:00","updated_at":"2026-01-09T08:27:24.898521-08:00","closed_at":"2026-01-09T08:27:24.898521-08:00"}
{"id":"mycelium-pwdi","title":"Task: Move hardcoded magic numbers to config.py (per CLAUDE.md)","description":"Per CLAUDE.md:119 'Move all magic numbers to config'. Currently hardcoded in solver.py: BIGBANG_SIGNATURE_THRESHOLD=500 (line 61), BIGBANG_MIN_DEPTH=3 (line 62), BIGBANG_DECAY_PER_100_SIGS=0.15 (line 63), MAX_DECOMPOSE_RECURSION=5 (line 1443). Also EMBEDDING_DIM=768 defined in 3 places. Fix: Centralize all constants in config.py.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:31:18.65926-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.194397-08:00","closed_at":"2026-01-20T18:00:01.194397-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-qan0","title":"Bug: Empty string handling in extraction steps in solver.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:01.0895-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:21:49.515706-08:00","closed_at":"2026-01-15T05:21:49.515706-08:00","close_reason":"Added empty string check to extraction step handling in solver.py - now skips empty strings and logs non-numeric string values instead of silently failing"}
{"id":"mycelium-qap4","title":"Feature: Add metrics/instrumentation for monitoring","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-13T11:35:00.112934-08:00","updated_at":"2026-01-20T17:50:06.53066-08:00","closed_at":"2026-01-20T17:50:06.53066-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-qerj","title":"Feature: Recursive DAG of DAGs for step plans","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-12T15:11:32.561367-08:00","updated_at":"2026-01-12T15:15:58.804648-08:00","closed_at":"2026-01-12T15:15:58.804648-08:00"}
{"id":"mycelium-qjk3","title":"Big 3: Direct DB access in solver.py bypasses data layer","description":"Per CLAUDE.md 'System Independence': solver.py:124 has direct SQL query.\n\n```python\nwith db.connection() as conn:\n    count = conn.execute(\"SELECT COUNT(*) FROM step_signatures\").fetchone()[0]\n```\n\n**Fix**: Use `step_db.get_signature_count()` instead of direct query.","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:25.378829-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T05:57:54.830185-08:00","closed_at":"2026-01-29T05:57:54.830185-08:00","close_reason":"Replaced direct SQL query with step_db.get_signature_count() per New Favorite Pattern. Updated tests to mock the correct module."}
{"id":"mycelium-qn2u","title":"Bug: Exploration thread outcomes not recorded with correct success value","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T09:50:44.559737-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T17:02:09.968236-08:00","closed_at":"2026-01-26T17:02:09.968236-08:00","close_reason":"Fixed: Propagate final_answer to ALL threads, not just root thread. Fork threads were incorrectly getting step results instead of problem answers."}
{"id":"mycelium-qnx9","title":"Implement GTS beam search decoding for inference","description":"The GTS model loads successfully but generate() returns placeholder. Need to implement:\n1. Tree-structured beam search (GTS uses goal-driven tree generation)\n2. Token-by-token prefix output (operators then operands)\n3. Integration with output vocabulary (out_idx2symbol)\n\nModel architecture is working:\n- Encoder: BiLSTM\n- Decoder: Tree-structured decoder with goal vectors\n- Beam size: 5 (from config)\n\nCurrent state:\n- encode() works\n- generate() returns placeholder\n- decompose_from_prefix() works (for testing with known prefixes)\n\nThis blocks full GTS decomposition - all GSM8K problems fail at decomposition step.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T12:55:55.290942-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T13:14:09.610243-08:00","closed_at":"2026-01-29T13:14:09.610243-08:00","close_reason":"Implemented in v2.0.4: beam search with joint scoring, operator boost, and NUM reference post-processing. Model works but has limitations (MAWPS training bias)."}
{"id":"mycelium-qsyp","title":"Centroid merge/split from interference patterns","description":"Implement structural tree changes driven by interference:\n\nMERGE (constructive interference):\n- Detect nodes with high co-occurrence in successful threads\n- If centroids are close AND both succeed consistently → merge into single node\n- Per ideas.md line 55: 'brainstorm how do we cleanly merge centroids that are too close'\n\nSPLIT (destructive interference):  \n- Detect nodes with mixed results at same dag_step\n- High variance in success rate for (dag_step, node) → signal to decompose\n- Cluster is too generic, needs finer-grained routing\n\nThis connects wave function amplitude to tree structure evolution.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:14:01.979874-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T17:05:43.551162-08:00","closed_at":"2026-01-20T17:05:43.551162-08:00","close_reason":"Implemented merge/split coordination from interference patterns. Merges consolidate operationally equivalent signatures, splits flag generic clusters for decomposition.","dependencies":[{"issue_id":"mycelium-qsyp","depends_on_id":"mycelium-zxzm","type":"blocks","created_at":"2026-01-20T14:14:09.617578-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-qx8x","title":"P2: Make min_similarity Welford-adaptive instead of static 0.85","description":"## Problem\n\nPer CLAUDE.md \"The Flow\": \"Database Statistics → Welford → Tree Structure. Welford variance guides all structural decisions.\"\n\nMultiple methods have hardcoded `min_similarity: float = 0.85` defaults that ignore the Welford-adaptive capability the system already has.\n\n## Current State (db.py)\n\nLines with static `min_similarity = 0.85`:\n- Line 991: `find_best_match()`\n- Line 1152: `find_similar_signatures()`\n- Line 1184: `find_deeper_signature()`\n- Line 1233: `find_or_create()`\n- Line 1298: `find_or_create_async()`\n- Line 3004: `get_routing_candidates()`\n\n## Why This Is a Problem\n\n- System has Welford stats tracking similarity distributions\n- Static threshold ignores learned variance\n- Early in system lifetime, 0.85 may be too strict (cold start)\n- Later, 0.85 may be too loose (mature system with tighter clusters)\n\n## Solution\n\nReplace static defaults with Welford-adaptive thresholds:\n\n```python\ndef _get_adaptive_similarity_threshold(\n    self,\n    context: str = \"routing\",\n    fallback: float = None,\n) -\u003e float:\n    \"\"\"Get Welford-adaptive similarity threshold.\n    \n    Per CLAUDE.md \"The Flow\": Thresholds from database statistics.\n    \n    Args:\n        context: Which threshold context (routing, matching, etc.)\n        fallback: Fallback if insufficient data (default from config)\n    \"\"\"\n    from mycelium.config import ROUTING_MIN_SIMILARITY\n    fallback = fallback or ROUTING_MIN_SIMILARITY\n    \n    # Get Welford stats for this context\n    stats = get_state_manager().get_welford_stats(f\"similarity_{context}\")\n    \n    # Need sufficient samples for reliable estimate\n    if not stats or stats.n \u003c 50:\n        return fallback\n    \n    # Adaptive: mean - 1.5 * std (captures ~93% of good matches)\n    # But never go below 0.70 or above 0.95\n    adaptive = stats.mean - 1.5 * stats.std\n    return max(0.70, min(0.95, adaptive))\n\n\n# Usage in find_or_create:\ndef find_or_create(\n    self,\n    step_type: str,\n    description: str,\n    *,\n    min_similarity: float = None,  # None = use adaptive\n    ...\n) -\u003e StepSignature:\n    if min_similarity is None:\n        min_similarity = self._get_adaptive_similarity_threshold(\"routing\")\n    ...\n```\n\n## Implementation Steps\n\n1. Add `_get_adaptive_similarity_threshold()` helper to StepSignatureDB\n2. Record similarity observations to Welford stats during routing\n3. Update all methods to use `min_similarity = None` default\n4. Replace static 0.85 with adaptive lookup when None\n5. Add config fallbacks: `ROUTING_MIN_SIMILARITY = 0.85` etc.\n6. Test with fresh DB (cold start) and mature DB\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/db.py` - Add adaptive helper, update methods\n- `src/mycelium/config.py` - Add fallback constants\n- `src/mycelium/data_layer/state_manager.py` - May need new Welford keys\n\n## Recording Similarity Stats\n\nNeed to record similarity observations for Welford:\n```python\n# In routing code, after computing similarity:\nget_state_manager().update_welford(\"similarity_routing\", similarity_score)\n```\n\n## Testing\n\n- Verify cold start uses fallback (0.85)\n- Verify mature system adapts threshold\n- Verify thresholds stay in reasonable range (0.70-0.95)\n\n## Context\n\nP2 priority per Big 3 audit - The Flow violation.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:51:43.274518-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:23:41.90373-08:00","closed_at":"2026-01-28T13:23:41.90373-08:00","close_reason":"Implemented Welford-adaptive similarity thresholds per The Flow principle"}
{"id":"mycelium-r16","title":"Move magic numbers to config file","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T12:23:53.408235-08:00","updated_at":"2026-01-09T10:45:17.026712-08:00","closed_at":"2026-01-09T10:45:17.026712-08:00"}
{"id":"mycelium-rj2","title":"Vectorized similarity computations for 5-17x speedup","description":"Replaced O(n) python loops with vectorized numpy matrix operations across key similarity functions:\n\n**Performance gains (500 signatures, 384-dim embeddings):**\n- find_similar(): 1.99ms → 0.35ms (5.6x speedup)\n- compute_resonance(): 7.47ms → 0.45ms (16.7x speedup)  \n- compute_interference_scores_batch(): 6.23ms → 4.98ms (1.3x speedup)\n- suggest_cluster_merges(): O(n²) loops → O(n²) numpy (~10x speedup)\n\n**New batch functions added:**\n- cosine_similarity_batch(query, matrix) - vectorized 1-to-many similarity\n- cosine_similarity_batch_essence(query, matrix, essence_dims) - essence subspace variant\n\n**Key techniques:**\n1. Stack centroids into matrix, compute all similarities via single @ operation\n2. Vectorized normalization with np.linalg.norm(matrix, axis=1)\n3. Numpy broadcasting for element-wise ops (gaussian, phase_factor)\n4. Pre-filtering with np.where(mask) instead of python conditionals\n\nCommits: e5d1443, and integrated into compute_resonance/suggest_cluster_merges","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T12:56:29.565383-08:00","updated_at":"2026-01-08T12:56:43.615682-08:00","closed_at":"2026-01-08T12:56:43.615682-08:00"}
{"id":"mycelium-rpin","title":"Bug: Race condition on child.centroid None check in db.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:30.67595-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:17:11.006087-08:00","closed_at":"2026-01-15T05:17:11.006087-08:00","close_reason":"Fixed TOCTOU race condition by capturing centroid value once before check and use. Fixed 8 locations across solver.py and step_signatures/db.py"}
{"id":"mycelium-rqys","title":"Modify mathdecomp schema: remove op enum, use func string","description":"## Goal\nSimplify `src/mycelium/mathdecomp/schema.py` to use function registry keys instead of predefined operators.\n\n## Changes to Step dataclass\n\n### Before\n```python\nclass Operator(str, Enum):\n    ADD = \"+\"\n    SUB = \"-\"\n    MUL = \"*\"\n    DIV = \"/\"\n\n@dataclass\nclass Step:\n    op: Operator\n    left: Ref\n    right: Ref\n```\n\n### After\n```python\n@dataclass\nclass Step:\n    id: str\n    func: str              # Key into FUNCTION_REGISTRY (e.g., \"add\", \"mul\", \"sqrt\")\n    inputs: List[Ref]      # Flexible arity (1 for sqrt, 2 for add, etc.)\n    result: Optional[float]\n    semantic: str\n```\n\n## Also Update\n- Remove `Operator` enum entirely\n- Update `Decomposition` class if needed\n- Update JSON serialization/deserialization\n\n## Acceptance Criteria\n- [ ] No hardcoded operator enum\n- [ ] Steps use func: str pointing to registry\n- [ ] inputs: List[Ref] for flexible arity\n- [ ] All tests updated","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:53:21.179226-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:04:15.000841-08:00","closed_at":"2026-01-31T06:04:15.000841-08:00","close_reason":"Schema updated: removed Operator enum, added func+inputs to Step","dependencies":[{"issue_id":"mycelium-rqys","depends_on_id":"mycelium-icv4","type":"blocks","created_at":"2026-01-31T05:54:32.72151-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-rwvb","title":"P1: Consolidate 5 signature creation pathways to single entry point","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": We have 5 different entry points for creating/finding signatures, violating the consolidation principle.\n\n## Current State (db.py)\n\n1. `find_or_create()` - Line 1229, public sync method\n2. `find_or_create_async()` - Line 1294, async wrapper\n3. `create_signature()` - Line 1373, routes through propose_signature()\n4. `_find_or_create_atomic()` - Line 1425, internal variant\n5. `_create_signature_atomic()` - Line 2088, another internal variant\n\n## Why This Is a Problem\n\n- Inconsistent behavior across pathways\n- Maintenance burden (changes must be made in multiple places)\n- Hard to ensure all paths apply same logic:\n  - Welford-based placement decisions\n  - Deduplication checks\n  - Parent/child relationship rules\n  - Graph embedding generation\n\n## Solution\n\nConsolidate to ONE core function with clear internal helpers:\n\n```python\ndef create_or_find_signature(\n    self,\n    step_type: str,\n    description: str,\n    *,\n    parent_id: Optional[int] = None,\n    min_similarity: float = None,  # None = use Welford-adaptive\n    async_mode: bool = False,\n) -\u003e StepSignature:\n    \"\"\"Single entry point for all signature creation/finding.\n    \n    Per CLAUDE.md \"New Favorite Pattern\": Consolidated pathway.\n    \"\"\"\n    # 1. Normalize inputs\n    # 2. Check deduplication (graph embedding similarity)\n    # 3. Find existing OR create new (atomic)\n    # 4. Apply Welford-guided placement if creating\n    # 5. Return result\n```\n\n## Implementation Steps\n\n1. Read all 5 current implementations to understand differences\n2. Identify the superset of all functionality\n3. Create unified `create_or_find_signature()` with all features\n4. Update all callers to use the new function\n5. Deprecate old functions (keep as thin wrappers initially)\n6. Run full test suite\n7. Remove deprecated wrappers in follow-up PR\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/db.py` - Main consolidation\n- Any callers of the 5 functions (search for usage)\n\n## Testing\n\n- All existing tests must pass\n- Add test verifying single pathway behavior\n- Verify Welford-adaptive thresholds work through consolidated path\n\n## Context\n\nThis is a P1 priority per Big 3 audit. Other Claude instances can pick this up.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:50:02.62957-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:13:48.24441-08:00","closed_at":"2026-01-28T13:13:48.24441-08:00","close_reason":"Already implemented. Code at lines 1239-1257 documents consolidated pattern: public APIs (find_or_create, find_or_create_async, create_signature) → propose_signature() → _create_signature_atomic(). All internal methods encapsulated within db.py. No external callers bypass the consolidated pathway."}
{"id":"mycelium-rxu8","title":"Reactive MCTS exploration on failure","description":"When a thread gets the wrong answer, trigger post-hoc MCTS exploration to find what WOULD have worked, then compare divergence points for precise blame.\n\n## Current Behavior\n- Only branch proactively when UCB1 gap is low (uncertain)\n- If confident but WRONG, no exploration of alternatives\n- Blame based on amplitude, not actual divergence\n\n## Proposed Behavior\n1. Thread A executes, gets wrong answer\n2. Trigger wider exploration:\n   - For each dag_step, try alternative leaf_nodes\n   - Execute alternatives to find Thread B that succeeds\n3. Compare Thread A vs Thread B:\n   - Find first divergence point (step where node choices differ)\n   - That's the root cause\n4. Credit/blame:\n   - Credit the node that led to correct answer\n   - Blame the node that led to wrong answer\n   - Steps AFTER divergence get neutral (input was already wrong)\n\n## Why Order Matters\nThread A: step_1→node_X (50) → step_2→node_Y (uses 50→200) WRONG\nThread B: step_1→node_Z (100) → step_2→node_Y (uses 100→400) RIGHT\n\nDivergence at step_1: node_X wrong, node_Z right\nstep_2 used same node_Y - not the problem, INPUT was wrong\n\n## Implementation Ideas\n- Add retry_with_alternatives() after grading fails\n- Limit exploration depth/breadth for compute budget\n- Store all thread paths for comparison\n- Use find_divergence_points() (already exists in mcts.py)","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T05:53:51.761034-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T06:09:46.821046-08:00","closed_at":"2026-01-23T06:09:46.821046-08:00","close_reason":"Implemented reactive MCTS exploration: retry_with_alternatives(), divergence analysis, and pipeline hook"}
{"id":"mycelium-ryi","title":"Create mushroom_math project with best research for arXiv paper","description":"Write the arXiv paper for Mycelium.\n\n**Location**: ~/Desktop/mycelium/paper.md\n\n## Core Analogy\n\n**Prime Factorization of Math Problems**: Just as composite numbers can be factored into their unique prime components, complex math problems can be decomposed into reusable atomic signatures. The signature embedding DB acts as the \"table of primes\" - a finite set of fundamental solution patterns that combine to solve infinite problem variations.\n\n## Components\n\n1. **Problem Decomposition** - Factor problems into atomic steps (DAG structure with dependencies)\n2. **Signature Embedding DB** - Vector store of \"prime\" solution patterns\n3. **Cosine Similarity Matching** - Find which known signatures apply to new steps\n4. **Hybrid DSL Execution** - Route steps to formula/code/LLM based on type\n5. **Final Merge Solver** - Synthesize atomic results into complete answer\n\n*Supporting concepts:*\n- Step-level reusability (steps reusable across problems, whole problems aren't)\n- Learning loop (reliability threshold, outcome tracking, inject vs solve fresh)\n\n## Delegated Tasks (dependencies)\n\n- mycelium-1hg: Run experiments, fill Table 1\n- mycelium-aj5: Step-level vs problem-level analysis\n- mycelium-3d5: Signature growth analysis\n- mycelium-cq5: Reliability threshold ablation\n- mycelium-dt9: Architecture diagram\n\n## My Responsibilities\n\n- Own the paper structure and narrative\n- Integrate results from delegated tasks\n- Polish writing and ensure coherence\n- Final edits and submission prep","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T08:52:29.696274-08:00","updated_at":"2026-01-20T17:54:36.141515-08:00","closed_at":"2026-01-20T17:54:36.141515-08:00","close_reason":"Stale - Jan 9, deprioritizing","dependencies":[{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-1hg","type":"blocks","created_at":"2026-01-09T09:43:08.939092-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-aj5","type":"blocks","created_at":"2026-01-09T09:43:08.988596-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-3d5","type":"blocks","created_at":"2026-01-09T09:43:09.037447-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-cq5","type":"blocks","created_at":"2026-01-09T09:43:09.085844-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-ryi","depends_on_id":"mycelium-dt9","type":"blocks","created_at":"2026-01-09T09:43:09.134719-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-s2uz","title":"Integrate GTSDecomposer with Solver","description":"## Context\nPer CLAUDE.md Big 5 #4 (True Atomic Decomposition), replace/augment LLM segmentation with GTS-based decomposition.\n\n## Dependencies\n- Depends on: mycelium-yhlj (ExprNode)\n- Depends on: mycelium-1c45 (GTSDecomposer)\n\n## Goal\nIntegrate GTS decomposition into the existing Solver flow so that:\n1. Problem comes in\n2. GTS decomposes to atomic steps\n3. Each step is embedded and routed through tree\n4. Results are combined\n\n## Current Flow (solver.py)\n```\nProblem -\u003e LLM Segmentation -\u003e DAGPlan -\u003e Route Steps -\u003e Execute -\u003e Combine\n```\n\n## New Flow\n```\nProblem -\u003e GTSDecomposer -\u003e Atomic Steps -\u003e DAGPlan -\u003e Route Steps -\u003e Execute -\u003e Combine\n```\n\n## Implementation\n\nModify `src/mycelium/solver.py`:\n\n```python\nclass Solver:\n    def __init__(self, ...):\n        # Add GTS decomposer\n        self.decomposer = GTSDecomposer()\n    \n    async def solve(self, problem: str) -\u003e SolverResult:\n        # Step 1: GTS decomposition (replaces LLM segmentation)\n        atomic_steps = self.decomposer.decompose(problem)\n        \n        # Step 2: Convert to DAGPlan format\n        dag_steps = []\n        for i, step in enumerate(atomic_steps):\n            dag_steps.append(Step(\n                id=f's{i+1}',\n                task=step.operation,\n                operation=step.operation,  # For graph embedding\n                depends_on=[f's{d}' for d in step.depends_on],\n                extracted_values=step.extracted_values\n            ))\n        \n        plan = DAGPlan(steps=dag_steps, problem=problem)\n        \n        # Step 3: Existing routing and execution flow\n        return await self._execute_plan(plan)\n```\n\n## Feature Flag\nAdd config option to switch between GTS and LLM segmentation:\n- `USE_GTS_DECOMPOSITION = True` (default for cold start)\n- Allow fallback to LLM if GTS fails\n\n## Tests Required\n- test_solver_with_gts_decomposition\n- test_dag_plan_from_atomic_steps\n- test_step_dependencies_correct\n- test_feature_flag_switching\n\n## Acceptance Criteria\n- [ ] Solver uses GTSDecomposer for problem decomposition\n- [ ] Atomic steps correctly converted to DAGPlan\n- [ ] Dependencies between steps preserved (step_1 result flows to step_2)\n- [ ] Feature flag allows switching decomposition strategy\n- [ ] All existing solver tests still pass","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T12:27:46.582789-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T12:53:05.430456-08:00","closed_at":"2026-01-29T12:53:05.430456-08:00","close_reason":"All implemented with 208 tests passing. Committed in 2b96e5b.","dependencies":[{"issue_id":"mycelium-s2uz","depends_on_id":"mycelium-1c45","type":"blocks","created_at":"2026-01-29T12:27:51.591777-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-s5d7","title":"Feature: Zero-LLM routing - mature tree should route without planner calls","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:01:24.734025-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:27:45.48148-08:00","closed_at":"2026-01-15T09:27:45.48148-08:00","close_reason":"Implemented zero-LLM routing feature. When enabled, solver tries to route problems directly through mature signature tree without calling planner. Requires high similarity (0.90), high success rate (70%), and working DSL. Falls back to planner if conditions not met. Added config options, implementation, and 12 tests."}
{"id":"mycelium-s90y","title":"Implement slow decay: sig_uses / total_problems","description":"Per CLAUDE.md: 'slow decay: sig_uses / total_problems'. Deprioritize signatures that aren't pulling their weight. Enhance existing TRAFFIC_DECAY in scoring.py. ~100 lines.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:38:12.818673-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:41:53.157859-08:00","closed_at":"2026-01-15T09:41:53.157859-08:00","close_reason":"Already implemented: scoring.py has _total_problems_cache with 60s TTL, get_total_problems_solved() caches DB lookups, increment_total_problems() updates cache immediately. compute_traffic_penalty() uses sig_uses/total_problems ratio for slow decay."}
{"id":"mycelium-sctd","title":"High: Centroid averaging race condition with stale fallback","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-13T11:34:39.734013-08:00","updated_at":"2026-01-13T11:46:06.409677-08:00","closed_at":"2026-01-13T11:46:06.409677-08:00"}
{"id":"mycelium-sfw","title":"Planner parsing silently drops steps on dependency issues","description":"planner.py has brittle parsing that silently returns partial execution order when dependencies are malformed or cyclic. Steps can be dropped without surfacing an error. Affected locations: planner.py:57 (dependency parsing), planner.py:118 (execution order). Should either: (1) Raise explicit error on cyclic/malformed dependencies, (2) Log warning when steps are dropped, or (3) Return validation result alongside execution order.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:19:16.872957-08:00","updated_at":"2026-01-08T13:23:09.517902-08:00","closed_at":"2026-01-08T13:23:09.517902-08:00"}
{"id":"mycelium-sgt","title":"Add periodic decay job or hook for signature decoherence","description":"decay_unused_signatures() exists but is never called automatically. Consider: (1) Adding a post-training hook in pipeline_runner to decay after each run, (2) A CLI command 'mycelium decay --dry-run', or (3) Documentation on when/how to run it. Without periodic decay, the decoherence feature has no effect.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T12:15:50.939732-08:00","updated_at":"2026-01-20T17:50:06.188705-08:00","closed_at":"2026-01-20T17:50:06.188705-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-sig","title":"[TEST] Add async test for MCTS simulation with phase constraints","description":"## Issue\nThe MCTS module (mcts.py) has sophisticated phase constraint tracking and simulation logic, but there's limited test coverage for:\n\n1. The MCTS search algorithm with actual async simulation\n2. Phase constraint assignment and score computation during simulation\n3. Cluster-aware priors and reusable solution detection\n4. The MCTSDecomposer end-to-end flow\n\n## Current State\n- test_mcts_clusters.py only tests ClusterInfo and basic functionality\n- No tests for the actual MCTS search loop with phase tracking\n- Phase constraint logic (PhaseAssignment, PhaseScore) tested separately but not integrated with MCTS\n\n## Suggested Tests\nAdd integration tests that:\n1. Run MCTS search with a mock simulation function\n2. Verify phase scores are computed correctly during simulation\n3. Test the backpropagation with phase-adjusted rewards\n4. Verify cluster coverage affects priors appropriately\n\n## Files to Update\n- tests/test_mcts_clusters.py - Extend with async tests","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T08:22:59.690733-08:00","updated_at":"2026-01-09T08:34:39.151614-08:00","closed_at":"2026-01-09T08:34:39.151614-08:00"}
{"id":"mycelium-sqc1","title":"Rich step-level stats for routing decisions","description":"Track per-step execution times, param extraction success, DSL vs decompose ratio. Feed into MCTS routing decisions. Per CLAUDE.md brainstorming: 'db audit for signature step level stats'. ~200 lines in src/mycelium/step_signatures/stats.py","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T09:38:06.014184-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T09:45:13.361512-08:00","closed_at":"2026-01-15T09:45:13.361512-08:00","close_reason":"Implemented stats.py with StepExecution, SignatureStats, RoutingContext dataclasses and StepStatsCollector for tracking per-step execution times, param extraction success, DSL vs decompose ratios. Added routing helpers: compute_routing_bonus, should_prefer_decomposition, get_signature_health. All 21 new tests pass."}
{"id":"mycelium-t3ao","title":"Update solver.py to orchestrate function calls","description":"## Goal\nModify `src/mycelium/solver.py` to execute function calls from registry instead of DSL.\n\n## Changes\n\n### Remove\n- DSL execution logic\n- DSL regeneration logic\n- References to dsl_executor\n\n### Modify\n- `_execute_step()` → call function from registry\n- Step routing → route to func_name instead of dsl_script\n\n### Keep\n- Problem decomposition flow\n- Signature routing via tree\n- Success/failure tracking\n- Post-mortem triggering\n\n## New Flow\n```python\nasync def _execute_step(self, step, context):\n    # 1. Route step to signature (get func_name)\n    signature = self._route_to_signature(step)\n    \n    # 2. Extract arguments from context\n    args = self._extract_args(step, context)\n    \n    # 3. Call function from registry\n    from mycelium.function_registry import call_function\n    result = call_function(signature.func_name, *args)\n    \n    # 4. Record success/failure\n    return StepResult(success=True, value=result)\n```\n\n## Acceptance Criteria\n- [ ] No DSL execution code\n- [ ] Uses function_registry for execution\n- [ ] Maintains routing through signature tree\n- [ ] All stats tracking still works","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-31T05:54:05.402258-08:00","created_by":"Bryce Roche","updated_at":"2026-01-31T06:13:59.6875-08:00","closed_at":"2026-01-31T06:13:59.6875-08:00","close_reason":"Completed in commit 8627d70 - solver uses function_registry, obsolete files removed","dependencies":[{"issue_id":"mycelium-t3ao","depends_on_id":"mycelium-icv4","type":"blocks","created_at":"2026-01-31T05:54:33.333873-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-t3ao","depends_on_id":"mycelium-3pdn","type":"blocks","created_at":"2026-01-31T05:54:33.435983-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-t7gq","title":"Bug: Hardcoded 1s timeout in dsl_executor.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:25.514956-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:26:18.446645-08:00","closed_at":"2026-01-15T05:26:18.446645-08:00","close_reason":"Replaced hardcoded 1.0s timeout with DSL_TIMEOUT_SEC from config.py - timeout is now configurable"}
{"id":"mycelium-t9kh","title":"Wire up mcts_thread_steps amplitude logging","description":"Log each step execution with amplitude. Key fields: amplitude (prior confidence), was_undecided (if branching), ucb1_gap, similarity_score, node_id. This is the core wave function table.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:09.980759-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T14:26:26.586192-08:00","closed_at":"2026-01-20T14:26:26.586192-08:00","close_reason":"Wired up log_thread_step calls in solver.py: (1) Added import for log_thread_step from mcts data layer, (2) Added routing context tracking instance variables (_routing_confidence, _routing_similarity, _routing_ucb1_gap, _routing_was_undecided), (3) Set routing context in _explore_multiple_paths from route_with_confidence result, (4) Log thread steps at end of _execute_step with full amplitude data, (5) Added fork thread step logging in _explore_multiple_paths for multi-path exploration."}
{"id":"mycelium-tgpx","title":"Consolidation: Extract rejection threshold logic to shared utility","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": \"We want to consolidate methods... Same with... leaf_node rejection of dag_steps.\"\n\nLeaf rejection logic is duplicated in solver.py and db.py with nearly identical code.\n\n## Current Behavior\n\n**solver.py:1419-1467**\n```python\nthreshold = best_sig.get_adaptive_rejection_threshold(k=1.5, min_samples=5, default_threshold=0.5)\n# Cold start check at line 1424-1425\nif sig_count \u003c COLD_START_SIGNATURE_THRESHOLD:\n    logger.debug(\"Cold start: skipping rejection...\")\n    return (best_sig, best_sim)\n# Threshold comparison at line 1435\nif best_sim \u003c threshold:\n    record_leaf_rejection(...)\n    return (None, 0.0)\n```\n\n**db.py:1580-1610**\n```python\nthreshold = best_match.get_adaptive_rejection_threshold(k=1.5, min_samples=5, default_threshold=0.5)\n# Cold start check (SAME logic)\nif not self.is_cold_start(conn=c):\n    # Rejection logic (SAME logic, different variable names)\n    if best_sim \u003c threshold:\n        ...\n```\n\nMagic numbers repeated: `k=1.5, min_samples=5, default_threshold=0.5`\n\n## Expected Behavior\n\nSingle utility function for rejection checking:\n\n```python\n# src/mycelium/step_signatures/rejection_utils.py\nfrom dataclasses import dataclass\nfrom mycelium.config import (\n    ADAPTIVE_REJECTION_K,\n    ADAPTIVE_REJECTION_MIN_SAMPLES,\n    ADAPTIVE_REJECTION_DEFAULT_THRESHOLD,\n)\n\n@dataclass\nclass RejectionResult:\n    rejected: bool\n    signature: Optional[StepSignature]\n    similarity: float\n    threshold: float\n    reason: Optional[str] = None\n\ndef check_rejection(\n    signature: StepSignature,\n    similarity: float,\n    is_cold_start: bool,\n    step_db: StepSignatureDB,\n) -\u003e RejectionResult:\n    \"\"\"Unified rejection check per CLAUDE.md New Favorite Pattern.\n    \n    Uses config values for threshold parameters.\n    Records rejection if applicable.\n    \"\"\"\n    if is_cold_start:\n        return RejectionResult(rejected=False, signature=signature, similarity=similarity, threshold=0.0)\n    \n    threshold = signature.get_adaptive_rejection_threshold(\n        k=ADAPTIVE_REJECTION_K,\n        min_samples=ADAPTIVE_REJECTION_MIN_SAMPLES,\n        default_threshold=ADAPTIVE_REJECTION_DEFAULT_THRESHOLD,\n    )\n    \n    if similarity \u003c threshold:\n        record_leaf_rejection(...)\n        return RejectionResult(rejected=True, signature=None, similarity=0.0, threshold=threshold, reason=\"below_threshold\")\n    \n    return RejectionResult(rejected=False, signature=signature, similarity=similarity, threshold=threshold)\n```\n\n## Files to Create/Modify\n\n**New file: `src/mycelium/step_signatures/rejection_utils.py`**\n- `RejectionResult` dataclass\n- `check_rejection()` function\n\n**Modify:**\n- `src/mycelium/solver.py:1419-1467` - Use `check_rejection()`\n- `src/mycelium/step_signatures/db.py:1580-1610` - Use `check_rejection()`\n\n**Config (already exists):**\n- `src/mycelium/config.py:178-183` - ADAPTIVE_REJECTION_* constants\n\n## Testing\n\n1. Create rejection_utils.py with tests\n2. Replace solver.py usage, run tests\n3. Replace db.py usage, run tests\n4. Verify identical behavior\n\n## Context\n\nPart of Consolidation code review. High priority per CLAUDE.md.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:38:31.326479-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:15:22.544711-08:00","closed_at":"2026-01-28T12:15:22.544711-08:00","close_reason":"Implemented: rejection_utils.py with check_rejection() consolidates magic numbers to config values. Updated solver.py and db.py to use unified utility."}
{"id":"mycelium-tlax","title":"Feature: Use graph_embedding for leaf routing, centroid for router routing","description":"Per discussion: routers and leaves should use different embeddings for routing.\n\n**Current state:**\n- Both routers and leaves use centroid for routing\n- graph_embedding exists but isn't used for routing decisions\n\n**Proposed change:**\n```\nif is_semantic_umbrella:\n    compare against centroid (drifts with children)\nelse:  # leaf\n    if graph_embedding exists:\n        compare against graph_embedding (static, operational identity)\n    else:\n        fall back to centroid (cold start)\n```\n\n**Rationale:**\n- Routers cluster semantically - centroid should drift with traffic\n- Leaves are \"math primes\" - their operational identity (MUL, ADD, etc.) is static\n- \"Primes don't drift\" - a multiply operation is always multiply\n\n**Benefits:**\n- Routes to leaves by WHAT THEY DO, not what they sound like\n- Avoids \"vocabulary clustering\" problem\n- Cleaner separation of concerns\n\n**Dependencies:**\n- mycelium-imh6: Leaves need DSL to have graph_embedding\n- mycelium-y96x: DSLs need to be atomic for clean graph_embeddings","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T10:23:42.215924-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T10:47:43.652939-08:00","closed_at":"2026-01-23T10:47:43.652939-08:00","close_reason":"Feature implemented in commit 2118dda: Option B - routers use graph_centroid (avg of children), leaves use graph_embedding. _route_by_graph_hierarchical() does BFS through tree using graph_embeddings. All dependencies resolved.","dependencies":[{"issue_id":"mycelium-tlax","depends_on_id":"mycelium-imh6","type":"blocks","created_at":"2026-01-23T10:23:47.947197-08:00","created_by":"Bryce Roche"},{"issue_id":"mycelium-tlax","depends_on_id":"mycelium-y96x","type":"blocks","created_at":"2026-01-23T10:23:48.020445-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-tnil","title":"System Independence: Refactor reactive exploration to learn from failures","description":"## Problem\n\nPer CLAUDE.md: \"Do not mask failures with LLM fallback. Let DSLs fail, record outcome, and let the refinement loop fix them.\"\n\nReactive exploration (solver.py:4141-4189) spawns multiple parallel re-solves on failure, which masks failures instead of learning from them.\n\n## Current Behavior\n\n```python\n# solver.py:4141-4189\nif REACTIVE_EXPLORATION_FULL_RESOLVE:\n    # Spawn 3 parallel threads with different RNG seeds\n    # Re-solve entire problem up to N times\n    # Keep first correct answer, discard failures\n```\n\nProblems:\n1. **Masks failures**: Just retries with different RNG, doesn't learn what failed\n2. **Fake grading**: Records synthetic grading (line 4174) for cross-DAG comparison\n3. **No decomposition**: Doesn't flag signatures for decomposition\n4. **Manual planner swap**: Replaces planner object with different temperature (lines 4148-4154)\n\n## Expected Behavior\n\nFailures should feed learning, not be masked by retries:\n\n1. **Record what failed**: Track (signature, step_position, failure_type) tuples\n2. **Update Welford stats**: Failed signatures should get exec_* updates\n3. **Trigger decomposition**: Signatures with high failure variance should be flagged\n4. **No retries**: Let the failure stand, system learns from it\n\n## Files to Modify\n\n- `src/mycelium/solver.py:4141-4189` - Remove or refactor `_solve_with_full_exploration`\n- `src/mycelium/config.py:215-222` - Remove REACTIVE_EXPLORATION_* configs\n- `src/mycelium/solver.py:3654-3750` - Refactor `_retry_with_alternatives`\n\n## Alternative Approach\n\nIf retry is truly needed for evaluation:\n1. Record ALL retry paths (not just winning one)\n2. Use post-mortem to compare winning vs losing paths\n3. Feed difference back to Welford stats\n4. This is already done in MCTS - reactive exploration duplicates it\n\n## Testing\n\n1. Disable REACTIVE_EXPLORATION_FULL_RESOLVE\n2. Run on challenging problems (MATH Level 3+)\n3. Verify failures are recorded (check mcts_dags table)\n4. Verify decomposition triggers work (check umbrella promotion)\n\n## Context\n\nPart of System Independence code review. Related to mycelium-02nn.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:37:47.291462-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:17:00.771203-08:00","closed_at":"2026-01-28T12:17:00.771203-08:00","close_reason":"Disabled reactive exploration by default. Per CLAUDE.md 'Let signatures fail' - retries mask failures instead of learning from them. Post-mortem analysis on failing DAG provides learning. Welford stats accumulate from failures and trigger decomposition.","dependencies":[{"issue_id":"mycelium-tnil","depends_on_id":"mycelium-02nn","type":"blocks","created_at":"2026-01-28T11:39:40.853633-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-topu","title":"Test: Add unit tests for dsl_templates.py","description":"Semantic DSL inference lacks test coverage. Need tests for:\n- infer_dsl_for_signature() priority order\n- _infer_dsl_from_values() param extraction\n- _infer_operation_semantic() dual-channel matching\n- _get_param_anchor_embeddings() caching\n- _find_similar_successful_dsl() similarity lookup\n\nReference: src/mycelium/step_signatures/dsl_templates.py (457 lines)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-14T06:19:57.899719-08:00","updated_at":"2026-01-14T06:24:45.743772-08:00","closed_at":"2026-01-14T06:24:45.743772-08:00"}
{"id":"mycelium-tw5n","title":"Bug: embedding_sum and centroid both None case in db.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:49.362344-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:16:58.159077-08:00","closed_at":"2026-01-15T05:16:58.159077-08:00","close_reason":"Fixed double-embedding bug: when both embedding_sum and centroid are None, current_count was set to 0 causing new_embedding to be counted twice (centroid = 2x embedding). Changed to current_count = 1 to match route_step_hierarchical behavior."}
{"id":"mycelium-u0j6","title":"Bug: TOCTOU race condition in centroid routing (db.py:299-300)","description":"In db.py:299-300, centroid is read and then used for cosine_similarity without protection. Another thread could update the centroid between read and use, causing crashes or incorrect routing. Per CLAUDE.md 'routing via MCTS learned from embeddings' - race conditions corrupt the routing decisions. Fix: Capture centroid once in local variable, handle None case explicitly.","status":"closed","priority":0,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:30:53.58088-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T13:39:57.378954-08:00","closed_at":"2026-01-15T13:39:57.378954-08:00","close_reason":"Fixed 3 TOCTOU race conditions in step_signatures/db.py (lines 649, 664, 727). Each now captures centroid in a local variable before the None check to prevent race conditions during routing."}
{"id":"mycelium-u978","title":"System Independence: Remove auto-promotion in divergence.py","description":"divergence.py:176-275 auto-promotes to umbrella and forces parent_id on splits without Welford evaluation. CLOSE_DISTANCE_THRESHOLD=0.20 is hardcoded. Should compute threshold from observed distance distributions.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:00:42.104263-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:06:26.832119-08:00","closed_at":"2026-01-28T12:06:26.832119-08:00","close_reason":"Not a violation - auto-promotion in divergence.py is automated system behavior. System Independence is about humans not manually editing tree structure."}
{"id":"mycelium-ufdl","title":"Perf: N+1 queries in umbrella routing - full JSON parsing","description":"get_children() in umbrella routing parses full JSON for each child.\n\nLocation: solver.py:1000-1015, db.py:1971-1995\n\nImpact: MEDIUM - 10-50ms per route with 5+ level deep trees\n\nChildren only need centroid/id for routing, not clarifying_questions/param_descriptions.\n\nFix: Use _row_to_signature_fast() which skips JSON parsing, or batch fetch with single query.","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T15:02:27.079075-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T15:27:09.452602-08:00","closed_at":"2026-01-15T15:27:09.452602-08:00","close_reason":"Added from_row_for_routing() that parses centroid but skips JSON. Updated get_children() with for_routing=True param. All 4 routing callsites now use fast mode. ~4x faster per child signature."}
{"id":"mycelium-ukc7","title":"Wire up mcts_dag_steps table logging","description":"Create mcts_dag_steps records when DAG plan is generated by planner. Log step_desc, step_num, branch_num, is_atomic for each step.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:07.531577-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T14:22:41.915382-08:00","closed_at":"2026-01-20T14:22:41.915382-08:00","close_reason":"Wired up mcts_dag_steps logging in solver.py. Now logs step_desc, step_num, branch_num, is_atomic for each step when DAG plan is generated (training mode only)."}
{"id":"mycelium-ulk","title":"Verify signature retrieval and method injection loop","description":"Signatures are now storing correctly. Need to verify:\n1. When a similar problem is seen, the signature is retrieved\n2. The method is injected into the prompt\n3. This actually improves accuracy on similar problems\n\nTest: Run training twice - second run should show method injection happening","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T05:32:34.756415-08:00","updated_at":"2026-01-08T06:13:56.696262-08:00","closed_at":"2026-01-08T06:13:56.696262-08:00"}
{"id":"mycelium-ursk","title":"Test: Add unit tests for solver and planner","description":"solver.py (1,566 lines) and planner.py have no unit tests - only integration tests.\n\nNeed tests for:\n- Error paths (DB corruption, LLM failures)\n- DSL timeout behavior\n- Concurrent access patterns\n\nPer CLAUDE.md: 'failures are valuable data' - but only if we can reproduce them in tests","status":"closed","priority":3,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:28:51.88041-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.335398-08:00","closed_at":"2026-01-20T18:00:01.335398-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-uwi","title":"Remove legacy problem-level signatures code","description":"Expunge unused problem-level signature code: delete signatures.py, remove SignatureDB imports from council_v2.py/mcts.py/solver.py/db.py/__init__.py, drop signatures table from schema.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T09:53:07.335343-08:00","updated_at":"2026-01-09T09:57:57.54369-08:00","closed_at":"2026-01-09T09:57:57.54369-08:00"}
{"id":"mycelium-uwlz","title":"Bug: Sibling dedup returns umbrella instead of leaf","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T14:36:08.099219-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T17:20:19.278542-08:00","closed_at":"2026-01-26T17:20:19.278542-08:00","close_reason":"Fixed: _route_hierarchical was returning umbrella as best_match when it had no children. Now returns None, letting caller create new leaf under the umbrella."}
{"id":"mycelium-v1d5","title":"Big 3: Consolidate rejection pathways (New Favorite Pattern)","description":"Per CLAUDE.md 'New Favorite Pattern': Consolidate methods for features.\n\n## Problem\n4+ functions handle rejection without consolidation:\n1. check_rejection() - rejection_utils.py\n2. record_leaf_rejection() - mcts.py\n3. increment_rejection_count() - db.py\n4. flag_high_rejection_leaves_for_decomposition() - mcts.py\n\nCallers must coordinate multiple functions, creating error-prone separation.\n\n## Solution\nCreate single `reject_dag_step(signature_id, dag_step_id, similarity)` that:\n1. Records rejection to DB\n2. Updates Welford stats\n3. Checks decomposition threshold\n4. Queues for decomposition if needed\n5. Returns decision struct\n\nAll callers use this one entry point.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T14:16:29.455312-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T14:25:13.424989-08:00","closed_at":"2026-01-28T14:25:13.424989-08:00","close_reason":"Consolidated rejection pathways to single reject_dag_step() function per CLAUDE.md New Favorite Pattern. All callers (check_rejection, db.py multi-part detection) now use this single entry point. record_leaf_rejection() kept for backwards compatibility but delegates to reject_dag_step()."}
{"id":"mycelium-v5pp","title":"Post-mortem: Difficulty re-estimation for consistently failing problems","description":"Problems that consistently fail across all paths may be harder than estimated. Post-mortem can detect these and revise difficulty estimates upward. This helps with curriculum learning - don't waste time on problems the system isn't ready for.","status":"closed","priority":3,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:05.463892-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T14:29:59.438403-08:00","closed_at":"2026-01-25T14:29:59.438403-08:00","close_reason":"Superseded by graph_embedding + Welford match scoring. System is now self-correcting through match_score (similarity + traffic + success + variance)."}
{"id":"mycelium-v87","title":"Centralize database connection management","description":"_get_connection() appears in both db.py and step_signatures.py. data_layer exists but inconsistently used.\n\nActions:\n- Add connection factory to data_layer\n- Deprecate _get_connection() in both modules  \n- Update all raw SQLite calls to use data_layer\n- Ensure schema migrations happen in one place","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T08:34:45.702413-08:00","updated_at":"2026-01-09T10:55:47.418622-08:00","closed_at":"2026-01-09T10:55:47.418622-08:00","dependencies":[{"issue_id":"mycelium-v87","depends_on_id":"mycelium-3g7","type":"blocks","created_at":"2026-01-09T08:35:23.372919-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-zcb","type":"blocks","created_at":"2026-01-09T09:00:42.399113-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-ern","type":"blocks","created_at":"2026-01-09T09:00:42.444588-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-jit","type":"blocks","created_at":"2026-01-09T09:00:42.490084-08:00","created_by":"daemon","metadata":"{}"},{"issue_id":"mycelium-v87","depends_on_id":"mycelium-dtj","type":"blocks","created_at":"2026-01-09T09:00:42.540202-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-vduc","title":"Consolidation: Replace direct embedder.embed() with cached_embed()","description":"## Problem\n\nPer CLAUDE.md \"New Favorite Pattern\": \"We want to consolidate methods.\"\n\nSome code uses direct `embedder.embed()` calls, bypassing the embedding cache. This causes:\n1. Redundant API calls for same text\n2. Inconsistent embedding values (API non-determinism)\n3. Higher latency and cost\n\n## Current Behavior\n\n**Direct calls (bypassing cache) - 8+ instances:**\n- `dsl_templates.py:397, 422, 482, 496, 601, 620` - 6 calls\n- `dsl_types.py:137, 170` - 2 calls\n- `graph_extractor.py:497` - 1 call\n\n**Correct cached pattern:**\n- `solver.py:932` - `cached_embed(problem, self.embedder)`\n- `db.py:1628` - `cached_embed(dsl_hint)`\n- `umbrella_learner.py:598` - `cached_embed(step.task, self.embedder)`\n\n## Expected Behavior\n\nALL embedding calls should use `cached_embed()` from `embedding_cache.py`:\n\n```python\n# Instead of:\nembedding = embedder.embed(text)\n\n# Use:\nfrom mycelium.step_signatures.embedding_cache import cached_embed\nembedding = cached_embed(text, embedder)\n```\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/dsl_templates.py:397, 422, 482, 496, 601, 620`\n- `src/mycelium/step_signatures/dsl_types.py:137, 170`\n- `src/mycelium/step_signatures/graph_extractor.py:497`\n\n## Implementation Notes\n\n1. Import `cached_embed` at top of each file\n2. Replace `embedder.embed(text)` with `cached_embed(text, embedder)`\n3. If embedder is None, some call sites may need adjustment\n\n## Testing\n\n1. Replace calls one file at a time\n2. Run tests after each file\n3. Verify cache hits in logs (optional: add cache hit logging)\n\n## Benefits\n\n- Reduced API calls (cache hit rate ~60-80% in typical runs)\n- Consistent embeddings for same text\n- Lower latency and cost\n\n## Context\n\nPart of Consolidation code review. Medium priority for cost/latency.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T11:39:08.7272-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:25:42.329023-08:00","closed_at":"2026-01-28T12:25:42.329023-08:00","close_reason":"All embedder.embed() calls replaced with cached_embed() in step_signatures modules"}
{"id":"mycelium-vf3","title":"Incomplete error handling in _row_to_signature for optional columns","description":"step_signatures.py:2426-2470 - _row_to_signature() has try-catch for io_schema but other wave properties (amplitude, phase, spread) might fail silently. Add safe access with row.get() for all optional columns.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:53.226918-08:00","updated_at":"2026-01-09T08:30:18.85225-08:00","closed_at":"2026-01-09T08:30:18.85225-08:00"}
{"id":"mycelium-vrq3","title":"Bug: Missing timestamp parsing error handling in scoring.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:31.383882-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:30:45.298856-08:00","closed_at":"2026-01-15T05:30:45.298856-08:00","close_reason":"Added AttributeError to except clause in compute_staleness_penalty to handle non-string inputs that lack .replace() method"}
{"id":"mycelium-vuuc","title":"Track signature performance by dag_step_id (step-type specialization)","description":"Currently signature.successes/uses don't distinguish which step types the signature is good/bad at.\n\nGap: A signature might be great for 'calculate percentage' steps but bad for 'find remainder' steps. We don't track this.\n\nImplementation:\n1. Add step_type_stats to signature (like difficulty_stats but for dag_step types)\n2. Format: {dag_step_id: {uses: N, successes: M}}\n3. Update in record_interference_outcome() and credit propagation\n4. Use in routing: prefer signatures with high success for THIS dag_step_id\n\nThis enables step-type specialization: route to signatures proven for specific operation types.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T06:25:18.061566-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T06:47:12.256932-08:00","closed_at":"2026-01-21T06:47:12.256932-08:00","close_reason":"Implemented step_type_stats for routing preferences. Signatures now track performance by dag_step type and routing uses this data to boost/penalize based on specialization."}
{"id":"mycelium-w44","title":"Benchmark: +45.7% lift from method injection","description":"## Key Finding\nMethod injection provides **+45.7% lift** in success rate.\n\n## Data\n| Path | Uses | Successes | Success Rate |\n|------|------|-----------|--------------|\n| Injected | 10 | 10 | 100% |\n| Non-injected | 1914 | 1039 | 54.3% |\n\n**Overall Lift: +45.7%**\n\n## Additional Metrics\n- Wave propagation effectiveness: +21.2%\n- Reliable signatures: 89 (of 312 total)\n- Canonical patterns: 102\n\n## Interpretation\nWhen the system injects a method template into the prompt, the success rate jumps from 54% to 100%. This validates the core hypothesis that:\n1. Signature matching finds relevant methods\n2. Method injection helps the LLM solve problems correctly\n\n## Next Steps\n- Gather more data to get per-signature lift confidence\n- Need 3+ samples in both arms per signature for confident estimates\n- Consider adjusting exploration_rate or running longer pipelines","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:22:24.982943-08:00","updated_at":"2026-01-20T17:48:37.529347-08:00","closed_at":"2026-01-20T17:48:37.529347-08:00","close_reason":"Stale - 11+ days old, deprioritizing"}
{"id":"mycelium-w5y5","title":"Bug: Race condition in db.py tuple indexing after None check","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T04:59:12.924522-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:08:25.314718-08:00","closed_at":"2026-01-15T05:08:25.314718-08:00","close_reason":"Fixed race condition by adding defensive None checks before tuple indexing in both db.py files. Affected locations: count_signatures(), record_usage(), remove_child(), clear_all_data() in step_signatures/db.py and get_stats() in main db.py"}
{"id":"mycelium-w7w","title":"Switch to aiosqlite for non-blocking DB operations","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:30.305496-08:00","updated_at":"2026-01-09T10:16:10.242983-08:00","closed_at":"2026-01-09T10:16:10.242983-08:00","dependencies":[{"issue_id":"mycelium-w7w","depends_on_id":"mycelium-o1a","type":"blocks","created_at":"2026-01-09T05:54:54.005517-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-w8w","title":"Amplitude decay compounds making wave propagation ineffective","description":"step_signatures.py:1936-1940 - AMPLITUDE_DECAY_RATE=0.99 applied per-update compounds with wave decay. Formula: neighbor.amplitude * 0.99 + delta means amplitudes decay faster than they grow. Review intent and fix formula.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T09:10:45.631172-08:00","updated_at":"2026-01-08T11:54:18.921595-08:00","closed_at":"2026-01-08T11:54:18.921595-08:00"}
{"id":"mycelium-wc9q","title":"Research: Use MCTS exploration to split vocab-based clusters into operation-based clusters","description":"## Problem\nMathBERT embeddings cluster by vocabulary similarity, not operational semantics. 'multiply by 2' and 'double the value' may be far apart despite being the same operation.\n\n## Solution\nUse MCTS multi-path exploration to discover operational equivalence that embeddings alone cannot capture.\n\n## Training vs Inference\n\n### Training (with ground truth)\n1. MCTS explores N paths through signature tree\n2. Each path produces an answer\n3. Compare to ground truth → success/fail per path\n4. Paths with same vocab but different outcomes → SPLIT signal\n5. Paths with different vocab but same outcome → MERGE signal\n6. Centroid updates reflect operational semantics, not just vocab\n\n### Inference (no ground truth)\n1. MCTS explores paths guided by learned confidence signals\n2. UCB1 balances exploitation (high success rate) vs exploration (uncertainty)\n3. Low confidence → explore more paths\n4. High confidence → exploit best path\n5. Return highest-confidence answer\n\n## Key Insight\nDuring training, ground truth lets us LABEL paths as operationally equivalent or different.\nDuring inference, we USE those labels (encoded as success rates, centroids) to guide exploration.\n\nThe confidence signals ARE the distilled knowledge from training exploration.","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T21:10:36.546388-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T18:00:01.002283-08:00","closed_at":"2026-01-20T18:00:01.002283-08:00","close_reason":"Stale - Jan 15, deprioritizing"}
{"id":"mycelium-wev3","title":"Add unit tests for step-node stats feedback loop","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-22T10:52:34.561838-08:00","created_by":"Bryce Roche","updated_at":"2026-01-22T10:58:06.369878-08:00","closed_at":"2026-01-22T10:58:06.369878-08:00","close_reason":"Added 14 unit tests covering update_dag_step_node_stats, get_dag_step_node_stats_batch, get_dag_step_node_stats_single, propagate_step_node_stats, and integration tests. All passing."}
{"id":"mycelium-wf4","title":"How do we decide when to add new step signature?","description":"Currently step signatures are added but the criteria for when to add a new one vs. reuse existing is unclear.\n\nQuestions to answer:\n- When should we create a new step signature vs. match to existing?\n- What similarity threshold triggers signature creation?\n- Should we require minimum success count before creating persistent signatures?\n- How do we handle near-duplicate steps that solve the same sub-problem differently?\n\nRelated: Step signatures are used in MCTS cluster-aware priors (mcts.py) and stored via StepSignatureDB.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T08:17:46.314404-08:00","updated_at":"2026-01-08T08:39:59.12617-08:00","closed_at":"2026-01-08T08:39:59.12617-08:00"}
{"id":"mycelium-wj29","title":"Feature: Add LLM fallback mode for cold start","description":"Add configurable LLM fallback when DSL execution fails. This allows the system to solve problems even with empty DB, while still learning signatures. Current design intentionally disabled fallback for strict execution but this prevents learning.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-14T07:08:40.16926-08:00","created_by":"Bryce Roche","updated_at":"2026-01-14T08:12:42.100063-08:00","closed_at":"2026-01-14T08:12:42.100063-08:00","close_reason":"Decided against LLM fallback per CLAUDE.md design philosophy. System should learn from failures, not mask them. Signature-guided learning is the solution.","dependencies":[{"issue_id":"mycelium-wj29","depends_on_id":"mycelium-i74m","type":"blocks","created_at":"2026-01-14T07:08:53.387294-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-wjvr","title":"Big 3: Consolidate cluster detection logic","description":"## Context\n\nPer CLAUDE.md \"New Favorite Pattern\": Consolidate methods through single entry points.\n\nThe cluster threshold calculation logic is duplicated in multiple places with inconsistent implementations and hardcoded magic numbers.\n\n---\n\n## Problem\n\n**Three locations compute cluster thresholds differently:**\n\n### 1. `get_adaptive_thresholds()` (lines 441-448) - GOOD ✓\n```python\ncluster_threshold = cluster_stats.mean - ADAPTIVE_THRESHOLD_K * cluster_stats.stddev\ncluster_threshold = max(0.3, min(0.95, cluster_threshold))\n```\nUses config constants properly.\n\n### 2. `_restructure_umbrella_internal()` (lines 8985-8990) - BAD ✗\n```python\ncluster_threshold = max(0.85, 1.0 - 2 * child_std) if child_std else 0.90\n```\nHardcoded: `0.85`, `1.0`, `2`, `0.90`\n\n### 3. `_create_subclusters_for_umbrella()` (lines 10296-10309) - BAD ✗\n```python\nif cv \u003e 0.1:\n    cluster_threshold = min(0.95, mean_sim + 2.0 * std_sim)\nelse:\n    percentile_idx = max(1, int(len(sorted_sims) * 0.03))\n    cluster_threshold = sorted_sims[percentile_idx]\ncluster_threshold = max(0.85, min(0.95, cluster_threshold))\n```\nHardcoded: `0.1`, `0.95`, `2.0`, `0.03`, `0.85`\n\n---\n\n## Files to Modify\n\n| File | Purpose |\n|------|---------|\n| `src/mycelium/config.py` | Add cluster threshold constants |\n| `src/mycelium/step_signatures/db.py` | Create consolidated function, update callers |\n\n---\n\n## Solution\n\n### Step 1: Add constants to config.py\n\n```python\n# =============================================================================\n# CLUSTER THRESHOLD COMPUTATION (per CLAUDE.md \"The Flow\")\n# =============================================================================\n# Unified constants for computing cluster thresholds across the codebase.\n\nCLUSTER_THRESHOLD_CV_CUTOFF = 0.1        # CV above this uses Welford method\nCLUSTER_THRESHOLD_STD_MULTIPLIER = 2.0   # k in mean ± k*std\nCLUSTER_THRESHOLD_PERCENTILE = 0.03      # Top 3% for low-CV distributions\nCLUSTER_THRESHOLD_MIN = 0.85             # Floor (never go below)\nCLUSTER_THRESHOLD_MAX = 0.95             # Ceiling (never go above)\nCLUSTER_THRESHOLD_COLD_START = 0.90      # Fallback when no data\n```\n\n### Step 2: Create consolidated function in db.py\n\nAdd after line ~450 (near `get_adaptive_thresholds()`):\n\n```python\ndef compute_cluster_threshold(\n    similarities: list[float],\n    welford_stats: Optional[WelfordStats] = None,\n) -\u003e tuple[float, str]:\n    \"\"\"Compute cluster threshold using unified algorithm.\n    \n    Per CLAUDE.md \"New Favorite Pattern\": Single entry point for all \n    cluster threshold computation.\n    \n    Args:\n        similarities: List of pairwise similarity values\n        welford_stats: Optional pre-computed Welford stats\n        \n    Returns:\n        Tuple of (threshold, method_used)\n    \"\"\"\n    from mycelium.config import (\n        CLUSTER_THRESHOLD_CV_CUTOFF,\n        CLUSTER_THRESHOLD_STD_MULTIPLIER,\n        CLUSTER_THRESHOLD_PERCENTILE,\n        CLUSTER_THRESHOLD_MIN,\n        CLUSTER_THRESHOLD_MAX,\n        CLUSTER_THRESHOLD_COLD_START,\n    )\n    \n    if not similarities:\n        return (CLUSTER_THRESHOLD_COLD_START, \"cold_start\")\n    \n    # Compute mean and std (Welford-style)\n    mean_sim = sum(similarities) / len(similarities)\n    if len(similarities) \u003e 1:\n        variance = sum((s - mean_sim) ** 2 for s in similarities) / len(similarities)\n        std_sim = variance ** 0.5\n    else:\n        std_sim = 0.0\n    \n    cv = std_sim / mean_sim if mean_sim \u003e 0 else 0.0\n    \n    if cv \u003e CLUSTER_THRESHOLD_CV_CUTOFF:\n        # High CV: Welford-guided threshold\n        threshold = min(CLUSTER_THRESHOLD_MAX, mean_sim + CLUSTER_THRESHOLD_STD_MULTIPLIER * std_sim)\n        method = \"welford\"\n    else:\n        # Low CV: Percentile-based threshold\n        sorted_sims = sorted(similarities, reverse=True)\n        percentile_idx = max(1, int(len(sorted_sims) * CLUSTER_THRESHOLD_PERCENTILE))\n        threshold = sorted_sims[percentile_idx]\n        method = \"percentile\"\n    \n    # Clamp to bounds\n    threshold = max(CLUSTER_THRESHOLD_MIN, min(CLUSTER_THRESHOLD_MAX, threshold))\n    \n    return (threshold, method)\n```\n\n### Step 3: Update callers\n\n**In `_restructure_umbrella_internal()` (~line 8985):**\n```python\n# Before:\ncluster_threshold = max(0.85, 1.0 - 2 * child_std) if child_std else 0.90\n\n# After:\nsims = [sim_matrix[i][j] for i in range(n) for j in range(i + 1, n)]\ncluster_threshold, method = compute_cluster_threshold(sims)\nlogger.debug(\"[restructure] Cluster threshold: %.3f (%s)\", cluster_threshold, method)\n```\n\n**In `_create_subclusters_for_umbrella()` (~line 10284):**\n```python\n# Before: (lines 10284-10309 - entire threshold calculation block)\n\n# After:\nsims = [sim_matrix[i][j] for i in range(n) for j in range(i + 1, n)]\ncluster_threshold, method = compute_cluster_threshold(sims)\nlogger.info(\"[subcluster] %s threshold %.3f (n=%d)\", method, cluster_threshold, len(sims))\n```\n\n---\n\n## Reference Pattern\n\nSee `_route_core()` at line 1115 for the consolidation pattern - it's the single implementation that `route_through_hierarchy()` and `route_with_confidence()` both delegate to.\n\n---\n\n## Testing\n\n```bash\n# Run full test suite\nuv run pytest tests/ -x -q\n\n# Verify no regressions in clustering behavior\nuv run pytest tests/test_tree_structure.py -v\n\n# Grep to confirm no hardcoded values remain\ngrep -n \"0\\.85\\|0\\.90\\|0\\.95\" src/mycelium/step_signatures/db.py | grep -i cluster\n```\n\n---\n\n## Acceptance Criteria\n\n- [ ] All 395+ tests pass\n- [ ] `compute_cluster_threshold()` function exists and is documented\n- [ ] Lines 8985-8990 use the new function\n- [ ] Lines 10296-10309 use the new function  \n- [ ] All magic numbers moved to config.py\n- [ ] No hardcoded cluster thresholds remain in db.py (verify with grep)","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T05:51:29.1609-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T06:12:22.095771-08:00","closed_at":"2026-01-29T06:12:22.095771-08:00","close_reason":"compute_cluster_threshold() created at db.py:458 as single entry point. Both callers (_restructure_umbrella_internal line 9049, _create_subclusters_for_umbrella line 10349) now use it. Config constants CLUSTER_THRESHOLD_* used. All 395 tests pass."}
{"id":"mycelium-wlf","title":"Bug: DSL param mapping fails for symbolic/non-numeric values","description":"## Problem\nStep audit revealed that arithmetic DSLs (compute_difference, compute_sum, compute_product) return 0.0 when parameter mapping extracts symbolic/non-numeric values from dependent steps.\n\n## Example Failure Pattern\n1. Task: 'Calculate the difference between side b and side a'\n2. Dependent steps return: side_b='20', side_a='a' (symbolic variable name)\n3. DSL script 'a - b' is injected with compute_difference signature\n4. Parameter extraction fails to parse 'a' as numeric, defaults to 0.0\n5. Result: 0.0 instead of correct symbolic expression\n\n## Root Cause\n- DSL parameter mapping extracts first numeric value from step results\n- When step results contain symbolic expressions like 'a', '(x, y)', 'x_C', etc., extraction fails\n- Default behavior returns 0.0, causing cascading errors\n\n## Affected Signatures\n- compute_difference (a - b): 8+ failures in audit\n- compute_sum (a + b): 4+ failures\n- compute_product (a * b): 2+ failures\n\n## Fix Options\n1. Add numeric-check validation before DSL injection - skip DSL if params are non-numeric\n2. Improve param extraction to detect symbolic values and fall back to LLM\n3. Add DSL type 'symbolic' that handles algebraic expressions via SymPy\n\n## Evidence\nSee step_audit.py output for problems with seed=42","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T10:21:02.326581-08:00","updated_at":"2026-01-12T10:34:02.705891-08:00","closed_at":"2026-01-12T10:34:02.705891-08:00"}
{"id":"mycelium-wow2","title":"Consolidate post-mortem to single pathway","description":"**Current State:** 4+ post-mortem entry points:\n- mcts.py: run_postmortem(), run_postmortem_with_interference(), run_diagnostic_postmortem()\n- adaptive.py: record_postmortem_stats()\n\n**Goal:** Single run_postmortem() with options for interference detection, diagnostic output, etc. Remove redundant variations.\n\n**Files:** src/mycelium/data_layer/mcts.py, src/mycelium/mcts/adaptive.py","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T13:22:01.756453-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T13:50:58.986869-08:00","closed_at":"2026-01-25T13:50:58.986869-08:00","close_reason":"Consolidated post-mortem to single run_postmortem() pathway. run_postmortem_with_interference and run_diagnostic_postmortem are now thin wrappers. Solver.py uses single call."}
{"id":"mycelium-wrvq","title":"Consolidate cache invalidation to single pathway","description":"**Current State:** 13+ cache invalidation entry points across 6 files:\n- db.py: invalidate_centroid_matrix(), invalidate_root_cache(), _invalidate_on_embedding_change(), _invalidate_on_relationship_change(), _invalidate_on_dsl_change()\n- graph_extractor.py: clear_graph_embedding_cache()\n- scoring.py: invalidate_traffic_cache()\n- utils.py: invalidate_signature_cache(), invalidate_children_cache(), invalidate_centroid_cache()\n- operation_extractor.py: clear_operation_cache()\n- mcts.py: invalidate_cache()\n\n**Goal:** Single CacheManager class or invalidate_all() that coordinates all caches. Individual invalidators become thin wrappers or get removed.\n\n**Files:** Multiple files need coordination","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T13:22:00.977016-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T13:27:38.386138-08:00","closed_at":"2026-01-25T13:27:38.386138-08:00","close_reason":"Added CacheManager class with semantic invalidation methods and invalidate_all()"}
{"id":"mycelium-ws1","title":"Match mode bypassed: clustering/injection use find_similar not find_matches","description":"MYCELIUM_MATCH_MODE (resonance/interference/auto) is bypassed in core flows because clustering and method injection call find_similar() directly instead of find_matches().\n\nAffected locations:\n- step_signatures.py:1750 - clustering logic\n- step_signatures.py:1981 - method injection\n\nThis means users setting MYCELIUM_MATCH_MODE won't see those modes used in actual behavior - only cosine similarity is used.\n\nFix: Update these call sites to use find_matches() which respects the configured mode.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-08T13:16:05.749583-08:00","updated_at":"2026-01-08T13:20:24.780128-08:00","closed_at":"2026-01-08T13:20:24.780128-08:00"}
{"id":"mycelium-wst","title":"Add retry logic with exponential backoff to client.py","description":"Wrap Groq API calls with retry decorator. Handle rate limits (429), server errors (5xx), and connection timeouts. Use tenacity or custom implementation with max 3 retries.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:30.28528-08:00","updated_at":"2026-01-09T07:49:20.236684-08:00","closed_at":"2026-01-09T07:49:20.236684-08:00"}
{"id":"mycelium-x0mt","title":"Post-mortem: Signature retirement/pruning for consistently failing nodes","description":"Signatures that consistently fail across multiple problems and dag_steps should be flagged for retirement. Post-mortem can identify these 'dead weight' nodes that hurt routing. Retirement could mean: pruning entirely, demoting to lower priority, or merging into parent.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-21T05:49:02.138244-08:00","created_by":"Bryce Roche","updated_at":"2026-01-21T08:50:36.24305-08:00","closed_at":"2026-01-21T08:50:36.24305-08:00","close_reason":"Already implemented. RETIREMENT_ENABLED config, run_retirement_check(), integrated in run_postmortem_with_interference(). Tracks demoted, pruned, merged_up stats."}
{"id":"mycelium-x1h6","title":"Feature: Tree-Planner Negotiation for dag_step refinement","description":"## Goal\nImplement bidirectional negotiation between TreeGuidedPlanner and signature tree.\n\n## Key Principles (from CLAUDE.md)\n1. **New Favorite Pattern**: Consolidate into single entry point\n2. **System Independence**: Tree grows organically, not manually\n3. **Negotiation**: Bias towards decomposing dag_steps (cheap) over leaf_nodes (permanent)\n\n## Design\n- Tree evaluates proposed dag_steps\n- If poor match: suggest dag_step refinement (not node creation)\n- Planner refines dag_steps based on tree vocabulary\n- Only post-mortem triggers leaf_node decomposition\n\n## Flow\nRound 1: Planner proposes dag_steps\nRound 2: Tree evaluates, provides decomposition hints for poor matches\nRound 3: Planner refines dag_steps to match existing vocabulary\nIterate until good matches or max rounds","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T19:36:00.336015-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T19:42:14.778649-08:00","closed_at":"2026-01-26T19:42:14.778649-08:00","close_reason":"Implemented in f0fdf3c - Tree-Planner negotiation with decomposition hints"}
{"id":"mycelium-x2h","title":"Add database migration system for schema changes","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T05:54:14.571081-08:00","updated_at":"2026-01-20T17:48:37.580361-08:00","closed_at":"2026-01-20T17:48:37.580361-08:00","close_reason":"Stale - 11+ days old, deprioritizing","dependencies":[{"issue_id":"mycelium-x2h","depends_on_id":"mycelium-o1a","type":"blocks","created_at":"2026-01-09T05:54:53.027961-08:00","created_by":"daemon","metadata":"{}"}]}
{"id":"mycelium-xfap","title":"Cleanup: Standardize logging tags across codebase","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-13T14:55:46.317785-08:00","updated_at":"2026-01-20T17:50:06.620965-08:00","closed_at":"2026-01-20T17:50:06.620965-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-xix","title":"Add batch processing to decay_unused_signatures for scale","description":"decay_unused_signatures() fetches all signatures into memory before processing. For large DBs with millions of signatures, this could cause memory issues. Add a batch_size parameter to process in chunks, e.g., 'LIMIT 1000 OFFSET N' with cursor-based iteration.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-08T12:15:43.699062-08:00","updated_at":"2026-01-20T17:50:06.211766-08:00","closed_at":"2026-01-20T17:50:06.211766-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-xm4","title":"Fix LRU cache for embedding lookups in step_signatures.py","description":"Add functools.lru_cache or manual cache dict for repeated embedding lookups. Cache get_essence_dims() results and signature centroid fetches.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:50.784995-08:00","updated_at":"2026-01-09T07:55:22.121835-08:00","closed_at":"2026-01-09T07:55:22.121835-08:00"}
{"id":"mycelium-xrig","title":"Bug: LLM validation rejects valid symbolic answers","description":"validate_llm_output_type() rejects outputs like 'x = 2' because they contain variables. But these are valid answers - the variable is part of the solution, not an unresolved computation. Need to distinguish between problem variables (OK) vs truly unresolved variables (BAD).","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-12T11:21:39.581534-08:00","updated_at":"2026-01-12T11:23:20.897291-08:00","closed_at":"2026-01-12T11:23:20.897291-08:00"}
{"id":"mycelium-xt7","title":"Add structured logging to planner.py","description":"Add consistent logging to planner.py for decomposition steps, DAG validation, and error cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:17.3163-08:00","updated_at":"2026-01-09T07:48:30.827162-08:00","closed_at":"2026-01-09T07:48:30.827162-08:00"}
{"id":"mycelium-xv09","title":"Feature: Proposed signatures staging table","description":"## Summary\nCreate a staging table for proposed signatures. During cold start, proposals are auto-accepted as root children. After cold start, Welford stats determine acceptance.\n\n## Schema\n```sql\nCREATE TABLE proposed_signatures (\n    id INTEGER PRIMARY KEY,\n    step_text TEXT NOT NULL,\n    embedding BLOB,\n    graph_embedding BLOB,\n    proposed_parent_id INTEGER REFERENCES step_signatures(id),\n    best_match_id INTEGER REFERENCES step_signatures(id),\n    best_match_sim REAL,\n    status TEXT DEFAULT 'pending',  -- pending, accepted, rejected, merged\n    decision_reason TEXT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    decided_at TIMESTAMP\n);\n```\n\n## Implementation\n1. Add table to schema in `db.py` `_ensure_tables()`\n2. Add methods to db.py:\n   - `propose_signature(step_text, embedding, ...) -\u003e proposal_id`\n   - `accept_proposal(proposal_id, parent_id) -\u003e signature_id`\n   - `reject_proposal(proposal_id, reason)`\n   - `merge_proposal(proposal_id, merge_into_sig_id)`\n   - `get_pending_proposals() -\u003e list[Proposal]`\n\n## Cold Start Behavior\n- Check `get_total_problems_solved()` \u003c COLD_START_THRESHOLD (20)\n- If cold start: auto-accept as child of root node\n- If not cold start: leave as pending for Welford-based decision\n\n## Integration Points\n- Modify `find_or_create_async()` to use staging table\n- During cold start: immediately promote to signature\n- After cold start: leave in staging for restructure pass","status":"closed","priority":1,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-27T06:37:59.927034-08:00","created_by":"Bryce Roche","updated_at":"2026-01-27T07:03:49.301471-08:00","closed_at":"2026-01-27T07:03:49.301471-08:00","close_reason":"Implemented in commit 11fb77d","dependencies":[{"issue_id":"mycelium-xv09","depends_on_id":"mycelium-bjrf","type":"blocks","created_at":"2026-01-27T06:38:08.53022-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-y96x","title":"Bug: Complex DSLs should be split into atomic operations","description":"DSL scripts should be atomic - single operations like MUL(p0, p1) or ADD(p0, p1).\n\nComplex DSLs with multiple operations (e.g., \"p0 * p1 + p2\") suggest the dag_step wasn't decomposed far enough.\n\n**To investigate:**\n- Query DSL scripts containing multiple operators: +, -, *, / in same script\n- Check if these have low success rates (complexity = errors)\n\n**Examples of bad DSLs:**\n- `(p0 + p1) * p2` - should be two steps\n- `p0 / p1 - p2` - should be two steps\n\n**Examples of good DSLs:**\n- `p0 * p1` - atomic\n- `p0 + p1` - atomic\n- `p0 ** p1` - atomic (single operation)\n\n**Fix:**\n1. Identify signatures with complex DSLs\n2. Decompose into parent umbrella + atomic children\n3. Tighten planner to produce atomic steps\n\nPer CLAUDE.md: \"Each step should not be capable of being broken down further\"","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-23T10:23:27.007106-08:00","created_by":"Bryce Roche","updated_at":"2026-01-23T10:48:07.55292-08:00","closed_at":"2026-01-23T10:48:07.55292-08:00","close_reason":"Implemented atomic DSL validation: is_atomic_dsl() rejects complex scripts, updated prompt to require single operations"}
{"id":"mycelium-y9qc","title":"Brainstorm: Depth-aware routing with successful neighbor fallback","description":"## Current approach\n- max_depth=5 hard limit prevents infinite loops\n- Umbrella routing is parent→child only\n\n## Proposed: Depth-aware neighbor routing\nInstead of hard depth limit, use depth as a routing constraint:\n\n1. **Depth property**: Each signature has an implicit depth level\n2. **Downward-only routing**: Can route to same depth OR deeper, never shallower\n3. **Successful neighbor fallback**: When stuck, route to high-success neighbor at same/deeper depth\n\n### Benefits\n- Loops impossible by design (can't go back up)\n- No arbitrary depth limit needed\n- Leverages success rates for smart fallback\n- Creates natural \"flow downward\" toward leaf executors\n\n### Questions to resolve\n1. How to assign depth? Options:\n   - Creation order (first sig = depth 0)\n   - Explicit field in schema\n   - Computed from parent-child relationships (max parent depth + 1)\n\n2. What defines \"neighbor\"?\n   - Embedding similarity (cosine \u003e 0.5)?\n   - Shared parent umbrella?\n   - Same step_type?\n\n3. New relationship type needed?\n   - `signature_neighbors` table with (sig_a, sig_b, similarity)?\n   - Or compute dynamically from embeddings?\n\n4. Selection criteria for neighbors:\n   - `score = similarity * success_rate`?\n   - Prefer deeper over same-depth?\n\n### Example flow\n```\nStep: \"Calculate probability of event A\"\n\n1. Match → probability_umbrella (depth 0)\n2. Route → counting_outcomes (depth 1, child)\n3. DSL fails\n4. Neighbor fallback → complement_probability (depth 1, neighbor, 80% success)\n5. DSL succeeds\n```\n\n### Implementation sketch\n```python\ndef route_with_neighbor_fallback(sig, embedding, current_depth):\n    # Try children first (depth + 1)\n    children = get_children(sig.id)\n    if children:\n        best = pick_by_embedding_and_success(children, embedding)\n        if best:\n            return best\n    \n    # Fallback to neighbors at same or deeper depth\n    neighbors = find_neighbors(embedding, min_depth=current_depth)\n    if neighbors:\n        return pick_by_success(neighbors)\n    \n    return None  # No valid route\n```","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-13T04:56:02.62509-08:00","updated_at":"2026-01-13T05:03:59.367471-08:00","closed_at":"2026-01-13T05:03:59.367471-08:00"}
{"id":"mycelium-yhc","title":"Add unit tests for clustering module","description":"Write pytest tests for compute_cohesion, compute_silhouette, build_distance_matrix. Test with synthetic embeddings and edge cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T06:58:41.853265-08:00","updated_at":"2026-01-09T07:55:44.154202-08:00","closed_at":"2026-01-09T07:55:44.154202-08:00"}
{"id":"mycelium-yhlj","title":"Implement ExprNode expression tree data structures","description":"## Context\nPer CLAUDE.md Big 5 #4 (True Atomic Decomposition) and #5 (Primitive vs Chain Nodes), we need expression tree data structures to support GTS-based decomposition.\n\n## Goal\nCreate expression tree classes that can:\n1. Represent prefix notation from GTS output\n2. Calculate tree depth\n3. Determine atomicity (depth \u003c= 1)\n4. Support recursive decomposition\n\n## Implementation\n\nCreate `src/mycelium/expression_tree.py`:\n\n```python\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom enum import Enum\n\nclass NodeType(Enum):\n    OPERATOR = 'operator'  # +, -, *, /\n    NUMBER = 'number'      # Literal values\n    VARIABLE = 'variable'  # NUM_0, NUM_1, step_1, etc.\n\n@dataclass\nclass ExprNode:\n    type: NodeType\n    value: str\n    left: Optional['ExprNode'] = None\n    right: Optional['ExprNode'] = None\n    \n    @property\n    def depth(self) -\u003e int:\n        '''Tree depth. Depth 1 = single operation (atomic).'''\n        ...\n    \n    @property\n    def is_atomic(self) -\u003e bool:\n        '''Per CLAUDE.md: depth \u003c= 1 is atomic during cold start.'''\n        return self.depth \u003c= 1\n    \n    def to_operation_string(self) -\u003e str:\n        '''Convert to operation description for graph embedding.'''\n        ...\n\ndef parse_prefix(prefix_str: str) -\u003e ExprNode:\n    '''Parse GTS prefix output to expression tree.'''\n    ...\n\ndef decompose_to_atomic(tree: ExprNode) -\u003e list[tuple[str, ExprNode, dict]]:\n    '''Recursively decompose until all steps are depth 1.'''\n    ...\n```\n\n## Tests Required\n- test_depth_calculation\n- test_atomicity_check  \n- test_prefix_parsing (with GTS-style NUM_0, NUM_1 tokens)\n- test_recursive_decomposition\n\n## Acceptance Criteria\n- [ ] ExprNode class with depth property\n- [ ] parse_prefix handles GTS output format\n- [ ] decompose_to_atomic returns list of atomic steps\n- [ ] All tests pass\n- [ ] Follows New Favorite Pattern (single entry point for parsing)","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-29T12:27:15.763054-08:00","created_by":"Bryce Roche","updated_at":"2026-01-29T12:53:05.424348-08:00","closed_at":"2026-01-29T12:53:05.424348-08:00","close_reason":"All implemented with 208 tests passing. Committed in 2b96e5b."}
{"id":"mycelium-ym7s","title":"Big 3: Welford-guided rejection decomposition (The Flow)","description":"Per CLAUDE.md 'The Flow': Database Statistics → Welford → Tree Structure.\n\n## Problem\nget_leaf_rejection_stats() uses hardcoded logic:\n```python\nshould_decompose = (\n    rejection_count \u003e= 10 and  # Hardcoded\n    rejection_rate \u003e= 0.30     # Hardcoded\n)\n```\n\n## Solution\nUse Welford-based adaptive thresholds:\n```python\n# Adaptive threshold: mean - k * std from observed distributions\nthreshold = get_adaptive_rejection_threshold(signature_id)\nconfidence = 1 - exp(-uses / CONFIDENCE_HALFLIFE)\nshould_decompose = (\n    confidence \u003e MIN_CONFIDENCE and\n    rejection_rate \u003e= threshold\n)\n```\n\nTrack rejection rate distribution via Welford, compute thresholds dynamically.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T14:16:31.607248-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T14:27:06.648161-08:00","closed_at":"2026-01-28T14:27:06.648161-08:00","close_reason":"Implemented Welford-guided rejection rate threshold. get_adaptive_rejection_rate_threshold() computes mean+k*std from rejection rate distribution. get_leaf_rejection_stats() and get_leaves_needing_decomposition() now use this adaptive threshold. Added REJECTION_RATE_WELFORD_ENABLED, REJECTION_RATE_WELFORD_K, REJECTION_RATE_MIN_SAMPLES to config."}
{"id":"mycelium-ynb","title":"Track step sequences for contextual matching (entanglement)","description":"Track which step types commonly follow each other and their success rates. Use this to improve method selection based on context.\n\nFrom wave function analysis: Steps are 'entangled' - the optimal method for step N depends on what step N-1 did.\n\nImplementation:\n1. Add step_sequences table (prev_type, curr_type, count, success_rate)\n2. Record transitions during solving\n3. Add get_contextual_method() that considers prev step type\n4. Weight signature matches by transition success rate","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T08:33:57.557384-08:00","updated_at":"2026-01-08T12:10:25.191086-08:00","closed_at":"2026-01-08T12:10:25.191086-08:00"}
{"id":"mycelium-ynn","title":"Variable detection in complexity estimation is backwards","description":"model_router.py:estimate_complexity() excludes 'a' and 'i' from variable detection but keeps all other single letters. The logic seems backwards - it should keep likely math variables (x, y, z, n, m, k, t) and exclude common words. Current: variables = set(re.findall(r'\\b[a-z]\\b', text_lower)) - {'a', 'i'}. Suggested fix: math_vars = {'x', 'y', 'z', 'n', 'm', 'k', 't', 'r', 's'} and use intersection instead of difference.","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-08T13:12:46.343362-08:00","updated_at":"2026-01-15T05:51:55.16432-08:00","closed_at":"2026-01-15T05:51:55.16432-08:00","close_reason":"Stale issue - model_router.py does not exist in codebase and has no git history. The code was likely never implemented or was refactored into a different approach."}
{"id":"mycelium-yq9","title":"model_router exception list may miss user-defined errors","description":"Line 192 catches specific exceptions but user rule conditions could raise others (ZeroDivisionError, IndexError). Consider broader catch or documenting expected exceptions.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-09T08:33:01.042765-08:00","updated_at":"2026-01-20T17:50:06.281742-08:00","closed_at":"2026-01-20T17:50:06.281742-08:00","close_reason":"Stale - older than Jan 15, deprioritizing"}
{"id":"mycelium-yuu","title":"Consolidate SignatureDB and StepSignatureDB into unified MyceliumDB","description":"Merge the two database classes into a single MyceliumDB class with all tables in one place. This simplifies the architecture and ensures consistent db_path usage.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T11:16:34.141371-08:00","updated_at":"2026-01-08T11:45:07.225023-08:00","closed_at":"2026-01-08T11:45:07.225023-08:00"}
{"id":"mycelium-yzwg","title":"Refactor: Consolidate failure recording in solver","description":"## Context (CLAUDE.md New Favorite Pattern)\nPer CLAUDE.md: \"consolidate method calls for features to simplify our codebase and reduce the chance of bugs\"\n\n## Problem\n`self.step_db.record_failure()` is called from 10+ places in `solver.py` with similar parameters:\n\n```\nsolver.py:811, 991, 1007, 1260, 1772, 2130, 2146, 2469, 2725, 4291\n```\n\nEach call site manually constructs similar parameters, leading to:\n- Code duplication\n- Inconsistent error handling\n- Risk of missing required fields\n\n## Solution\nCreate a unified helper method in `Solver` class:\n\n```python\ndef _record_step_outcome(\n    self,\n    signature: StepSignature,\n    step: Step,\n    success: bool,\n    result: Any = None,\n    error: str = None,\n    execution_method: str = None,\n) -\u003e None:\n    \"\"\"Record step execution outcome (success or failure).\n    \n    Consolidates all outcome recording to ensure consistent:\n    - Parameter extraction\n    - Error categorization  \n    - Logging\n    - Stats updates\n    \"\"\"\n    if success:\n        self.step_db.record_success(signature.id, ...)\n    else:\n        self.step_db.record_failure(signature.id, ...)\n```\n\nThen replace all direct `record_failure()` calls with this helper.\n\n## Files to Modify\n1. `src/mycelium/solver.py` - Add helper method and update call sites\n\n## Acceptance Criteria\n- [ ] Single `_record_step_outcome()` method handles all outcome recording\n- [ ] All 10+ call sites updated to use the helper\n- [ ] Consistent logging format across all outcomes\n- [ ] Tests pass\n\n## Notes\n- This is lower priority than DB consolidation - the current code works, it's just verbose\n- Consider also consolidating `record_success()` calls if they follow same pattern\n- May want to add metrics/timing capture in the consolidated method","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T17:58:02.822404-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T18:03:41.575273-08:00","closed_at":"2026-01-26T18:03:41.575273-08:00","close_reason":"Implemented _record_failure() helper method in solver.py, replacing 10 direct step_db.record_failure() calls with consolidated method. All solver tests pass."}
{"id":"mycelium-z1a0","title":"Bug: Bare except swallowing KeyboardInterrupt in solver.py","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:19.601184-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:25:38.934867-08:00","closed_at":"2026-01-15T05:25:38.934867-08:00","close_reason":"Changed bare except: to except Exception: in solver.py:81 to allow KeyboardInterrupt and SystemExit to propagate"}
{"id":"mycelium-z3nb","title":"Consolidate umbrella marking pattern","description":"## Problem\nMultiple places in src/mycelium/step_signatures/db.py mark a signature as umbrella with inline UPDATEs instead of using dedicated `promote_to_umbrella()`:\n\nDedicated function exists:\n- `promote_to_umbrella()` (line ~4877) - Sets is_semantic_umbrella=1, dsl_type='router', dsl_script=NULL, computes graph_centroid\n\nBut inline UPDATEs also used:\n- Line ~3851 in `add_child()`: `SET is_semantic_umbrella = 1, dsl_type = 'router', dsl_script = NULL`\n- Lines ~3633-3637 in `record_usage()`: Same pattern for auto-demotion logic\n\nThese inline UPDATEs:\n- Don't compute graph_centroid from children\n- May miss cache invalidation\n- Duplicate the 'what makes an umbrella' logic\n\n## Pattern to Follow\nSee how we consolidated graph_centroid updates to use `propagate_graph_centroid_to_parents()` everywhere.\n\n## Proposed Solution\nAlways call `promote_to_umbrella(signature_id)` instead of inline UPDATEs:\n\n1. Ensure `promote_to_umbrella()` handles all side effects:\n   - Set is_semantic_umbrella = 1\n   - Set dsl_type = 'router'\n   - Clear dsl_script = NULL\n   - Compute graph_centroid from children\n   - Invalidate appropriate caches\n   - Propagate centroid to ancestors\n\n2. Replace inline UPDATEs with function call\n\n3. If `add_child()` or `record_usage()` need conditional umbrella promotion, call the function conditionally rather than inline SQL.\n\n## Acceptance Criteria\n- [ ] `promote_to_umbrella()` is the ONLY way to mark a signature as umbrella\n- [ ] All inline UPDATEs for umbrella marking removed\n- [ ] Function handles all side effects (centroid, caches, propagation)\n- [ ] No behavior change in when signatures become umbrellas\n- [ ] Clear documentation of when/why signatures get promoted","status":"closed","priority":4,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-25T08:08:45.72222-08:00","created_by":"Bryce Roche","updated_at":"2026-01-25T08:43:05.941053-08:00","closed_at":"2026-01-25T08:43:05.941053-08:00","close_reason":"Consolidated umbrella marking into single pathway (_promote_to_umbrella_internal). Also cleaned up unused text centroid pathways (propagate_centroid_to_parents, _update_centroid_atomic now NO-OPs)."}
{"id":"mycelium-z4j","title":"Docstring mismatch in MCTS get_prior() about only_reliable","description":"mcts.py:169-197 - Docstring says 'prior_probability' but uses only_reliable=False returning all signatures. Either update docstring or change to only_reliable=True.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T09:10:55.082153-08:00","updated_at":"2026-01-08T12:15:47.032147-08:00","closed_at":"2026-01-08T12:15:47.032147-08:00"}
{"id":"mycelium-zb9e","title":"Perf: Extract DB connection boilerplate","description":"PRAGMA setup duplicated in 5 places:\n- data_layer/connection.py:59-68\n- step_signatures/db.py:74-79\n- step_signatures/scoring.py:79-81\n- step_signatures/stats.py:174-175\n- step_signatures/decay.py:189-190\n\nExtract to shared utility to ensure consistent WAL mode and timeout settings.\n\nLatency impact: LOW but prevents misconfiguration","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:28:21.533018-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T14:43:07.761745-08:00","closed_at":"2026-01-15T14:43:07.761745-08:00","close_reason":"Extracted PRAGMA setup to configure_connection() utility in data_layer/connection.py and updated all 5 locations"}
{"id":"mycelium-zcb","title":"Migrate signatures.py to use data_layer","description":"Replace 10 direct sqlite3.connect calls with data_layer.db.connection(). Import db, replace connection pattern.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-09T09:00:29.142156-08:00","updated_at":"2026-01-09T09:01:45.893772-08:00","closed_at":"2026-01-09T09:01:45.893772-08:00"}
{"id":"mycelium-zdsk","title":"Bug: np.frombuffer receives string instead of bytes in has_mcts_alternatives","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-26T09:50:49.835876-08:00","created_by":"Bryce Roche","updated_at":"2026-01-26T10:50:12.402751-08:00","closed_at":"2026-01-26T10:50:12.402751-08:00","close_reason":"Fixed np.frombuffer bug - use _parse_centroid_data which handles string/bytes and fixed match_step_to_leaves_mcts parameter name"}
{"id":"mycelium-zlgm","title":"Remove or use signature_db parameter in validate_plan_coherence","description":"The signature_db parameter is accepted by validate_plan_coherence() but never used. Either implement richer validation using the signature DB (e.g., check if matching signatures exist for steps) or remove the unused parameter.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-14T06:06:31.725881-08:00","updated_at":"2026-01-14T06:56:45.976904-08:00","closed_at":"2026-01-14T06:56:45.976904-08:00","close_reason":"Removed unused parameter"}
{"id":"mycelium-zlza","title":"P2: Remove manual tree manipulation - integrate into automated review","description":"## Problem\n\nPer CLAUDE.md \"System Independence\": \"The system restructures its own tree via periodic review—that's by design. Resist manually intervening.\"\n\nWe have 3 violations where code manually manipulates the tree outside the automated review process.\n\n## Violations\n\n### 1. Manual Orphan Cleanup (db.py:8625-8682)\n\n`_cleanup_orphan_umbrellas()` manually finds and deletes orphaned umbrella signatures.\n\n```python\ndef _cleanup_orphan_umbrellas(self, conn=None):\n    # Finds orphans with no children and no parent\n    # Directly DELETEs them\n```\n\n**Should Be**: Orphan detection and cleanup should be part of `run_periodic_tree_review()`, not a separate manual function.\n\n### 2. Direct Reparenting During Archive (db.py:2986, 9366)\n\n`archive_signature_with_reparent()` manually updates parent relationships:\n\n```python\nc.execute(\"UPDATE signature_relationships SET parent_id = ? WHERE child_id = ?\", ...)\n```\n\n**Should Be**: Reparenting decisions should flow through periodic tree review with Welford-guided decisions.\n\n### 3. Permanent Deletion Instead of Archive (db.py:8664, 5876)\n\nDirect `DELETE FROM step_signatures` statements:\n\n```python\nc.execute(\"DELETE FROM step_signatures WHERE id = ?\", (orphan_id,))\n```\n\n**Should Be**: Use soft-delete via `is_archived = 1` flag. Permanent deletion loses learning history.\n\n## Solution\n\n1. **Move orphan cleanup INTO `run_periodic_tree_review()`**\n   - Remove standalone `_cleanup_orphan_umbrellas()`\n   - Add orphan detection as a step in the review process\n   - Use archive instead of delete\n\n2. **Remove `archive_signature_with_reparent()`**\n   - Reparenting should only happen during periodic review\n   - If archiving needs to happen, children become orphans → next review handles them\n\n3. **Replace DELETE with UPDATE is_archived**\n   - Search for all `DELETE FROM step_signatures`\n   - Replace with `UPDATE step_signatures SET is_archived = 1`\n   - Ensure archived signatures are excluded from routing\n\n## Implementation Steps\n\n1. Audit all tree manipulation code paths\n2. Identify which are called from automated review vs manual triggers\n3. Move manual triggers into review process\n4. Replace DELETE with soft-delete\n5. Test that tree self-heals correctly\n\n## Files to Modify\n\n- `src/mycelium/step_signatures/db.py`\n- Possibly `src/mycelium/step_signatures/umbrella_learner.py`\n\n## Context\n\nP2 priority per Big 3 audit - System Independence violations.","status":"closed","priority":2,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:50:53.334102-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T13:07:15.225693-08:00","closed_at":"2026-01-28T13:07:15.225693-08:00","close_reason":"Implemented System Independence fixes: (1) Replaced DELETE with soft-delete in _cleanup_orphan_umbrellas, (2) Added _adopt_orphan_children to periodic review, (3) Deprecated archive_signature_with_reparent - now just archive and let periodic review adopt orphans."}
{"id":"mycelium-zsat","title":"New Favorite Pattern: Consolidate leaf rejection to single entry point","description":"Leaf rejection has 3 entry points: mcts.py:807,931 (record_leaf_rejection, check_and_reject_if_low_similarity), db.py:1593,1641 (two separate rejection paths), solver.py:1475. Should consolidate to single entry point per New Favorite Pattern.","status":"closed","priority":1,"issue_type":"task","owner":"bryce.roche@gmail.com","created_at":"2026-01-28T12:00:42.833946-08:00","created_by":"Bryce Roche","updated_at":"2026-01-28T12:08:01.501884-08:00","closed_at":"2026-01-28T12:08:01.501884-08:00","close_reason":"Consolidated leaf rejection to single entry point: record_leaf_rejection(). Removed redundant check_and_reject_if_low_similarity() wrapper. All 3 callers (db.py:1593, db.py:1641, solver.py:1494) now use record_leaf_rejection() directly."}
{"id":"mycelium-zu82","title":"Bug: Inconsistent comparison operators in scoring.py traffic_share","status":"closed","priority":2,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T05:00:55.577406-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T05:37:38.130789-08:00","closed_at":"2026-01-15T05:37:38.130789-08:00","close_reason":"Moved TRAFFIC_MIN_SHARE \u003c= 0 check before traffic_share calculation. The previous placement was unreachable dead code when threshold was 0 (the \u003e= check would always trigger first)."}
{"id":"mycelium-zxzm","title":"Implement amplitude interference patterns","description":"When multiple threads visit same (dag_step_id, node_id): Constructive interference (both succeed) reinforces amplitude. Destructive interference (mixed results) indicates routing issue.\n\nKey insight: Use interference to drive STRUCTURAL changes:\n- Constructive interference → MERGE centroids (similar nodes that consistently succeed together should merge)\n- Destructive interference → SPLIT cluster (dissimilar nodes in same cluster that produce mixed results signal the cluster needs decomposition)\n\nThis connects wave function mechanics to the tree's organic growth.","status":"closed","priority":2,"issue_type":"feature","owner":"bryce.roche@gmail.com","created_at":"2026-01-20T14:07:23.787904-08:00","created_by":"Bryce Roche","updated_at":"2026-01-20T16:53:13.485973-08:00","closed_at":"2026-01-20T16:53:13.485973-08:00","close_reason":"Implemented interference pattern detection and centroid effects. Constructive interference reinforces nodes, destructive flags for split.","dependencies":[{"issue_id":"mycelium-zxzm","depends_on_id":"mycelium-t9kh","type":"blocks","created_at":"2026-01-20T14:07:35.776517-08:00","created_by":"Bryce Roche"}]}
{"id":"mycelium-zyx3","title":"Bug: 20+ swallowed exceptions cause silent failures","description":"20+ bare 'except Exception: pass' statements throughout solver.py (lines 83, 376, 568, 1118, 1225, 1484, 1518) and other modules. Per CLAUDE.md 'Record every failure - it feeds the refinement loop' - silent failures mean we lose valuable learning signal. Fix: Add logging to all exception handlers with signature_id, operation, and error context.","status":"closed","priority":1,"issue_type":"bug","owner":"bryce.roche@gmail.com","created_at":"2026-01-15T13:30:59.729674-08:00","created_by":"Bryce Roche","updated_at":"2026-01-15T13:54:47.977714-08:00","closed_at":"2026-01-15T13:54:47.977714-08:00","close_reason":"Added logging to 20+ silent exception handlers across 9 files. Failures now recorded per CLAUDE.md principle."}
